{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c34d2d",
   "metadata": {
    "papermill": {
     "duration": 0.003692,
     "end_time": "2025-05-14T09:50:30.202965",
     "exception": false,
     "start_time": "2025-05-14T09:50:30.199273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optimal Activation Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0dd97a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:30.210282Z",
     "iopub.status.busy": "2025-05-14T09:50:30.210008Z",
     "iopub.status.idle": "2025-05-14T09:50:47.465894Z",
     "shell.execute_reply": "2025-05-14T09:50:47.465168Z"
    },
    "papermill": {
     "duration": 17.261281,
     "end_time": "2025-05-14T09:50:47.467468",
     "exception": false,
     "start_time": "2025-05-14T09:50:30.206187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 09:50:32.324156: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747216232.556371      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747216232.626525      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Input, PReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau # Added ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris, load_wine, load_diabetes, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import time # To measure execution time\n",
    "import warnings # To suppress warnings if needed\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output (optional)\n",
    "# tf.get_logger().setLevel('ERROR')\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Configuration ---\n",
    "N_SEEDS = 5         # Number of random seeds to run for averaging results\n",
    "BASE_SEED = 42    # Base seed for reproducibility\n",
    "SEEDS = [BASE_SEED + i for i in range(N_SEEDS)] # List of seeds for multiple runs\n",
    "\n",
    "# Batch sizes to test\n",
    "BATCH_SIZES = [16, 32, 64, 128, 256]\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 200\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EARLY_STOPPING_PATIENCE = 20 # Patience for EarlyStopping\n",
    "REDUCE_LR_PATIENCE = 10     # Patience for ReduceLROnPlateau\n",
    "REDUCE_LR_FACTOR = 0.2      # Factor to reduce learning rate by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c31b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:47.474777Z",
     "iopub.status.busy": "2025-05-14T09:50:47.474206Z",
     "iopub.status.idle": "2025-05-14T09:50:47.480103Z",
     "shell.execute_reply": "2025-05-14T09:50:47.479413Z"
    },
    "papermill": {
     "duration": 0.010692,
     "end_time": "2025-05-14T09:50:47.481261",
     "exception": false,
     "start_time": "2025-05-14T09:50:47.470569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Seed Setting Function ---\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Sets random seeds for reproducibility.\"\"\"\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # Ensure TF uses deterministic operations where possible\n",
    "    # Note: This might impact performance. Remove if not strictly needed.\n",
    "    # tf.config.experimental.enable_op_determinism() # Might require specific TF versions/configs\n",
    "\n",
    "# Set initial seed for data splitting consistency\n",
    "set_seed(BASE_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29542a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:47.487363Z",
     "iopub.status.busy": "2025-05-14T09:50:47.487146Z",
     "iopub.status.idle": "2025-05-14T09:50:47.498313Z",
     "shell.execute_reply": "2025-05-14T09:50:47.497725Z"
    },
    "papermill": {
     "duration": 0.015654,
     "end_time": "2025-05-14T09:50:47.499550",
     "exception": false,
     "start_time": "2025-05-14T09:50:47.483896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Custom Activation Functions ---\n",
    "class OptimA(Layer):  # Optimal Activation\n",
    "    \"\"\"\n",
    "    Custom activation layer 'OptimA' with trainable parameters.\n",
    "    Combines tanh and softplus * sigmoid components.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(OptimA, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Defines the trainable weights (parameters) of the activation function.\"\"\"\n",
    "        self.alpha = self.add_weight(name='alpha', shape=(), initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=(), initializer=tf.keras.initializers.Constant(0.5), trainable=True)\n",
    "        self.gamma = self.add_weight(name='gamma', shape=(), initializer='ones', trainable=True)\n",
    "        self.delta = self.add_weight(name='delta', shape=(), initializer=tf.keras.initializers.Constant(0.5), trainable=True)\n",
    "        self.lambda_ = self.add_weight(name='lambda', shape=(), initializer='ones', trainable=True)\n",
    "        super(OptimA, self).build(input_shape) # Ensure build is called for the parent\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Defines the forward pass of the activation function.\"\"\"\n",
    "        term1 = self.alpha * tf.math.tanh(self.beta * x)\n",
    "        term2 = self.gamma * tf.math.softplus(self.delta * x) * tf.math.sigmoid(self.lambda_ * x)\n",
    "        return term1 + term2\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Ensures the layer can be saved and loaded.\"\"\"\n",
    "        config = super(OptimA, self).get_config()\n",
    "        # No specific state needs to be added here unless non-weight parameters are used\n",
    "        return config\n",
    "\n",
    "class OptimALinear(Layer):  # Optimal Activation (Linear Approximation)\n",
    "    \"\"\"\n",
    "    Custom activation layer 'OptimALinear' using linear approximations\n",
    "    for tanh, softplus, and sigmoid. Includes trainable parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, epsilon=1e-5, **kwargs):\n",
    "        super(OptimALinear, self).__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Defines the trainable weights (parameters) of the activation function.\"\"\"\n",
    "        self.alpha = self.add_weight(name='alpha', shape=(), initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=(), initializer=tf.keras.initializers.Constant(0.5), trainable=True)\n",
    "        self.gamma = self.add_weight(name='gamma', shape=(), initializer='ones', trainable=True)\n",
    "        self.delta = self.add_weight(name='delta', shape=(), initializer=tf.keras.initializers.Constant(0.5), trainable=True)\n",
    "        self.lambda_ = self.add_weight(name='lambda', shape=(), initializer='ones', trainable=True)\n",
    "        super(OptimALinear, self).build(input_shape) # Ensure build is called for the parent\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Defines the forward pass using linear approximations.\"\"\"\n",
    "        # Linear approximation for tanh (clipping)\n",
    "        term1 = self.alpha * tf.clip_by_value(self.beta * x, -1.0, 1.0)\n",
    "\n",
    "        # Linear approximations for softplus (ReLU-like) and sigmoid (linear segment)\n",
    "        # Softplus approx: max(0, val) + epsilon (to avoid potential zero multiplication)\n",
    "        softplus_approx = tf.maximum(0.0, self.delta * x) + self.epsilon\n",
    "        # Sigmoid approx near 0: 0.5 + 0.25 * val (first term of Taylor expansion around 0)\n",
    "        sigmoid_approx = tf.clip_by_value(0.5 + 0.25 * self.lambda_ * x, 0.0, 1.0) # Clip to [0,1]\n",
    "\n",
    "        term2 = self.gamma * softplus_approx * sigmoid_approx\n",
    "        return term1 + term2\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Ensures the layer can be saved and loaded.\"\"\"\n",
    "        config = super(OptimALinear, self).get_config()\n",
    "        config.update({\"epsilon\": self.epsilon})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb76ac21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:47.506184Z",
     "iopub.status.busy": "2025-05-14T09:50:47.505914Z",
     "iopub.status.idle": "2025-05-14T09:50:47.521560Z",
     "shell.execute_reply": "2025-05-14T09:50:47.520937Z"
    },
    "papermill": {
     "duration": 0.020367,
     "end_time": "2025-05-14T09:50:47.522766",
     "exception": false,
     "start_time": "2025-05-14T09:50:47.502399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class AdaptiveSwish(Layer):  # Trainable Swish Activation\n",
    "    \"\"\"\n",
    "    Custom activation layer 'AdaptiveSwish' with trainable parameters.\n",
    "    Implements the Swish activation: x * sigmoid(beta * x), scaled by alpha.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AdaptiveSwish, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Defines trainable weights of the activation function.\"\"\"\n",
    "        # Scaling factor\n",
    "        self.alpha = self.add_weight(\n",
    "            name='alpha', shape=(), initializer='ones', trainable=True)\n",
    "        # Slope parameter inside sigmoid\n",
    "        self.beta = self.add_weight(\n",
    "            name='beta', shape=(), initializer=tf.keras.initializers.Constant(1.0), trainable=True)\n",
    "        super(AdaptiveSwish, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Forward pass: alpha * x * sigmoid(beta * x)\"\"\"\n",
    "        return self.alpha * x * tf.math.sigmoid(self.beta * x)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Enables serialization of the layer.\"\"\"\n",
    "        config = super(AdaptiveSwish, self).get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "class LiSHT(Layer):  # Linearly Scaled Hyperbolic Tangent\n",
    "    \"\"\"\n",
    "    Custom activation layer 'LiSHT' with trainable parameters.\n",
    "    Implements LiSHT activation: alpha * x * tanh(beta * x).\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LiSHT, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Defines trainable weights of the activation function.\"\"\"\n",
    "        # Scaling factor\n",
    "        self.alpha = self.add_weight(\n",
    "            name='alpha', shape=(), initializer='ones', trainable=True)\n",
    "        # Slope parameter inside tanh\n",
    "        self.beta = self.add_weight(\n",
    "            name='beta', shape=(), initializer=tf.keras.initializers.Constant(1.0), trainable=True)\n",
    "        super(LiSHT, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Forward pass: alpha * x * tanh(beta * x)\"\"\"\n",
    "        return self.alpha * x * tf.math.tanh(self.beta * x)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Enables serialization of the layer.\"\"\"\n",
    "        config = super(LiSHT, self).get_config()\n",
    "        return config\n",
    "\n",
    "class AdaptiveMish(Layer):\n",
    "    \"\"\"\n",
    "    Custom Adaptive Mish activation (parameterized Mish):\n",
    "    f(x) = x * tanh( softplus(beta * x) / beta ), where beta > 0 is trainable.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AdaptiveMish, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Trainable positive parameter for Mish scaling as 1D tensor\n",
    "        self.beta = self.add_weight(\n",
    "            name='beta',\n",
    "            shape=(1,),\n",
    "            initializer=tf.keras.initializers.Ones(),\n",
    "            trainable=True,\n",
    "            constraint=tf.keras.constraints.MinMaxNorm(min_value=1e-6)\n",
    "        )\n",
    "        super(AdaptiveMish, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        softplus_term = tf.math.softplus(self.beta * x)\n",
    "        return x * tf.math.tanh(softplus_term / self.beta)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(AdaptiveMish, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df09c2c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:47.529622Z",
     "iopub.status.busy": "2025-05-14T09:50:47.529072Z",
     "iopub.status.idle": "2025-05-14T09:50:47.533494Z",
     "shell.execute_reply": "2025-05-14T09:50:47.532735Z"
    },
    "papermill": {
     "duration": 0.009426,
     "end_time": "2025-05-14T09:50:47.534966",
     "exception": false,
     "start_time": "2025-05-14T09:50:47.525540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading and Preparation ---\n",
    "print(\"Loading and preparing data...\")\n",
    "\n",
    "# Dictionary to hold dataset configurations\n",
    "datasets_config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4605d9b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:47.545287Z",
     "iopub.status.busy": "2025-05-14T09:50:47.545076Z",
     "iopub.status.idle": "2025-05-14T09:50:47.740547Z",
     "shell.execute_reply": "2025-05-14T09:50:47.739913Z"
    },
    "papermill": {
     "duration": 0.202188,
     "end_time": "2025-05-14T09:50:47.741982",
     "exception": false,
     "start_time": "2025-05-14T09:50:47.539794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "# 1. Regression: Boston Housing (Note: Boston Housing is often discouraged due to ethical concerns, but kept here as per the original request)\n",
    "try:\n",
    "    (x_train_boston, y_train_boston), (x_test_boston, y_test_boston) = boston_housing.load_data(seed=BASE_SEED)\n",
    "    scaler_boston = StandardScaler()\n",
    "    x_train_boston = scaler_boston.fit_transform(x_train_boston)\n",
    "    x_test_boston = scaler_boston.transform(x_test_boston)\n",
    "    datasets_config['Boston Housing'] = {\n",
    "        'data': (x_train_boston, y_train_boston, x_test_boston, y_test_boston),\n",
    "        'task_type': 'regression',\n",
    "        'metric_name': 'MAE' # Mean Absolute Error\n",
    "    }\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not load Boston Housing dataset. Skipping. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa4625e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:47.753989Z",
     "iopub.status.busy": "2025-05-14T09:50:47.753747Z",
     "iopub.status.idle": "2025-05-14T09:50:47.766229Z",
     "shell.execute_reply": "2025-05-14T09:50:47.765408Z"
    },
    "papermill": {
     "duration": 0.019862,
     "end_time": "2025-05-14T09:50:47.767533",
     "exception": false,
     "start_time": "2025-05-14T09:50:47.747671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Classification: Iris\n",
    "data_iris = load_iris()\n",
    "x_train_iris, x_test_iris, y_train_iris, y_test_iris = train_test_split(data_iris.data, data_iris.target, test_size=0.2, random_state=BASE_SEED, stratify=data_iris.target)\n",
    "scaler_iris = StandardScaler()\n",
    "x_train_iris = scaler_iris.fit_transform(x_train_iris)\n",
    "x_test_iris = scaler_iris.transform(x_test_iris)\n",
    "y_train_iris_cat = to_categorical(y_train_iris) # Keep original for potential different loss functions if needed\n",
    "y_test_iris_cat = to_categorical(y_test_iris)\n",
    "datasets_config['Iris'] = {\n",
    "    'data': (x_train_iris, y_train_iris_cat, x_test_iris, y_test_iris_cat),\n",
    "    'task_type': 'classification',\n",
    "    'metric_name': 'Accuracy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69a7393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:47.779192Z",
     "iopub.status.busy": "2025-05-14T09:50:47.778972Z",
     "iopub.status.idle": "2025-05-14T09:50:47.788497Z",
     "shell.execute_reply": "2025-05-14T09:50:47.787736Z"
    },
    "papermill": {
     "duration": 0.016853,
     "end_time": "2025-05-14T09:50:47.789913",
     "exception": false,
     "start_time": "2025-05-14T09:50:47.773060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Multiclass Classification: Wine\n",
    "data_wine = load_wine()\n",
    "x_train_wine, x_test_wine, y_train_wine, y_test_wine = train_test_split(data_wine.data, data_wine.target, test_size=0.2, random_state=BASE_SEED, stratify=data_wine.target)\n",
    "scaler_wine = StandardScaler()\n",
    "x_train_wine = scaler_wine.fit_transform(x_train_wine)\n",
    "x_test_wine = scaler_wine.transform(x_test_wine)\n",
    "y_train_wine_cat = to_categorical(y_train_wine)\n",
    "y_test_wine_cat = to_categorical(y_test_wine)\n",
    "datasets_config['Wine'] = {\n",
    "    'data': (x_train_wine, y_train_wine_cat, x_test_wine, y_test_wine_cat),\n",
    "    'task_type': 'classification',\n",
    "    'metric_name': 'Accuracy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa95600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:47.801771Z",
     "iopub.status.busy": "2025-05-14T09:50:47.801496Z",
     "iopub.status.idle": "2025-05-14T09:50:47.811487Z",
     "shell.execute_reply": "2025-05-14T09:50:47.810728Z"
    },
    "papermill": {
     "duration": 0.017385,
     "end_time": "2025-05-14T09:50:47.812949",
     "exception": false,
     "start_time": "2025-05-14T09:50:47.795564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Regression: Diabetes Dataset\n",
    "data_diabetes = load_diabetes()\n",
    "x_train_diabetes, x_test_diabetes, y_train_diabetes, y_test_diabetes = train_test_split(\n",
    "    data_diabetes.data, data_diabetes.target, test_size=0.2, random_state=BASE_SEED\n",
    ")\n",
    "scaler_diabetes = StandardScaler()\n",
    "x_train_diabetes = scaler_diabetes.fit_transform(x_train_diabetes)\n",
    "x_test_diabetes = scaler_diabetes.transform(x_test_diabetes)\n",
    "datasets_config['Diabetes'] = {\n",
    "    'data': (x_train_diabetes, y_train_diabetes, x_test_diabetes, y_test_diabetes),\n",
    "    'task_type': 'regression',\n",
    "    'metric_name': 'MAE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a73719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:47.824949Z",
     "iopub.status.busy": "2025-05-14T09:50:47.824734Z",
     "iopub.status.idle": "2025-05-14T09:50:48.273187Z",
     "shell.execute_reply": "2025-05-14T09:50:48.272328Z"
    },
    "papermill": {
     "duration": 0.456293,
     "end_time": "2025-05-14T09:50:48.274818",
     "exception": false,
     "start_time": "2025-05-14T09:50:47.818525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Regression: California Housing Dataset\n",
    "data_california = fetch_california_housing()\n",
    "x_train_california, x_test_california, y_train_california, y_test_california = train_test_split(\n",
    "    data_california.data, data_california.target, test_size=0.2, random_state=BASE_SEED\n",
    ")\n",
    "scaler_california = StandardScaler()\n",
    "x_train_california = scaler_california.fit_transform(x_train_california)\n",
    "x_test_california = scaler_california.transform(x_test_california)\n",
    "datasets_config['California Housing'] = {\n",
    "    'data': (x_train_california, y_train_california, x_test_california, y_test_california),\n",
    "    'task_type': 'regression',\n",
    "    'metric_name': 'MAE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52a684c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:48.286803Z",
     "iopub.status.busy": "2025-05-14T09:50:48.286201Z",
     "iopub.status.idle": "2025-05-14T09:50:48.290595Z",
     "shell.execute_reply": "2025-05-14T09:50:48.289940Z"
    },
    "papermill": {
     "duration": 0.009873,
     "end_time": "2025-05-14T09:50:48.291671",
     "exception": false,
     "start_time": "2025-05-14T09:50:48.281798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading and preparation complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Data loading and preparation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52ec3d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:48.299082Z",
     "iopub.status.busy": "2025-05-14T09:50:48.298865Z",
     "iopub.status.idle": "2025-05-14T09:50:48.307577Z",
     "shell.execute_reply": "2025-05-14T09:50:48.306829Z"
    },
    "papermill": {
     "duration": 0.013665,
     "end_time": "2025-05-14T09:50:48.308634",
     "exception": false,
     "start_time": "2025-05-14T09:50:48.294969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Model Building and Evaluation Function ---\n",
    "def build_and_evaluate_model(x_train, y_train, x_test, y_test, activation_instance,\n",
    "                             task_type=\"classification\", batch_size=32):\n",
    "    \"\"\"\n",
    "    Builds, compiles, trains, and evaluates a simple Sequential model.\n",
    "\n",
    "    Args:\n",
    "        x_train: Training features.\n",
    "        y_train: Training targets.\n",
    "        x_test: Testing features.\n",
    "        y_test: Testing targets.\n",
    "        activation_instance: An instantiated activation layer or a string identifier.\n",
    "        task_type (str): 'classification' or 'regression'.\n",
    "        batch_size (int): Batch size for training.\n",
    "\n",
    "    Returns:\n",
    "        float: The evaluation metric score (Accuracy for classification, MAE for regression).\n",
    "               Returns np.nan if training fails.\n",
    "    \"\"\"\n",
    "    # Ensure a new model is created for each call\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(x_train.shape[1],))) # Use Input layer for explicit shape definition\n",
    "    model.add(Dense(64, activation=activation_instance)) # Hidden layer\n",
    "\n",
    "    # Output layer and loss function based on task type\n",
    "    if task_type == \"classification\":\n",
    "        num_classes = y_train.shape[1]\n",
    "        if num_classes == 1: # Binary classification (should ideally be checked based on unique values in original y)\n",
    "             # This case isn't used with the current to_categorical preprocessing, but included for completeness\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            loss = 'binary_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "        else:  # Multiclass classification\n",
    "            model.add(Dense(num_classes, activation='softmax'))\n",
    "            loss = 'categorical_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "        monitor_metric = 'val_accuracy' # Monitor validation accuracy for callbacks\n",
    "        eval_metric_index = 1 # metrics list index for accuracy\n",
    "\n",
    "    elif task_type == \"regression\":\n",
    "        model.add(Dense(1)) # Linear output layer\n",
    "        loss = 'mse' # Mean Squared Error is common for training regression\n",
    "        metrics = ['mae'] # Mean Absolute Error is often preferred for evaluation\n",
    "        monitor_metric = 'val_mae' # Monitor validation MAE for callbacks\n",
    "        eval_metric_index = 1 # metrics list index for MAE\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = AdamW(learning_rate=1e-3, beta_1=0.95, beta_2=0.999)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    # Define callbacks\n",
    "    early_stop = EarlyStopping(monitor=monitor_metric, patience=EARLY_STOPPING_PATIENCE,\n",
    "                               restore_best_weights=True, mode='min' if task_type == 'regression' else 'max')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=monitor_metric, factor=REDUCE_LR_FACTOR,\n",
    "                                  patience=REDUCE_LR_PATIENCE, min_lr=1e-6,\n",
    "                                  mode='min' if task_type == 'regression' else 'max')\n",
    "\n",
    "    # Train the model\n",
    "    try:\n",
    "        history = model.fit(x_train, y_train,\n",
    "                          validation_split=VALIDATION_SPLIT,\n",
    "                          epochs=EPOCHS,\n",
    "                          batch_size=batch_size,\n",
    "                          callbacks=[early_stop, reduce_lr],\n",
    "                          verbose=0) # verbose=0 for cleaner output during loops\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        results = model.evaluate(x_test, y_test, verbose=0)\n",
    "        return results[eval_metric_index] # Return the desired metric (Accuracy or MAE)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"      ! Training/Evaluation failed: {e}\")\n",
    "        return np.nan # Return NaN if an error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ee2200a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:50:48.316275Z",
     "iopub.status.busy": "2025-05-14T09:50:48.316048Z",
     "iopub.status.idle": "2025-05-14T18:25:57.996843Z",
     "shell.execute_reply": "2025-05-14T18:25:57.996041Z"
    },
    "papermill": {
     "duration": 30909.716979,
     "end_time": "2025-05-14T18:25:58.028984",
     "exception": false,
     "start_time": "2025-05-14T09:50:48.312005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Experiment ---\n",
      "\n",
      "--- Running Seed 1/5 (Seed: 42) ---\n",
      "  Dataset: Boston Housing (regression)\n",
      "    Activation: OptimA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747216249.511085      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747216253.104023      60 service.cc:148] XLA service 0x7abfac00c840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747216253.104734      60 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1747216253.357731      60 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1747216254.039368      60 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Batch: 16  | MAE: 3.4092 | Time: 11.89s\n",
      "      Batch: 32  | MAE: 3.2323 | Time: 9.05s\n",
      "      Batch: 64  | MAE: 3.3454 | Time: 11.73s\n",
      "      Batch: 128 | MAE: 3.5782 | Time: 13.21s\n",
      "      Batch: 256 | MAE: 3.8935 | Time: 16.49s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 2.3856 | Time: 30.24s\n",
      "      Batch: 32  | MAE: 2.3875 | Time: 24.19s\n",
      "      Batch: 64  | MAE: 2.6273 | Time: 21.69s\n",
      "      Batch: 128 | MAE: 4.2119 | Time: 12.10s\n",
      "      Batch: 256 | MAE: 4.0577 | Time: 18.92s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 2.5419 | Time: 22.66s\n",
      "      Batch: 32  | MAE: 2.6748 | Time: 21.39s\n",
      "      Batch: 64  | MAE: 3.2224 | Time: 19.96s\n",
      "      Batch: 128 | MAE: 4.1652 | Time: 17.71s\n",
      "      Batch: 256 | MAE: 4.6621 | Time: 17.63s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 2.6222 | Time: 18.15s\n",
      "      Batch: 32  | MAE: 2.5657 | Time: 22.34s\n",
      "      Batch: 64  | MAE: 2.8696 | Time: 19.59s\n",
      "      Batch: 128 | MAE: 3.7013 | Time: 17.81s\n",
      "      Batch: 256 | MAE: 4.3086 | Time: 17.47s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 2.7143 | Time: 19.80s\n",
      "      Batch: 32  | MAE: 2.6781 | Time: 21.41s\n",
      "      Batch: 64  | MAE: 3.0449 | Time: 19.17s\n",
      "      Batch: 128 | MAE: 3.7885 | Time: 17.35s\n",
      "      Batch: 256 | MAE: 4.5359 | Time: 16.96s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 2.5222 | Time: 28.61s\n",
      "      Batch: 32  | MAE: 2.5399 | Time: 22.56s\n",
      "      Batch: 64  | MAE: 3.0441 | Time: 20.14s\n",
      "      Batch: 128 | MAE: 4.0278 | Time: 18.42s\n",
      "      Batch: 256 | MAE: 5.0162 | Time: 19.13s\n",
      "  Dataset: Iris (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 6.95s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 7.39s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 6.10s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 7.67s\n",
      "      Batch: 256 | Accuracy: 0.3333 | Time: 4.92s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.7333 | Time: 5.66s\n",
      "      Batch: 32  | Accuracy: 0.7333 | Time: 5.73s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 6.64s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 6.21s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 6.72s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 6.66s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 5.46s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 8.71s\n",
      "      Batch: 128 | Accuracy: 0.6000 | Time: 4.90s\n",
      "      Batch: 256 | Accuracy: 0.6333 | Time: 4.25s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | Accuracy: 0.8333 | Time: 8.67s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 4.36s\n",
      "      Batch: 64  | Accuracy: 0.6667 | Time: 4.48s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 4.85s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 4.52s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 6.86s\n",
      "      Batch: 32  | Accuracy: 0.7000 | Time: 5.81s\n",
      "      Batch: 64  | Accuracy: 0.6000 | Time: 4.75s\n",
      "      Batch: 128 | Accuracy: 0.7333 | Time: 4.19s\n",
      "      Batch: 256 | Accuracy: 0.5667 | Time: 4.74s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 5.92s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 5.54s\n",
      "      Batch: 64  | Accuracy: 0.6667 | Time: 6.96s\n",
      "      Batch: 128 | Accuracy: 0.5333 | Time: 4.68s\n",
      "      Batch: 256 | Accuracy: 0.5000 | Time: 5.67s\n",
      "  Dataset: Wine (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 6.65s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 6.21s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 7.54s\n",
      "      Batch: 128 | Accuracy: 0.9444 | Time: 7.92s\n",
      "      Batch: 256 | Accuracy: 0.9722 | Time: 6.14s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 7.20s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 7.49s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 7.50s\n",
      "      Batch: 128 | Accuracy: 0.8056 | Time: 6.12s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 7.53s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 6.29s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 5.83s\n",
      "      Batch: 64  | Accuracy: 1.0000 | Time: 6.69s\n",
      "      Batch: 128 | Accuracy: 0.9444 | Time: 6.83s\n",
      "      Batch: 256 | Accuracy: 0.8889 | Time: 6.01s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 5.72s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 6.56s\n",
      "      Batch: 64  | Accuracy: 1.0000 | Time: 7.25s\n",
      "      Batch: 128 | Accuracy: 0.8889 | Time: 7.16s\n",
      "      Batch: 256 | Accuracy: 0.9444 | Time: 6.20s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | Accuracy: 0.8333 | Time: 5.32s\n",
      "      Batch: 32  | Accuracy: 0.8611 | Time: 5.32s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 6.27s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 5.44s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 5.58s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | Accuracy: 0.8889 | Time: 6.29s\n",
      "      Batch: 32  | Accuracy: 0.8611 | Time: 6.30s\n",
      "      Batch: 64  | Accuracy: 0.9444 | Time: 10.13s\n",
      "      Batch: 128 | Accuracy: 0.8333 | Time: 6.19s\n",
      "      Batch: 256 | Accuracy: 0.8889 | Time: 7.52s\n",
      "  Dataset: Diabetes (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 43.5439 | Time: 13.67s\n",
      "      Batch: 32  | MAE: 45.3043 | Time: 15.47s\n",
      "      Batch: 64  | MAE: 45.6017 | Time: 20.73s\n",
      "      Batch: 128 | MAE: 58.9508 | Time: 21.20s\n",
      "      Batch: 256 | MAE: 92.9421 | Time: 18.62s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 41.2916 | Time: 17.91s\n",
      "      Batch: 32  | MAE: 41.1215 | Time: 20.31s\n",
      "      Batch: 64  | MAE: 44.9458 | Time: 19.45s\n",
      "      Batch: 128 | MAE: 78.1842 | Time: 18.13s\n",
      "      Batch: 256 | MAE: 90.6441 | Time: 19.44s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 47.2215 | Time: 14.62s\n",
      "      Batch: 32  | MAE: 46.2702 | Time: 18.60s\n",
      "      Batch: 64  | MAE: 64.1574 | Time: 18.22s\n",
      "      Batch: 128 | MAE: 85.2017 | Time: 16.95s\n",
      "      Batch: 256 | MAE: 115.6597 | Time: 16.78s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 42.7547 | Time: 19.40s\n",
      "      Batch: 32  | MAE: 45.7325 | Time: 20.73s\n",
      "      Batch: 64  | MAE: 50.6324 | Time: 18.43s\n",
      "      Batch: 128 | MAE: 72.0306 | Time: 19.51s\n",
      "      Batch: 256 | MAE: 84.5821 | Time: 17.34s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 43.7056 | Time: 20.59s\n",
      "      Batch: 32  | MAE: 44.7078 | Time: 20.06s\n",
      "      Batch: 64  | MAE: 54.1191 | Time: 18.61s\n",
      "      Batch: 128 | MAE: 61.8556 | Time: 16.75s\n",
      "      Batch: 256 | MAE: 92.1195 | Time: 16.71s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 48.8565 | Time: 14.17s\n",
      "      Batch: 32  | MAE: 49.6672 | Time: 17.55s\n",
      "      Batch: 64  | MAE: 56.1672 | Time: 18.15s\n",
      "      Batch: 128 | MAE: 67.9969 | Time: 19.59s\n",
      "      Batch: 256 | MAE: 76.7156 | Time: 16.99s\n",
      "  Dataset: California Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 0.3624 | Time: 347.64s\n",
      "      Batch: 32  | MAE: 0.3688 | Time: 217.96s\n",
      "      Batch: 64  | MAE: 0.3740 | Time: 120.49s\n",
      "      Batch: 128 | MAE: 0.3702 | Time: 68.75s\n",
      "      Batch: 256 | MAE: 0.3924 | Time: 42.65s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 0.3616 | Time: 414.84s\n",
      "      Batch: 32  | MAE: 0.3845 | Time: 220.13s\n",
      "      Batch: 64  | MAE: 0.3844 | Time: 91.58s\n",
      "      Batch: 128 | MAE: 0.3902 | Time: 69.05s\n",
      "      Batch: 256 | MAE: 0.3908 | Time: 42.98s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 0.3906 | Time: 403.38s\n",
      "      Batch: 32  | MAE: 0.3910 | Time: 207.18s\n",
      "      Batch: 64  | MAE: 0.3974 | Time: 111.54s\n",
      "      Batch: 128 | MAE: 0.4039 | Time: 63.74s\n",
      "      Batch: 256 | MAE: 0.4107 | Time: 40.24s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 0.3594 | Time: 405.71s\n",
      "      Batch: 32  | MAE: 0.3659 | Time: 210.18s\n",
      "      Batch: 64  | MAE: 0.3639 | Time: 113.38s\n",
      "      Batch: 128 | MAE: 0.3747 | Time: 65.75s\n",
      "      Batch: 256 | MAE: 0.3932 | Time: 40.70s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 0.3685 | Time: 343.59s\n",
      "      Batch: 32  | MAE: 0.3832 | Time: 66.07s\n",
      "      Batch: 64  | MAE: 0.3837 | Time: 59.62s\n",
      "      Batch: 128 | MAE: 0.3825 | Time: 38.25s\n",
      "      Batch: 256 | MAE: 0.3776 | Time: 39.43s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 0.4069 | Time: 159.39s\n",
      "      Batch: 32  | MAE: 0.4060 | Time: 89.88s\n",
      "      Batch: 64  | MAE: 0.4266 | Time: 38.42s\n",
      "      Batch: 128 | MAE: 0.4126 | Time: 43.08s\n",
      "      Batch: 256 | MAE: 0.4288 | Time: 33.65s\n",
      "\n",
      "--- Running Seed 2/5 (Seed: 43) ---\n",
      "  Dataset: Boston Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 2.5502 | Time: 29.05s\n",
      "      Batch: 32  | MAE: 3.3732 | Time: 8.40s\n",
      "      Batch: 64  | MAE: 3.5091 | Time: 10.35s\n",
      "      Batch: 128 | MAE: 3.4900 | Time: 12.74s\n",
      "      Batch: 256 | MAE: 3.7246 | Time: 15.22s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 2.3023 | Time: 27.54s\n",
      "      Batch: 32  | MAE: 2.4227 | Time: 27.48s\n",
      "      Batch: 64  | MAE: 2.8818 | Time: 20.22s\n",
      "      Batch: 128 | MAE: 4.1792 | Time: 12.09s\n",
      "      Batch: 256 | MAE: 3.9688 | Time: 17.86s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 2.4714 | Time: 25.35s\n",
      "      Batch: 32  | MAE: 2.7648 | Time: 20.40s\n",
      "      Batch: 64  | MAE: 3.2516 | Time: 18.09s\n",
      "      Batch: 128 | MAE: 3.9947 | Time: 16.75s\n",
      "      Batch: 256 | MAE: 4.5953 | Time: 16.19s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 2.6269 | Time: 16.46s\n",
      "      Batch: 32  | MAE: 2.6311 | Time: 20.41s\n",
      "      Batch: 64  | MAE: 2.9989 | Time: 18.22s\n",
      "      Batch: 128 | MAE: 3.7604 | Time: 19.86s\n",
      "      Batch: 256 | MAE: 4.2596 | Time: 16.94s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 2.6984 | Time: 25.41s\n",
      "      Batch: 32  | MAE: 2.6998 | Time: 20.38s\n",
      "      Batch: 64  | MAE: 3.2122 | Time: 17.89s\n",
      "      Batch: 128 | MAE: 3.7041 | Time: 16.67s\n",
      "      Batch: 256 | MAE: 4.4139 | Time: 16.12s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 2.5873 | Time: 25.80s\n",
      "      Batch: 32  | MAE: 2.5674 | Time: 20.40s\n",
      "      Batch: 64  | MAE: 3.0127 | Time: 18.23s\n",
      "      Batch: 128 | MAE: 3.7748 | Time: 16.83s\n",
      "      Batch: 256 | MAE: 5.0571 | Time: 16.24s\n",
      "  Dataset: Iris (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 6.02s\n",
      "      Batch: 32  | Accuracy: 0.6667 | Time: 7.07s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 5.56s\n",
      "      Batch: 128 | Accuracy: 0.8000 | Time: 5.47s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 4.66s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 6.04s\n",
      "      Batch: 32  | Accuracy: 0.8333 | Time: 7.78s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 7.04s\n",
      "      Batch: 128 | Accuracy: 0.7000 | Time: 5.61s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 5.35s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 4.69s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 7.17s\n",
      "      Batch: 64  | Accuracy: 0.6667 | Time: 4.68s\n",
      "      Batch: 128 | Accuracy: 0.6667 | Time: 4.59s\n",
      "      Batch: 256 | Accuracy: 0.8000 | Time: 4.97s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | Accuracy: 0.7333 | Time: 4.28s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 5.20s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 5.28s\n",
      "      Batch: 128 | Accuracy: 0.7000 | Time: 4.43s\n",
      "      Batch: 256 | Accuracy: 0.8000 | Time: 4.91s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 4.88s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 4.82s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 4.07s\n",
      "      Batch: 128 | Accuracy: 0.6667 | Time: 4.91s\n",
      "      Batch: 256 | Accuracy: 0.6667 | Time: 3.63s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 5.39s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 9.06s\n",
      "      Batch: 64  | Accuracy: 0.5667 | Time: 8.56s\n",
      "      Batch: 128 | Accuracy: 0.6333 | Time: 5.44s\n",
      "      Batch: 256 | Accuracy: 0.6000 | Time: 5.76s\n",
      "  Dataset: Wine (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 6.26s\n",
      "      Batch: 32  | Accuracy: 0.8611 | Time: 6.11s\n",
      "      Batch: 64  | Accuracy: 0.9722 | Time: 6.10s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 6.09s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 6.83s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 6.50s\n",
      "      Batch: 32  | Accuracy: 0.9167 | Time: 6.21s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 6.33s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 7.98s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 6.38s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | Accuracy: 0.9722 | Time: 5.24s\n",
      "      Batch: 32  | Accuracy: 0.9167 | Time: 4.56s\n",
      "      Batch: 64  | Accuracy: 1.0000 | Time: 5.99s\n",
      "      Batch: 128 | Accuracy: 0.9444 | Time: 5.93s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 5.35s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 5.38s\n",
      "      Batch: 32  | Accuracy: 0.8611 | Time: 4.92s\n",
      "      Batch: 64  | Accuracy: 0.9444 | Time: 6.03s\n",
      "      Batch: 128 | Accuracy: 0.9722 | Time: 6.50s\n",
      "      Batch: 256 | Accuracy: 0.8056 | Time: 5.13s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | Accuracy: 0.8889 | Time: 4.65s\n",
      "      Batch: 32  | Accuracy: 0.9167 | Time: 4.72s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 4.88s\n",
      "      Batch: 128 | Accuracy: 0.8333 | Time: 7.11s\n",
      "      Batch: 256 | Accuracy: 0.6944 | Time: 4.64s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 6.90s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 5.96s\n",
      "      Batch: 64  | Accuracy: 0.8611 | Time: 5.73s\n",
      "      Batch: 128 | Accuracy: 0.6111 | Time: 6.89s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 5.92s\n",
      "  Dataset: Diabetes (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 43.5110 | Time: 13.97s\n",
      "      Batch: 32  | MAE: 43.2047 | Time: 16.71s\n",
      "      Batch: 64  | MAE: 45.4680 | Time: 19.27s\n",
      "      Batch: 128 | MAE: 60.1089 | Time: 17.88s\n",
      "      Batch: 256 | MAE: 95.0172 | Time: 17.43s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 43.5425 | Time: 13.12s\n",
      "      Batch: 32  | MAE: 45.0673 | Time: 15.14s\n",
      "      Batch: 64  | MAE: 44.3690 | Time: 22.18s\n",
      "      Batch: 128 | MAE: 68.5874 | Time: 18.31s\n",
      "      Batch: 256 | MAE: 145.7749 | Time: 5.61s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 47.2156 | Time: 13.64s\n",
      "      Batch: 32  | MAE: 47.3828 | Time: 18.32s\n",
      "      Batch: 64  | MAE: 60.2986 | Time: 18.15s\n",
      "      Batch: 128 | MAE: 87.2754 | Time: 16.67s\n",
      "      Batch: 256 | MAE: 120.0037 | Time: 16.30s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 43.9666 | Time: 18.59s\n",
      "      Batch: 32  | MAE: 45.8041 | Time: 19.83s\n",
      "      Batch: 64  | MAE: 51.3846 | Time: 17.95s\n",
      "      Batch: 128 | MAE: 72.7083 | Time: 16.68s\n",
      "      Batch: 256 | MAE: 94.4172 | Time: 16.47s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 47.9482 | Time: 13.80s\n",
      "      Batch: 32  | MAE: 45.4483 | Time: 19.42s\n",
      "      Batch: 64  | MAE: 56.1804 | Time: 17.54s\n",
      "      Batch: 128 | MAE: 60.5919 | Time: 16.57s\n",
      "      Batch: 256 | MAE: 98.7002 | Time: 15.99s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 47.1102 | Time: 17.95s\n",
      "      Batch: 32  | MAE: 48.9115 | Time: 18.21s\n",
      "      Batch: 64  | MAE: 50.8428 | Time: 18.40s\n",
      "      Batch: 128 | MAE: 63.9857 | Time: 16.86s\n",
      "      Batch: 256 | MAE: 74.4401 | Time: 16.55s\n",
      "  Dataset: California Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 0.3580 | Time: 399.67s\n",
      "      Batch: 32  | MAE: 0.3623 | Time: 217.35s\n",
      "      Batch: 64  | MAE: 0.3693 | Time: 124.41s\n",
      "      Batch: 128 | MAE: 0.3770 | Time: 70.03s\n",
      "      Batch: 256 | MAE: 0.3840 | Time: 43.12s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 0.3697 | Time: 419.61s\n",
      "      Batch: 32  | MAE: 0.3677 | Time: 218.54s\n",
      "      Batch: 64  | MAE: 0.3793 | Time: 117.73s\n",
      "      Batch: 128 | MAE: 0.3803 | Time: 59.60s\n",
      "      Batch: 256 | MAE: 0.3848 | Time: 47.21s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 0.3888 | Time: 412.08s\n",
      "      Batch: 32  | MAE: 0.3906 | Time: 215.79s\n",
      "      Batch: 64  | MAE: 0.3950 | Time: 116.39s\n",
      "      Batch: 128 | MAE: 0.4024 | Time: 68.35s\n",
      "      Batch: 256 | MAE: 0.4093 | Time: 42.64s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 0.3597 | Time: 333.41s\n",
      "      Batch: 32  | MAE: 0.3590 | Time: 211.86s\n",
      "      Batch: 64  | MAE: 0.3689 | Time: 114.18s\n",
      "      Batch: 128 | MAE: 0.3744 | Time: 65.83s\n",
      "      Batch: 256 | MAE: 0.3909 | Time: 40.73s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 0.3647 | Time: 388.58s\n",
      "      Batch: 32  | MAE: 0.3714 | Time: 209.96s\n",
      "      Batch: 64  | MAE: 0.3798 | Time: 96.97s\n",
      "      Batch: 128 | MAE: 0.3798 | Time: 65.73s\n",
      "      Batch: 256 | MAE: 0.3783 | Time: 40.58s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 0.3878 | Time: 408.67s\n",
      "      Batch: 32  | MAE: 0.3897 | Time: 212.59s\n",
      "      Batch: 64  | MAE: 0.3965 | Time: 99.38s\n",
      "      Batch: 128 | MAE: 0.4018 | Time: 52.41s\n",
      "      Batch: 256 | MAE: 0.4106 | Time: 40.52s\n",
      "\n",
      "--- Running Seed 3/5 (Seed: 44) ---\n",
      "  Dataset: Boston Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 2.9470 | Time: 31.19s\n",
      "      Batch: 32  | MAE: 2.5741 | Time: 27.66s\n",
      "      Batch: 64  | MAE: 3.0540 | Time: 21.21s\n",
      "      Batch: 128 | MAE: 3.7893 | Time: 12.91s\n",
      "      Batch: 256 | MAE: 3.4773 | Time: 18.71s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 2.4011 | Time: 28.26s\n",
      "      Batch: 32  | MAE: 3.2143 | Time: 23.68s\n",
      "      Batch: 64  | MAE: 2.8580 | Time: 20.80s\n",
      "      Batch: 128 | MAE: 4.4097 | Time: 11.74s\n",
      "      Batch: 256 | MAE: 3.7108 | Time: 17.99s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 2.5410 | Time: 23.53s\n",
      "      Batch: 32  | MAE: 2.6504 | Time: 20.85s\n",
      "      Batch: 64  | MAE: 3.3719 | Time: 18.55s\n",
      "      Batch: 128 | MAE: 4.0107 | Time: 16.99s\n",
      "      Batch: 256 | MAE: 4.9218 | Time: 17.04s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 2.5630 | Time: 16.41s\n",
      "      Batch: 32  | MAE: 2.6536 | Time: 20.92s\n",
      "      Batch: 64  | MAE: 3.1300 | Time: 19.44s\n",
      "      Batch: 128 | MAE: 3.9017 | Time: 17.32s\n",
      "      Batch: 256 | MAE: 4.2830 | Time: 22.02s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 2.7718 | Time: 19.28s\n",
      "      Batch: 32  | MAE: 2.8661 | Time: 20.94s\n",
      "      Batch: 64  | MAE: 3.2878 | Time: 18.62s\n",
      "      Batch: 128 | MAE: 3.8614 | Time: 17.11s\n",
      "      Batch: 256 | MAE: 4.5838 | Time: 16.36s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 2.8092 | Time: 18.52s\n",
      "      Batch: 32  | MAE: 2.7647 | Time: 20.52s\n",
      "      Batch: 64  | MAE: 3.0549 | Time: 18.86s\n",
      "      Batch: 128 | MAE: 3.5936 | Time: 16.94s\n",
      "      Batch: 256 | MAE: 5.1278 | Time: 16.81s\n",
      "  Dataset: Iris (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 6.27s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 6.38s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 5.80s\n",
      "      Batch: 128 | Accuracy: 0.7333 | Time: 6.34s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 7.10s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.9000 | Time: 9.47s\n",
      "      Batch: 32  | Accuracy: 0.7333 | Time: 5.14s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 9.01s\n",
      "      Batch: 128 | Accuracy: 0.6000 | Time: 9.16s\n",
      "      Batch: 256 | Accuracy: 0.6000 | Time: 4.83s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | Accuracy: 0.8667 | Time: 7.96s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 7.28s\n",
      "      Batch: 64  | Accuracy: 0.7000 | Time: 4.55s\n",
      "      Batch: 128 | Accuracy: 0.5333 | Time: 4.55s\n",
      "      Batch: 256 | Accuracy: 0.7333 | Time: 4.97s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 4.31s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 6.96s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 5.45s\n",
      "      Batch: 128 | Accuracy: 0.6667 | Time: 4.42s\n",
      "      Batch: 256 | Accuracy: 0.8000 | Time: 4.49s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | Accuracy: 0.5667 | Time: 3.98s\n",
      "      Batch: 32  | Accuracy: 0.7333 | Time: 3.55s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 4.60s\n",
      "      Batch: 128 | Accuracy: 0.7333 | Time: 4.56s\n",
      "      Batch: 256 | Accuracy: 0.7333 | Time: 4.34s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 6.34s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 6.45s\n",
      "      Batch: 64  | Accuracy: 0.4667 | Time: 4.16s\n",
      "      Batch: 128 | Accuracy: 0.5333 | Time: 7.43s\n",
      "      Batch: 256 | Accuracy: 0.6667 | Time: 6.21s\n",
      "  Dataset: Wine (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.8889 | Time: 6.12s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 10.37s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 7.01s\n",
      "      Batch: 128 | Accuracy: 0.9167 | Time: 6.14s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 7.16s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 6.75s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 5.71s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 6.18s\n",
      "      Batch: 128 | Accuracy: 0.9722 | Time: 5.93s\n",
      "      Batch: 256 | Accuracy: 0.9722 | Time: 6.32s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 5.20s\n",
      "      Batch: 32  | Accuracy: 1.0000 | Time: 5.55s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 5.98s\n",
      "      Batch: 128 | Accuracy: 0.8889 | Time: 5.89s\n",
      "      Batch: 256 | Accuracy: 0.8056 | Time: 5.25s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 5.52s\n",
      "      Batch: 32  | Accuracy: 0.9167 | Time: 5.34s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 5.57s\n",
      "      Batch: 128 | Accuracy: 0.7500 | Time: 5.02s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 5.00s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 4.87s\n",
      "      Batch: 32  | Accuracy: 0.8056 | Time: 8.65s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 5.73s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 5.45s\n",
      "      Batch: 256 | Accuracy: 0.9444 | Time: 6.95s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 5.84s\n",
      "      Batch: 32  | Accuracy: 0.8889 | Time: 5.84s\n",
      "      Batch: 64  | Accuracy: 0.8611 | Time: 6.80s\n",
      "      Batch: 128 | Accuracy: 0.6389 | Time: 4.94s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 7.41s\n",
      "  Dataset: Diabetes (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 42.9981 | Time: 13.35s\n",
      "      Batch: 32  | MAE: 43.0661 | Time: 17.45s\n",
      "      Batch: 64  | MAE: 44.6964 | Time: 19.25s\n",
      "      Batch: 128 | MAE: 54.6586 | Time: 17.75s\n",
      "      Batch: 256 | MAE: 90.5589 | Time: 17.55s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 42.8496 | Time: 13.81s\n",
      "      Batch: 32  | MAE: 42.4727 | Time: 18.13s\n",
      "      Batch: 64  | MAE: 43.5260 | Time: 19.53s\n",
      "      Batch: 128 | MAE: 59.9889 | Time: 18.29s\n",
      "      Batch: 256 | MAE: 87.8745 | Time: 18.33s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 47.0102 | Time: 13.94s\n",
      "      Batch: 32  | MAE: 47.2361 | Time: 19.05s\n",
      "      Batch: 64  | MAE: 67.6820 | Time: 18.28s\n",
      "      Batch: 128 | MAE: 76.8398 | Time: 24.00s\n",
      "      Batch: 256 | MAE: 114.4991 | Time: 17.92s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 42.5806 | Time: 22.88s\n",
      "      Batch: 32  | MAE: 45.0363 | Time: 20.38s\n",
      "      Batch: 64  | MAE: 50.8410 | Time: 18.37s\n",
      "      Batch: 128 | MAE: 64.4591 | Time: 16.81s\n",
      "      Batch: 256 | MAE: 86.9740 | Time: 16.46s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 44.5737 | Time: 18.10s\n",
      "      Batch: 32  | MAE: 44.8725 | Time: 19.51s\n",
      "      Batch: 64  | MAE: 53.3579 | Time: 17.57s\n",
      "      Batch: 128 | MAE: 62.5926 | Time: 16.52s\n",
      "      Batch: 256 | MAE: 89.7280 | Time: 15.99s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 49.8609 | Time: 13.51s\n",
      "      Batch: 32  | MAE: 48.0567 | Time: 18.30s\n",
      "      Batch: 64  | MAE: 52.6539 | Time: 18.04s\n",
      "      Batch: 128 | MAE: 64.3650 | Time: 16.78s\n",
      "      Batch: 256 | MAE: 75.6846 | Time: 16.38s\n",
      "  Dataset: California Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 0.3618 | Time: 350.31s\n",
      "      Batch: 32  | MAE: 0.3636 | Time: 212.62s\n",
      "      Batch: 64  | MAE: 0.3625 | Time: 117.52s\n",
      "      Batch: 128 | MAE: 0.3706 | Time: 68.13s\n",
      "      Batch: 256 | MAE: 0.3850 | Time: 42.33s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 0.3628 | Time: 414.70s\n",
      "      Batch: 32  | MAE: 0.3670 | Time: 219.09s\n",
      "      Batch: 64  | MAE: 0.3706 | Time: 116.83s\n",
      "      Batch: 128 | MAE: 0.3783 | Time: 75.90s\n",
      "      Batch: 256 | MAE: 0.3855 | Time: 44.07s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 0.3868 | Time: 402.46s\n",
      "      Batch: 32  | MAE: 0.3971 | Time: 162.21s\n",
      "      Batch: 64  | MAE: 0.3927 | Time: 115.01s\n",
      "      Batch: 128 | MAE: 0.4003 | Time: 64.95s\n",
      "      Batch: 256 | MAE: 0.4083 | Time: 40.66s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 0.3588 | Time: 406.49s\n",
      "      Batch: 32  | MAE: 0.3594 | Time: 211.14s\n",
      "      Batch: 64  | MAE: 0.3637 | Time: 110.77s\n",
      "      Batch: 128 | MAE: 0.3784 | Time: 65.55s\n",
      "      Batch: 256 | MAE: 0.3860 | Time: 40.40s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 0.3700 | Time: 380.71s\n",
      "      Batch: 32  | MAE: 0.3667 | Time: 199.69s\n",
      "      Batch: 64  | MAE: 0.3699 | Time: 112.28s\n",
      "      Batch: 128 | MAE: 0.3786 | Time: 59.93s\n",
      "      Batch: 256 | MAE: 0.3806 | Time: 41.43s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 0.3896 | Time: 404.15s\n",
      "      Batch: 32  | MAE: 0.3906 | Time: 201.27s\n",
      "      Batch: 64  | MAE: 0.4017 | Time: 114.97s\n",
      "      Batch: 128 | MAE: 0.3960 | Time: 65.77s\n",
      "      Batch: 256 | MAE: 0.4164 | Time: 39.61s\n",
      "\n",
      "--- Running Seed 4/5 (Seed: 45) ---\n",
      "  Dataset: Boston Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 3.4024 | Time: 9.13s\n",
      "      Batch: 32  | MAE: 2.5689 | Time: 24.45s\n",
      "      Batch: 64  | MAE: 2.9308 | Time: 22.03s\n",
      "      Batch: 128 | MAE: 3.5747 | Time: 13.01s\n",
      "      Batch: 256 | MAE: 3.7252 | Time: 17.41s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 2.3121 | Time: 28.51s\n",
      "      Batch: 32  | MAE: 2.3943 | Time: 30.34s\n",
      "      Batch: 64  | MAE: 3.1327 | Time: 21.98s\n",
      "      Batch: 128 | MAE: 4.4692 | Time: 12.33s\n",
      "      Batch: 256 | MAE: 3.9386 | Time: 18.77s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 2.4342 | Time: 26.63s\n",
      "      Batch: 32  | MAE: 2.6720 | Time: 22.39s\n",
      "      Batch: 64  | MAE: 3.4278 | Time: 19.28s\n",
      "      Batch: 128 | MAE: 4.0971 | Time: 17.38s\n",
      "      Batch: 256 | MAE: 4.7304 | Time: 17.18s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 2.5277 | Time: 23.48s\n",
      "      Batch: 32  | MAE: 2.5202 | Time: 21.44s\n",
      "      Batch: 64  | MAE: 3.1562 | Time: 19.23s\n",
      "      Batch: 128 | MAE: 3.8054 | Time: 17.46s\n",
      "      Batch: 256 | MAE: 4.1945 | Time: 17.04s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 2.6668 | Time: 22.39s\n",
      "      Batch: 32  | MAE: 2.7326 | Time: 21.40s\n",
      "      Batch: 64  | MAE: 3.0032 | Time: 19.00s\n",
      "      Batch: 128 | MAE: 3.8349 | Time: 17.48s\n",
      "      Batch: 256 | MAE: 4.5007 | Time: 16.92s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 2.6095 | Time: 22.34s\n",
      "      Batch: 32  | MAE: 3.2671 | Time: 12.39s\n",
      "      Batch: 64  | MAE: 3.1930 | Time: 19.73s\n",
      "      Batch: 128 | MAE: 4.0429 | Time: 17.74s\n",
      "      Batch: 256 | MAE: 4.8275 | Time: 18.00s\n",
      "  Dataset: Iris (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.9667 | Time: 8.98s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 7.18s\n",
      "      Batch: 64  | Accuracy: 0.6000 | Time: 5.52s\n",
      "      Batch: 128 | Accuracy: 0.7333 | Time: 7.24s\n",
      "      Batch: 256 | Accuracy: 0.6667 | Time: 11.11s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.8667 | Time: 8.95s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 5.18s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 6.07s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 5.86s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 6.50s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 4.27s\n",
      "      Batch: 32  | Accuracy: 0.6333 | Time: 4.11s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 5.59s\n",
      "      Batch: 128 | Accuracy: 0.5333 | Time: 5.05s\n",
      "      Batch: 256 | Accuracy: 0.7333 | Time: 3.91s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 6.58s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 6.19s\n",
      "      Batch: 64  | Accuracy: 0.7000 | Time: 4.44s\n",
      "      Batch: 128 | Accuracy: 0.8000 | Time: 6.09s\n",
      "      Batch: 256 | Accuracy: 0.3333 | Time: 7.55s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | Accuracy: 0.7333 | Time: 5.59s\n",
      "      Batch: 32  | Accuracy: 0.7333 | Time: 4.50s\n",
      "      Batch: 64  | Accuracy: 0.7000 | Time: 5.70s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 4.89s\n",
      "      Batch: 256 | Accuracy: 0.6333 | Time: 4.26s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | Accuracy: 0.7000 | Time: 4.43s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 6.10s\n",
      "      Batch: 64  | Accuracy: 0.5000 | Time: 4.66s\n",
      "      Batch: 128 | Accuracy: 0.6333 | Time: 4.69s\n",
      "      Batch: 256 | Accuracy: 0.4000 | Time: 4.64s\n",
      "  Dataset: Wine (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 7.47s\n",
      "      Batch: 32  | Accuracy: 0.8889 | Time: 6.59s\n",
      "      Batch: 64  | Accuracy: 0.9722 | Time: 7.14s\n",
      "      Batch: 128 | Accuracy: 0.8889 | Time: 14.58s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 6.46s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.9722 | Time: 7.29s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 6.65s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 7.24s\n",
      "      Batch: 128 | Accuracy: 0.9444 | Time: 6.44s\n",
      "      Batch: 256 | Accuracy: 0.8333 | Time: 7.40s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | Accuracy: 0.9722 | Time: 5.45s\n",
      "      Batch: 32  | Accuracy: 0.8611 | Time: 5.10s\n",
      "      Batch: 64  | Accuracy: 0.9444 | Time: 6.68s\n",
      "      Batch: 128 | Accuracy: 0.8889 | Time: 6.90s\n",
      "      Batch: 256 | Accuracy: 0.8333 | Time: 5.40s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 5.90s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 7.09s\n",
      "      Batch: 64  | Accuracy: 0.8611 | Time: 4.86s\n",
      "      Batch: 128 | Accuracy: 0.8056 | Time: 5.88s\n",
      "      Batch: 256 | Accuracy: 0.6389 | Time: 5.73s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 6.25s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 5.28s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 5.86s\n",
      "      Batch: 128 | Accuracy: 0.9167 | Time: 7.34s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 5.25s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | Accuracy: 0.8611 | Time: 5.83s\n",
      "      Batch: 32  | Accuracy: 0.9167 | Time: 5.72s\n",
      "      Batch: 64  | Accuracy: 0.9444 | Time: 5.80s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 6.98s\n",
      "      Batch: 256 | Accuracy: 0.7778 | Time: 5.32s\n",
      "  Dataset: Diabetes (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 44.6422 | Time: 14.50s\n",
      "      Batch: 32  | MAE: 44.0301 | Time: 18.49s\n",
      "      Batch: 64  | MAE: 45.2033 | Time: 21.09s\n",
      "      Batch: 128 | MAE: 56.4671 | Time: 30.45s\n",
      "      Batch: 256 | MAE: 93.1910 | Time: 20.84s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 42.9454 | Time: 17.06s\n",
      "      Batch: 32  | MAE: 42.6522 | Time: 21.07s\n",
      "      Batch: 64  | MAE: 43.5618 | Time: 21.44s\n",
      "      Batch: 128 | MAE: 66.3287 | Time: 20.22s\n",
      "      Batch: 256 | MAE: 92.2411 | Time: 19.85s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 46.6843 | Time: 15.72s\n",
      "      Batch: 32  | MAE: 47.3802 | Time: 19.13s\n",
      "      Batch: 64  | MAE: 70.2409 | Time: 19.30s\n",
      "      Batch: 128 | MAE: 83.8798 | Time: 17.84s\n",
      "      Batch: 256 | MAE: 114.4916 | Time: 17.55s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 44.6849 | Time: 19.39s\n",
      "      Batch: 32  | MAE: 45.2776 | Time: 21.16s\n",
      "      Batch: 64  | MAE: 50.2747 | Time: 19.35s\n",
      "      Batch: 128 | MAE: 68.5964 | Time: 17.96s\n",
      "      Batch: 256 | MAE: 85.1245 | Time: 17.52s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 43.5251 | Time: 20.21s\n",
      "      Batch: 32  | MAE: 44.5516 | Time: 20.88s\n",
      "      Batch: 64  | MAE: 53.3329 | Time: 19.19s\n",
      "      Batch: 128 | MAE: 62.6821 | Time: 17.71s\n",
      "      Batch: 256 | MAE: 97.8562 | Time: 17.10s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 48.5036 | Time: 15.05s\n",
      "      Batch: 32  | MAE: 49.0194 | Time: 19.15s\n",
      "      Batch: 64  | MAE: 52.7401 | Time: 19.39s\n",
      "      Batch: 128 | MAE: 61.8268 | Time: 18.02s\n",
      "      Batch: 256 | MAE: 73.4543 | Time: 17.67s\n",
      "  Dataset: California Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 0.3612 | Time: 260.48s\n",
      "      Batch: 32  | MAE: 0.3679 | Time: 220.30s\n",
      "      Batch: 64  | MAE: 0.3653 | Time: 120.29s\n",
      "      Batch: 128 | MAE: 0.3739 | Time: 69.29s\n",
      "      Batch: 256 | MAE: 0.3840 | Time: 43.81s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 0.3624 | Time: 424.04s\n",
      "      Batch: 32  | MAE: 0.3716 | Time: 232.60s\n",
      "      Batch: 64  | MAE: 0.3873 | Time: 123.36s\n",
      "      Batch: 128 | MAE: 0.3830 | Time: 71.08s\n",
      "      Batch: 256 | MAE: 0.3886 | Time: 44.47s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 0.3918 | Time: 408.57s\n",
      "      Batch: 32  | MAE: 0.3897 | Time: 213.50s\n",
      "      Batch: 64  | MAE: 0.3986 | Time: 115.27s\n",
      "      Batch: 128 | MAE: 0.4007 | Time: 67.14s\n",
      "      Batch: 256 | MAE: 0.4073 | Time: 42.01s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 0.3633 | Time: 333.98s\n",
      "      Batch: 32  | MAE: 0.3658 | Time: 213.86s\n",
      "      Batch: 64  | MAE: 0.3715 | Time: 115.47s\n",
      "      Batch: 128 | MAE: 0.3746 | Time: 66.49s\n",
      "      Batch: 256 | MAE: 0.3865 | Time: 42.05s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 0.3728 | Time: 395.91s\n",
      "      Batch: 32  | MAE: 0.3780 | Time: 206.70s\n",
      "      Batch: 64  | MAE: 0.3752 | Time: 113.87s\n",
      "      Batch: 128 | MAE: 0.3715 | Time: 63.83s\n",
      "      Batch: 256 | MAE: 0.3807 | Time: 39.89s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 0.3878 | Time: 397.68s\n",
      "      Batch: 32  | MAE: 0.3878 | Time: 208.42s\n",
      "      Batch: 64  | MAE: 0.4066 | Time: 112.22s\n",
      "      Batch: 128 | MAE: 0.4060 | Time: 64.78s\n",
      "      Batch: 256 | MAE: 0.4195 | Time: 40.20s\n",
      "\n",
      "--- Running Seed 5/5 (Seed: 46) ---\n",
      "  Dataset: Boston Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 2.5213 | Time: 30.93s\n",
      "      Batch: 32  | MAE: 3.3455 | Time: 8.42s\n",
      "      Batch: 64  | MAE: 3.4839 | Time: 11.46s\n",
      "      Batch: 128 | MAE: 3.7706 | Time: 13.09s\n",
      "      Batch: 256 | MAE: 3.6606 | Time: 15.01s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 2.2852 | Time: 27.76s\n",
      "      Batch: 32  | MAE: 2.3846 | Time: 22.48s\n",
      "      Batch: 64  | MAE: 2.8514 | Time: 19.99s\n",
      "      Batch: 128 | MAE: 4.1867 | Time: 12.47s\n",
      "      Batch: 256 | MAE: 4.2495 | Time: 27.59s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 2.4480 | Time: 26.01s\n",
      "      Batch: 32  | MAE: 2.6376 | Time: 21.68s\n",
      "      Batch: 64  | MAE: 3.5182 | Time: 19.27s\n",
      "      Batch: 128 | MAE: 4.1326 | Time: 17.62s\n",
      "      Batch: 256 | MAE: 4.7611 | Time: 17.24s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 2.5229 | Time: 19.15s\n",
      "      Batch: 32  | MAE: 2.5498 | Time: 21.12s\n",
      "      Batch: 64  | MAE: 2.9632 | Time: 18.68s\n",
      "      Batch: 128 | MAE: 3.8460 | Time: 17.19s\n",
      "      Batch: 256 | MAE: 4.7180 | Time: 16.58s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 2.6476 | Time: 21.96s\n",
      "      Batch: 32  | MAE: 2.7373 | Time: 20.51s\n",
      "      Batch: 64  | MAE: 3.2103 | Time: 18.20s\n",
      "      Batch: 128 | MAE: 3.7538 | Time: 16.71s\n",
      "      Batch: 256 | MAE: 4.6979 | Time: 16.26s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 2.7849 | Time: 15.25s\n",
      "      Batch: 32  | MAE: 2.7551 | Time: 20.68s\n",
      "      Batch: 64  | MAE: 2.9111 | Time: 18.55s\n",
      "      Batch: 128 | MAE: 3.9136 | Time: 17.15s\n",
      "      Batch: 256 | MAE: 5.2884 | Time: 16.98s\n",
      "  Dataset: Iris (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.9000 | Time: 6.96s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 5.73s\n",
      "      Batch: 64  | Accuracy: 0.8333 | Time: 6.11s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 7.97s\n",
      "      Batch: 256 | Accuracy: 0.7333 | Time: 7.51s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 5.96s\n",
      "      Batch: 32  | Accuracy: 0.7333 | Time: 5.97s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 6.68s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 5.43s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 5.17s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | Accuracy: 0.8333 | Time: 4.40s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 5.29s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 4.50s\n",
      "      Batch: 128 | Accuracy: 0.8000 | Time: 4.04s\n",
      "      Batch: 256 | Accuracy: 0.7333 | Time: 5.07s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | Accuracy: 0.6333 | Time: 4.26s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 4.61s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 12.72s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 5.21s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 4.00s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 5.42s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 4.73s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 6.14s\n",
      "      Batch: 128 | Accuracy: 0.6333 | Time: 4.78s\n",
      "      Batch: 256 | Accuracy: 0.6333 | Time: 4.38s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | Accuracy: 0.6667 | Time: 4.98s\n",
      "      Batch: 32  | Accuracy: 0.5333 | Time: 4.24s\n",
      "      Batch: 64  | Accuracy: 0.6000 | Time: 4.88s\n",
      "      Batch: 128 | Accuracy: 0.3333 | Time: 5.13s\n",
      "      Batch: 256 | Accuracy: 0.6000 | Time: 4.82s\n",
      "  Dataset: Wine (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.8611 | Time: 6.20s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 6.11s\n",
      "      Batch: 64  | Accuracy: 0.9722 | Time: 6.29s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 5.95s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 5.94s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 6.27s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 6.10s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 6.18s\n",
      "      Batch: 128 | Accuracy: 0.8889 | Time: 7.72s\n",
      "      Batch: 256 | Accuracy: 0.8333 | Time: 5.26s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 5.47s\n",
      "      Batch: 32  | Accuracy: 0.8889 | Time: 4.98s\n",
      "      Batch: 64  | Accuracy: 0.8611 | Time: 4.89s\n",
      "      Batch: 128 | Accuracy: 0.9444 | Time: 5.66s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 6.58s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 5.19s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 5.36s\n",
      "      Batch: 64  | Accuracy: 0.8333 | Time: 5.81s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 4.91s\n",
      "      Batch: 256 | Accuracy: 0.8056 | Time: 6.65s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 4.83s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 4.48s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 5.39s\n",
      "      Batch: 128 | Accuracy: 0.9167 | Time: 5.30s\n",
      "      Batch: 256 | Accuracy: 0.8889 | Time: 5.59s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 13.69s\n",
      "      Batch: 32  | Accuracy: 0.9167 | Time: 6.03s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 7.12s\n",
      "      Batch: 128 | Accuracy: 0.9167 | Time: 7.46s\n",
      "      Batch: 256 | Accuracy: 0.8333 | Time: 6.21s\n",
      "  Dataset: Diabetes (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 43.5416 | Time: 14.19s\n",
      "      Batch: 32  | MAE: 43.1469 | Time: 18.15s\n",
      "      Batch: 64  | MAE: 45.2877 | Time: 20.34s\n",
      "      Batch: 128 | MAE: 54.2612 | Time: 18.46s\n",
      "      Batch: 256 | MAE: 92.0737 | Time: 18.11s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 42.1082 | Time: 16.84s\n",
      "      Batch: 32  | MAE: 43.8226 | Time: 18.01s\n",
      "      Batch: 64  | MAE: 45.4369 | Time: 19.83s\n",
      "      Batch: 128 | MAE: 69.9444 | Time: 18.40s\n",
      "      Batch: 256 | MAE: 91.8497 | Time: 17.97s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 47.1919 | Time: 13.97s\n",
      "      Batch: 32  | MAE: 47.2218 | Time: 18.22s\n",
      "      Batch: 64  | MAE: 69.5654 | Time: 18.08s\n",
      "      Batch: 128 | MAE: 81.8004 | Time: 17.00s\n",
      "      Batch: 256 | MAE: 117.1451 | Time: 16.50s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 43.6084 | Time: 20.68s\n",
      "      Batch: 32  | MAE: 45.4069 | Time: 20.46s\n",
      "      Batch: 64  | MAE: 55.4586 | Time: 18.33s\n",
      "      Batch: 128 | MAE: 69.5593 | Time: 17.20s\n",
      "      Batch: 256 | MAE: 88.9790 | Time: 16.79s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 43.2879 | Time: 20.98s\n",
      "      Batch: 32  | MAE: 47.4292 | Time: 19.73s\n",
      "      Batch: 64  | MAE: 55.3182 | Time: 18.10s\n",
      "      Batch: 128 | MAE: 62.1688 | Time: 16.90s\n",
      "      Batch: 256 | MAE: 93.2202 | Time: 16.35s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 49.6346 | Time: 13.85s\n",
      "      Batch: 32  | MAE: 49.8994 | Time: 17.10s\n",
      "      Batch: 64  | MAE: 53.9825 | Time: 18.40s\n",
      "      Batch: 128 | MAE: 66.2979 | Time: 16.98s\n",
      "      Batch: 256 | MAE: 75.0309 | Time: 16.63s\n",
      "  Dataset: California Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 0.3597 | Time: 261.38s\n",
      "      Batch: 32  | MAE: 0.3629 | Time: 215.46s\n",
      "      Batch: 64  | MAE: 0.3666 | Time: 116.17s\n",
      "      Batch: 128 | MAE: 0.3748 | Time: 66.64s\n",
      "      Batch: 256 | MAE: 0.3811 | Time: 42.05s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 0.3604 | Time: 430.00s\n",
      "      Batch: 32  | MAE: 0.3745 | Time: 219.95s\n",
      "      Batch: 64  | MAE: 0.3732 | Time: 118.19s\n",
      "      Batch: 128 | MAE: 0.3826 | Time: 67.53s\n",
      "      Batch: 256 | MAE: 0.3883 | Time: 42.14s\n",
      "    Activation: AdaptiveMish\n",
      "      Batch: 16  | MAE: 0.3830 | Time: 400.47s\n",
      "      Batch: 32  | MAE: 0.3875 | Time: 207.81s\n",
      "      Batch: 64  | MAE: 0.3955 | Time: 113.28s\n",
      "      Batch: 128 | MAE: 0.3968 | Time: 65.55s\n",
      "      Batch: 256 | MAE: 0.4098 | Time: 40.19s\n",
      "    Activation: AdaptiveSwish\n",
      "      Batch: 16  | MAE: 0.3561 | Time: 398.31s\n",
      "      Batch: 32  | MAE: 0.3587 | Time: 207.22s\n",
      "      Batch: 64  | MAE: 0.3647 | Time: 111.61s\n",
      "      Batch: 128 | MAE: 0.3753 | Time: 63.97s\n",
      "      Batch: 256 | MAE: 0.3888 | Time: 39.67s\n",
      "    Activation: PReLU\n",
      "      Batch: 16  | MAE: 0.3744 | Time: 352.43s\n",
      "      Batch: 32  | MAE: 0.3785 | Time: 167.95s\n",
      "      Batch: 64  | MAE: 0.3752 | Time: 110.62s\n",
      "      Batch: 128 | MAE: 0.3800 | Time: 62.91s\n",
      "      Batch: 256 | MAE: 0.3777 | Time: 38.97s\n",
      "    Activation: LiSHT\n",
      "      Batch: 16  | MAE: 0.3950 | Time: 228.63s\n",
      "      Batch: 32  | MAE: 0.3904 | Time: 205.21s\n",
      "      Batch: 64  | MAE: 0.3984 | Time: 111.39s\n",
      "      Batch: 128 | MAE: 0.4003 | Time: 63.15s\n",
      "      Batch: 256 | MAE: 0.4087 | Time: 39.24s\n",
      "\n",
      "--- Experiment Finished ---\n",
      "Total time: 30909.67 seconds (515.16 minutes)\n"
     ]
    }
   ],
   "source": [
    "# --- Activation Functions Dictionary ---\n",
    "# We need to instantiate custom layers inside the loop later,\n",
    "# so we store either the class or string name here.\n",
    "activations_to_test = {\n",
    "    'OptimA': OptimA,\n",
    "    'OptimALinear': OptimALinear,\n",
    "    'AdaptiveMish': AdaptiveMish,\n",
    "    'AdaptiveSwish': AdaptiveSwish,\n",
    "    'PReLU': PReLU,\n",
    "    'LiSHT': LiSHT\n",
    "}\n",
    "\n",
    "# --- Results Storage ---\n",
    "# Structure: results[dataset_name][activation_name][batch_size] = [list_of_scores_from_seeds]\n",
    "results = {\n",
    "    ds_name: {\n",
    "        act_name: {\n",
    "            bs: [] for bs in BATCH_SIZES\n",
    "        } for act_name in activations_to_test.keys()\n",
    "    } for ds_name in datasets_config.keys()\n",
    "}\n",
    "\n",
    "# --- Main Experiment Loop ---\n",
    "print(\"\\n--- Starting Experiment ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"\\n--- Running Seed {i+1}/{N_SEEDS} (Seed: {seed}) ---\")\n",
    "    set_seed(seed) # Set seed for this specific run's TF/Numpy operations\n",
    "\n",
    "    for ds_name, ds_config in datasets_config.items():\n",
    "        print(f\"  Dataset: {ds_name} ({ds_config['task_type']})\")\n",
    "        x_train, y_train, x_test, y_test = ds_config['data']\n",
    "        task_type = ds_config['task_type']\n",
    "        metric_name = ds_config['metric_name']\n",
    "\n",
    "        for act_name, activation_ref in activations_to_test.items():\n",
    "            print(f\"    Activation: {act_name}\")\n",
    "\n",
    "            for bs in BATCH_SIZES:\n",
    "                # print(f\"      Batch Size: {bs} ... \", end=\"\")\n",
    "                run_start_time = time.time()\n",
    "\n",
    "                # Instantiate custom layers here for each trial to reset their state\n",
    "                if activation_ref == OptimA:\n",
    "                    activation_instance = OptimA()\n",
    "                elif activation_ref == OptimALinear:\n",
    "                    activation_instance = OptimALinear()\n",
    "                elif activation_ref == AdaptiveSwish:\n",
    "                    activation_instance = AdaptiveSwish()\n",
    "                elif activation_ref == PReLU:\n",
    "                    activation_instance = PReLU()\n",
    "                elif activation_ref == LiSHT:\n",
    "                    activation_instance = LiSHT()\n",
    "                elif activation_ref == AdaptiveMish:\n",
    "                    activation_instance = AdaptiveMish()\n",
    "                else:\n",
    "                    activation_instance = activation_ref # Use string name directly\n",
    "\n",
    "                # Build, train, and evaluate\n",
    "                score = build_and_evaluate_model(\n",
    "                    x_train, y_train, x_test, y_test,\n",
    "                    activation_instance=activation_instance,\n",
    "                    task_type=task_type,\n",
    "                    batch_size=bs\n",
    "                )\n",
    "\n",
    "                run_end_time = time.time()\n",
    "                run_duration = run_end_time - run_start_time\n",
    "\n",
    "                # Store the result\n",
    "                results[ds_name][act_name][bs].append(score)\n",
    "\n",
    "                # Print result for this run\n",
    "                if not np.isnan(score):\n",
    "                    # print(f\"Score ({metric_name}): {score:.4f} (Time: {run_duration:.2f}s)\")\n",
    "                     print(f\"      Batch: {bs:<3} | {metric_name}: {score:.4f} | Time: {run_duration:.2f}s\")\n",
    "                else:\n",
    "                    # print(\"Failed.\")\n",
    "                     print(f\"      Batch: {bs:<3} | Failed.\")\n",
    "\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "print(f\"\\n--- Experiment Finished ---\")\n",
    "print(f\"Total time: {total_duration:.2f} seconds ({total_duration/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a55e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:25:58.091337Z",
     "iopub.status.busy": "2025-05-14T18:25:58.090633Z",
     "iopub.status.idle": "2025-05-14T18:25:58.140596Z",
     "shell.execute_reply": "2025-05-14T18:25:58.140048Z"
    },
    "papermill": {
     "duration": 0.082396,
     "end_time": "2025-05-14T18:25:58.141653",
     "exception": false,
     "start_time": "2025-05-14T18:25:58.059257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Results ---\n",
      "\n",
      "--- Aggregated Results Table ---\n",
      "Metrics averaged over 5 seeds.\n",
      "Note: 'Best' means highest Accuracy for Classification, lowest MAE for Regression.\n"
     ]
    }
   ],
   "source": [
    "# --- Process and Display Results ---\n",
    "print(\"\\n--- Processing Results ---\")\n",
    "\n",
    "processed_results = []\n",
    "\n",
    "for ds_name, ds_results in results.items():\n",
    "    task_type = datasets_config[ds_name]['task_type']\n",
    "    metric_name = datasets_config[ds_name]['metric_name']\n",
    "    # Determine if higher score is better (classification) or lower is better (regression)\n",
    "    higher_is_better = (task_type == 'classification')\n",
    "\n",
    "    for act_name, act_results in ds_results.items():\n",
    "        for bs, scores in act_results.items():\n",
    "            valid_scores = [s for s in scores if not np.isnan(s)] # Filter out NaNs\n",
    "            if not valid_scores:\n",
    "                mean_score, best_score, worst_score = np.nan, np.nan, np.nan\n",
    "                num_successful_runs = 0\n",
    "            else:\n",
    "                mean_score = np.mean(valid_scores)\n",
    "                num_successful_runs = len(valid_scores)\n",
    "                if higher_is_better:\n",
    "                    best_score = np.max(valid_scores)\n",
    "                    worst_score = np.min(valid_scores)\n",
    "                else: # Lower is better (MAE)\n",
    "                    best_score = np.min(valid_scores)\n",
    "                    worst_score = np.max(valid_scores)\n",
    "\n",
    "            processed_results.append({\n",
    "                'Dataset': ds_name,\n",
    "                'Activation': act_name,\n",
    "                'Batch Size': bs,\n",
    "                f'Mean {metric_name}': mean_score,\n",
    "                f'Best {metric_name}': best_score,\n",
    "                f'Worst {metric_name}': worst_score,\n",
    "                'Successful Runs': f\"{num_successful_runs}/{N_SEEDS}\"\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(processed_results)\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"\\n--- Aggregated Results Table ---\")\n",
    "print(f\"Metrics averaged over {N_SEEDS} seeds.\")\n",
    "print(f\"Note: 'Best' means highest Accuracy for Classification, lowest MAE for Regression.\")\n",
    "\n",
    "# Display sorted results (e.g., by Dataset, then Mean Score)\n",
    "# Adjust sorting based on what comparison is most important\n",
    "# Example: Sort by Dataset, then Activation, then Batch Size\n",
    "results_df_sorted = results_df.sort_values(by=['Dataset', 'Activation', 'Batch Size'])\n",
    "\n",
    "# Or sort to find the best performing overall (example for classification)\n",
    "# results_df_sorted = results_df.sort_values(by=['Mean Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd4186f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:25:58.202808Z",
     "iopub.status.busy": "2025-05-14T18:25:58.202398Z",
     "iopub.status.idle": "2025-05-14T18:25:58.216661Z",
     "shell.execute_reply": "2025-05-14T18:25:58.216057Z"
    },
    "papermill": {
     "duration": 0.045966,
     "end_time": "2025-05-14T18:25:58.217879",
     "exception": false,
     "start_time": "2025-05-14T18:25:58.171913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Dataset    Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "    Boston Housing  AdaptiveMish          16    2.4873    2.4342     2.5419             5/5            NaN            NaN             NaN\n",
      "    Boston Housing  AdaptiveMish          32    2.6799    2.6376     2.7648             5/5            NaN            NaN             NaN\n",
      "    Boston Housing  AdaptiveMish          64    3.3584    3.2224     3.5182             5/5            NaN            NaN             NaN\n",
      "    Boston Housing  AdaptiveMish         128    4.0801    3.9947     4.1652             5/5            NaN            NaN             NaN\n",
      "    Boston Housing  AdaptiveMish         256    4.7341    4.5953     4.9218             5/5            NaN            NaN             NaN\n",
      "    Boston Housing AdaptiveSwish          16    2.5725    2.5229     2.6269             5/5            NaN            NaN             NaN\n",
      "    Boston Housing AdaptiveSwish          32    2.5841    2.5202     2.6536             5/5            NaN            NaN             NaN\n",
      "    Boston Housing AdaptiveSwish          64    3.0236    2.8696     3.1562             5/5            NaN            NaN             NaN\n",
      "    Boston Housing AdaptiveSwish         128    3.8030    3.7013     3.9017             5/5            NaN            NaN             NaN\n",
      "    Boston Housing AdaptiveSwish         256    4.3527    4.1945     4.7180             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         LiSHT          16    2.6626    2.5222     2.8092             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         LiSHT          32    2.7788    2.5399     3.2671             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         LiSHT          64    3.0432    2.9111     3.1930             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         LiSHT         128    3.8705    3.5936     4.0429             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         LiSHT         256    5.0634    4.8275     5.2884             5/5            NaN            NaN             NaN\n",
      "    Boston Housing        OptimA          16    2.9660    2.5213     3.4092             5/5            NaN            NaN             NaN\n",
      "    Boston Housing        OptimA          32    3.0188    2.5689     3.3732             5/5            NaN            NaN             NaN\n",
      "    Boston Housing        OptimA          64    3.2646    2.9308     3.5091             5/5            NaN            NaN             NaN\n",
      "    Boston Housing        OptimA         128    3.6405    3.4900     3.7893             5/5            NaN            NaN             NaN\n",
      "    Boston Housing        OptimA         256    3.6962    3.4773     3.8935             5/5            NaN            NaN             NaN\n",
      "    Boston Housing  OptimALinear          16    2.3372    2.2852     2.4011             5/5            NaN            NaN             NaN\n",
      "    Boston Housing  OptimALinear          32    2.5607    2.3846     3.2143             5/5            NaN            NaN             NaN\n",
      "    Boston Housing  OptimALinear          64    2.8702    2.6273     3.1327             5/5            NaN            NaN             NaN\n",
      "    Boston Housing  OptimALinear         128    4.2913    4.1792     4.4692             5/5            NaN            NaN             NaN\n",
      "    Boston Housing  OptimALinear         256    3.9851    3.7108     4.2495             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         PReLU          16    2.6998    2.6476     2.7718             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         PReLU          32    2.7428    2.6781     2.8661             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         PReLU          64    3.1517    3.0032     3.2878             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         PReLU         128    3.7885    3.7041     3.8614             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         PReLU         256    4.5465    4.4139     4.6979             5/5            NaN            NaN             NaN\n",
      "California Housing  AdaptiveMish          16    0.3882    0.3830     0.3918             5/5            NaN            NaN             NaN\n",
      "California Housing  AdaptiveMish          32    0.3912    0.3875     0.3971             5/5            NaN            NaN             NaN\n",
      "California Housing  AdaptiveMish          64    0.3958    0.3927     0.3986             5/5            NaN            NaN             NaN\n",
      "California Housing  AdaptiveMish         128    0.4008    0.3968     0.4039             5/5            NaN            NaN             NaN\n",
      "California Housing  AdaptiveMish         256    0.4090    0.4073     0.4107             5/5            NaN            NaN             NaN\n",
      "California Housing AdaptiveSwish          16    0.3595    0.3561     0.3633             5/5            NaN            NaN             NaN\n",
      "California Housing AdaptiveSwish          32    0.3618    0.3587     0.3659             5/5            NaN            NaN             NaN\n",
      "California Housing AdaptiveSwish          64    0.3665    0.3637     0.3715             5/5            NaN            NaN             NaN\n",
      "California Housing AdaptiveSwish         128    0.3755    0.3744     0.3784             5/5            NaN            NaN             NaN\n",
      "California Housing AdaptiveSwish         256    0.3891    0.3860     0.3932             5/5            NaN            NaN             NaN\n",
      "California Housing         LiSHT          16    0.3934    0.3878     0.4069             5/5            NaN            NaN             NaN\n",
      "California Housing         LiSHT          32    0.3929    0.3878     0.4060             5/5            NaN            NaN             NaN\n",
      "California Housing         LiSHT          64    0.4060    0.3965     0.4266             5/5            NaN            NaN             NaN\n",
      "California Housing         LiSHT         128    0.4033    0.3960     0.4126             5/5            NaN            NaN             NaN\n",
      "California Housing         LiSHT         256    0.4168    0.4087     0.4288             5/5            NaN            NaN             NaN\n",
      "California Housing        OptimA          16    0.3606    0.3580     0.3624             5/5            NaN            NaN             NaN\n",
      "California Housing        OptimA          32    0.3651    0.3623     0.3688             5/5            NaN            NaN             NaN\n",
      "California Housing        OptimA          64    0.3675    0.3625     0.3740             5/5            NaN            NaN             NaN\n",
      "California Housing        OptimA         128    0.3733    0.3702     0.3770             5/5            NaN            NaN             NaN\n",
      "California Housing        OptimA         256    0.3853    0.3811     0.3924             5/5            NaN            NaN             NaN\n",
      "California Housing  OptimALinear          16    0.3634    0.3604     0.3697             5/5            NaN            NaN             NaN\n",
      "California Housing  OptimALinear          32    0.3731    0.3670     0.3845             5/5            NaN            NaN             NaN\n",
      "California Housing  OptimALinear          64    0.3790    0.3706     0.3873             5/5            NaN            NaN             NaN\n",
      "California Housing  OptimALinear         128    0.3829    0.3783     0.3902             5/5            NaN            NaN             NaN\n",
      "California Housing  OptimALinear         256    0.3876    0.3848     0.3908             5/5            NaN            NaN             NaN\n",
      "California Housing         PReLU          16    0.3701    0.3647     0.3744             5/5            NaN            NaN             NaN\n",
      "California Housing         PReLU          32    0.3756    0.3667     0.3832             5/5            NaN            NaN             NaN\n",
      "California Housing         PReLU          64    0.3768    0.3699     0.3837             5/5            NaN            NaN             NaN\n",
      "California Housing         PReLU         128    0.3785    0.3715     0.3825             5/5            NaN            NaN             NaN\n",
      "California Housing         PReLU         256    0.3790    0.3776     0.3807             5/5            NaN            NaN             NaN\n",
      "          Diabetes  AdaptiveMish          16   47.0647   46.6843    47.2215             5/5            NaN            NaN             NaN\n",
      "          Diabetes  AdaptiveMish          32   47.0982   46.2702    47.3828             5/5            NaN            NaN             NaN\n",
      "          Diabetes  AdaptiveMish          64   66.3889   60.2986    70.2409             5/5            NaN            NaN             NaN\n",
      "          Diabetes  AdaptiveMish         128   82.9994   76.8398    87.2754             5/5            NaN            NaN             NaN\n",
      "          Diabetes  AdaptiveMish         256  116.3599  114.4916   120.0037             5/5            NaN            NaN             NaN\n",
      "          Diabetes AdaptiveSwish          16   43.5190   42.5806    44.6849             5/5            NaN            NaN             NaN\n",
      "          Diabetes AdaptiveSwish          32   45.4515   45.0363    45.8041             5/5            NaN            NaN             NaN\n",
      "          Diabetes AdaptiveSwish          64   51.7183   50.2747    55.4586             5/5            NaN            NaN             NaN\n",
      "          Diabetes AdaptiveSwish         128   69.4707   64.4591    72.7083             5/5            NaN            NaN             NaN\n",
      "          Diabetes AdaptiveSwish         256   88.0154   84.5821    94.4172             5/5            NaN            NaN             NaN\n",
      "          Diabetes         LiSHT          16   48.7932   47.1102    49.8609             5/5            NaN            NaN             NaN\n",
      "          Diabetes         LiSHT          32   49.1108   48.0567    49.8994             5/5            NaN            NaN             NaN\n",
      "          Diabetes         LiSHT          64   53.2773   50.8428    56.1672             5/5            NaN            NaN             NaN\n",
      "          Diabetes         LiSHT         128   64.8945   61.8268    67.9969             5/5            NaN            NaN             NaN\n",
      "          Diabetes         LiSHT         256   75.0651   73.4543    76.7156             5/5            NaN            NaN             NaN\n",
      "          Diabetes        OptimA          16   43.6474   42.9981    44.6422             5/5            NaN            NaN             NaN\n",
      "          Diabetes        OptimA          32   43.7504   43.0661    45.3043             5/5            NaN            NaN             NaN\n",
      "          Diabetes        OptimA          64   45.2514   44.6964    45.6017             5/5            NaN            NaN             NaN\n",
      "          Diabetes        OptimA         128   56.8893   54.2612    60.1089             5/5            NaN            NaN             NaN\n",
      "          Diabetes        OptimA         256   92.7566   90.5589    95.0172             5/5            NaN            NaN             NaN\n",
      "          Diabetes  OptimALinear          16   42.5475   41.2916    43.5425             5/5            NaN            NaN             NaN\n",
      "          Diabetes  OptimALinear          32   43.0273   41.1215    45.0673             5/5            NaN            NaN             NaN\n",
      "          Diabetes  OptimALinear          64   44.3679   43.5260    45.4369             5/5            NaN            NaN             NaN\n",
      "          Diabetes  OptimALinear         128   68.6067   59.9889    78.1842             5/5            NaN            NaN             NaN\n",
      "          Diabetes  OptimALinear         256  101.6769   87.8745   145.7749             5/5            NaN            NaN             NaN\n",
      "          Diabetes         PReLU          16   44.6081   43.2879    47.9482             5/5            NaN            NaN             NaN\n",
      "          Diabetes         PReLU          32   45.4019   44.5516    47.4292             5/5            NaN            NaN             NaN\n",
      "          Diabetes         PReLU          64   54.4617   53.3329    56.1804             5/5            NaN            NaN             NaN\n",
      "          Diabetes         PReLU         128   61.9782   60.5919    62.6821             5/5            NaN            NaN             NaN\n",
      "          Diabetes         PReLU         256   94.3248   89.7280    98.7002             5/5            NaN            NaN             NaN\n",
      "              Iris  AdaptiveMish          16       NaN       NaN        NaN             5/5         0.8067         0.8667          0.7667\n",
      "              Iris  AdaptiveMish          32       NaN       NaN        NaN             5/5         0.7533         0.8000          0.6333\n",
      "              Iris  AdaptiveMish          64       NaN       NaN        NaN             5/5         0.7333         0.8000          0.6667\n",
      "              Iris  AdaptiveMish         128       NaN       NaN        NaN             5/5         0.6267         0.8000          0.5333\n",
      "              Iris  AdaptiveMish         256       NaN       NaN        NaN             5/5         0.7267         0.8000          0.6333\n",
      "              Iris AdaptiveSwish          16       NaN       NaN        NaN             5/5         0.7533         0.8333          0.6333\n",
      "              Iris AdaptiveSwish          32       NaN       NaN        NaN             5/5         0.7867         0.8000          0.7667\n",
      "              Iris AdaptiveSwish          64       NaN       NaN        NaN             5/5         0.7467         0.8000          0.6667\n",
      "              Iris AdaptiveSwish         128       NaN       NaN        NaN             5/5         0.7400         0.8000          0.6667\n",
      "              Iris AdaptiveSwish         256       NaN       NaN        NaN             5/5         0.6800         0.8000          0.3333\n",
      "              Iris         LiSHT          16       NaN       NaN        NaN             5/5         0.7467         0.8000          0.6667\n",
      "              Iris         LiSHT          32       NaN       NaN        NaN             5/5         0.7267         0.8000          0.5333\n",
      "              Iris         LiSHT          64       NaN       NaN        NaN             5/5         0.5600         0.6667          0.4667\n",
      "              Iris         LiSHT         128       NaN       NaN        NaN             5/5         0.5333         0.6333          0.3333\n",
      "              Iris         LiSHT         256       NaN       NaN        NaN             5/5         0.5533         0.6667          0.4000\n",
      "              Iris        OptimA          16       NaN       NaN        NaN             5/5         0.8533         0.9667          0.8000\n",
      "              Iris        OptimA          32       NaN       NaN        NaN             5/5         0.7733         0.8000          0.6667\n",
      "              Iris        OptimA          64       NaN       NaN        NaN             5/5         0.7467         0.8333          0.6000\n",
      "              Iris        OptimA         128       NaN       NaN        NaN             5/5         0.7600         0.8000          0.7333\n",
      "              Iris        OptimA         256       NaN       NaN        NaN             5/5         0.6400         0.7667          0.3333\n",
      "              Iris  OptimALinear          16       NaN       NaN        NaN             5/5         0.8067         0.9000          0.7333\n",
      "              Iris  OptimALinear          32       NaN       NaN        NaN             5/5         0.7600         0.8333          0.7333\n",
      "              Iris  OptimALinear          64       NaN       NaN        NaN             5/5         0.7733         0.8000          0.7333\n",
      "              Iris  OptimALinear         128       NaN       NaN        NaN             5/5         0.7200         0.7667          0.6000\n",
      "              Iris  OptimALinear         256       NaN       NaN        NaN             5/5         0.6933         0.7667          0.6000\n",
      "              Iris         PReLU          16       NaN       NaN        NaN             5/5         0.7400         0.8000          0.5667\n",
      "              Iris         PReLU          32       NaN       NaN        NaN             5/5         0.7400         0.7667          0.7000\n",
      "              Iris         PReLU          64       NaN       NaN        NaN             5/5         0.7200         0.8000          0.6000\n",
      "              Iris         PReLU         128       NaN       NaN        NaN             5/5         0.7067         0.7667          0.6333\n",
      "              Iris         PReLU         256       NaN       NaN        NaN             5/5         0.6467         0.7333          0.5667\n",
      "              Wine  AdaptiveMish          16       NaN       NaN        NaN             5/5         0.9611         1.0000          0.9167\n",
      "              Wine  AdaptiveMish          32       NaN       NaN        NaN             5/5         0.9278         1.0000          0.8611\n",
      "              Wine  AdaptiveMish          64       NaN       NaN        NaN             5/5         0.9389         1.0000          0.8611\n",
      "              Wine  AdaptiveMish         128       NaN       NaN        NaN             5/5         0.9222         0.9444          0.8889\n",
      "              Wine  AdaptiveMish         256       NaN       NaN        NaN             5/5         0.8500         0.8889          0.8056\n",
      "              Wine AdaptiveSwish          16       NaN       NaN        NaN             5/5         0.9278         0.9444          0.9167\n",
      "              Wine AdaptiveSwish          32       NaN       NaN        NaN             5/5         0.9278         0.9722          0.8611\n",
      "              Wine AdaptiveSwish          64       NaN       NaN        NaN             5/5         0.9111         1.0000          0.8333\n",
      "              Wine AdaptiveSwish         128       NaN       NaN        NaN             5/5         0.8556         0.9722          0.7500\n",
      "              Wine AdaptiveSwish         256       NaN       NaN        NaN             5/5         0.8111         0.9444          0.6389\n",
      "              Wine         LiSHT          16       NaN       NaN        NaN             5/5         0.9111         0.9444          0.8611\n",
      "              Wine         LiSHT          32       NaN       NaN        NaN             5/5         0.9111         0.9722          0.8611\n",
      "              Wine         LiSHT          64       NaN       NaN        NaN             5/5         0.9056         0.9444          0.8611\n",
      "              Wine         LiSHT         128       NaN       NaN        NaN             5/5         0.7722         0.9167          0.6111\n",
      "              Wine         LiSHT         256       NaN       NaN        NaN             5/5         0.8556         0.9167          0.7778\n",
      "              Wine        OptimA          16       NaN       NaN        NaN             5/5         0.9333         1.0000          0.8611\n",
      "              Wine        OptimA          32       NaN       NaN        NaN             5/5         0.9278         0.9722          0.8611\n",
      "              Wine        OptimA          64       NaN       NaN        NaN             5/5         0.9444         0.9722          0.8889\n",
      "              Wine        OptimA         128       NaN       NaN        NaN             5/5         0.8944         0.9444          0.8611\n",
      "              Wine        OptimA         256       NaN       NaN        NaN             5/5         0.9167         0.9722          0.8611\n",
      "              Wine  OptimALinear          16       NaN       NaN        NaN             5/5         0.9722         1.0000          0.9444\n",
      "              Wine  OptimALinear          32       NaN       NaN        NaN             5/5         0.9500         0.9722          0.9167\n",
      "              Wine  OptimALinear          64       NaN       NaN        NaN             5/5         0.9056         0.9167          0.8889\n",
      "              Wine  OptimALinear         128       NaN       NaN        NaN             5/5         0.8944         0.9722          0.8056\n",
      "              Wine  OptimALinear         256       NaN       NaN        NaN             5/5         0.8833         0.9722          0.8333\n",
      "              Wine         PReLU          16       NaN       NaN        NaN             5/5         0.9111         0.9444          0.8333\n",
      "              Wine         PReLU          32       NaN       NaN        NaN             5/5         0.8944         0.9444          0.8056\n",
      "              Wine         PReLU          64       NaN       NaN        NaN             5/5         0.9056         0.9167          0.8889\n",
      "              Wine         PReLU         128       NaN       NaN        NaN             5/5         0.8778         0.9167          0.8333\n",
      "              Wine         PReLU         256       NaN       NaN        NaN             5/5         0.8500         0.9444          0.6944\n"
     ]
    }
   ],
   "source": [
    "print(results_df_sorted.to_string(index=False, float_format=\"%.4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72306649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:25:58.280060Z",
     "iopub.status.busy": "2025-05-14T18:25:58.279551Z",
     "iopub.status.idle": "2025-05-14T18:25:58.303054Z",
     "shell.execute_reply": "2025-05-14T18:25:58.302394Z"
    },
    "papermill": {
     "duration": 0.05545,
     "end_time": "2025-05-14T18:25:58.304212",
     "exception": false,
     "start_time": "2025-05-14T18:25:58.248762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results Grouped by Dataset ---\n",
      "\n",
      "--- Boston Housing ---\n",
      "       Dataset    Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "Boston Housing  OptimALinear          16    2.3372    2.2852     2.4011             5/5            NaN            NaN             NaN\n",
      "Boston Housing  AdaptiveMish          16    2.4873    2.4342     2.5419             5/5            NaN            NaN             NaN\n",
      "Boston Housing  OptimALinear          32    2.5607    2.3846     3.2143             5/5            NaN            NaN             NaN\n",
      "Boston Housing AdaptiveSwish          16    2.5725    2.5229     2.6269             5/5            NaN            NaN             NaN\n",
      "Boston Housing AdaptiveSwish          32    2.5841    2.5202     2.6536             5/5            NaN            NaN             NaN\n",
      "Boston Housing         LiSHT          16    2.6626    2.5222     2.8092             5/5            NaN            NaN             NaN\n",
      "Boston Housing  AdaptiveMish          32    2.6799    2.6376     2.7648             5/5            NaN            NaN             NaN\n",
      "Boston Housing         PReLU          16    2.6998    2.6476     2.7718             5/5            NaN            NaN             NaN\n",
      "Boston Housing         PReLU          32    2.7428    2.6781     2.8661             5/5            NaN            NaN             NaN\n",
      "Boston Housing         LiSHT          32    2.7788    2.5399     3.2671             5/5            NaN            NaN             NaN\n",
      "Boston Housing  OptimALinear          64    2.8702    2.6273     3.1327             5/5            NaN            NaN             NaN\n",
      "Boston Housing        OptimA          16    2.9660    2.5213     3.4092             5/5            NaN            NaN             NaN\n",
      "Boston Housing        OptimA          32    3.0188    2.5689     3.3732             5/5            NaN            NaN             NaN\n",
      "Boston Housing AdaptiveSwish          64    3.0236    2.8696     3.1562             5/5            NaN            NaN             NaN\n",
      "Boston Housing         LiSHT          64    3.0432    2.9111     3.1930             5/5            NaN            NaN             NaN\n",
      "Boston Housing         PReLU          64    3.1517    3.0032     3.2878             5/5            NaN            NaN             NaN\n",
      "Boston Housing        OptimA          64    3.2646    2.9308     3.5091             5/5            NaN            NaN             NaN\n",
      "Boston Housing  AdaptiveMish          64    3.3584    3.2224     3.5182             5/5            NaN            NaN             NaN\n",
      "Boston Housing        OptimA         128    3.6405    3.4900     3.7893             5/5            NaN            NaN             NaN\n",
      "Boston Housing        OptimA         256    3.6962    3.4773     3.8935             5/5            NaN            NaN             NaN\n",
      "Boston Housing         PReLU         128    3.7885    3.7041     3.8614             5/5            NaN            NaN             NaN\n",
      "Boston Housing AdaptiveSwish         128    3.8030    3.7013     3.9017             5/5            NaN            NaN             NaN\n",
      "Boston Housing         LiSHT         128    3.8705    3.5936     4.0429             5/5            NaN            NaN             NaN\n",
      "Boston Housing  OptimALinear         256    3.9851    3.7108     4.2495             5/5            NaN            NaN             NaN\n",
      "Boston Housing  AdaptiveMish         128    4.0801    3.9947     4.1652             5/5            NaN            NaN             NaN\n",
      "Boston Housing  OptimALinear         128    4.2913    4.1792     4.4692             5/5            NaN            NaN             NaN\n",
      "Boston Housing AdaptiveSwish         256    4.3527    4.1945     4.7180             5/5            NaN            NaN             NaN\n",
      "Boston Housing         PReLU         256    4.5465    4.4139     4.6979             5/5            NaN            NaN             NaN\n",
      "Boston Housing  AdaptiveMish         256    4.7341    4.5953     4.9218             5/5            NaN            NaN             NaN\n",
      "Boston Housing         LiSHT         256    5.0634    4.8275     5.2884             5/5            NaN            NaN             NaN\n",
      "\n",
      "--- Iris ---\n",
      "Dataset    Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "   Iris  AdaptiveMish          16       NaN       NaN        NaN             5/5         0.8067         0.8667          0.7667\n",
      "   Iris  AdaptiveMish          32       NaN       NaN        NaN             5/5         0.7533         0.8000          0.6333\n",
      "   Iris  AdaptiveMish          64       NaN       NaN        NaN             5/5         0.7333         0.8000          0.6667\n",
      "   Iris  AdaptiveMish         128       NaN       NaN        NaN             5/5         0.6267         0.8000          0.5333\n",
      "   Iris  AdaptiveMish         256       NaN       NaN        NaN             5/5         0.7267         0.8000          0.6333\n",
      "   Iris AdaptiveSwish          16       NaN       NaN        NaN             5/5         0.7533         0.8333          0.6333\n",
      "   Iris AdaptiveSwish          32       NaN       NaN        NaN             5/5         0.7867         0.8000          0.7667\n",
      "   Iris AdaptiveSwish          64       NaN       NaN        NaN             5/5         0.7467         0.8000          0.6667\n",
      "   Iris AdaptiveSwish         128       NaN       NaN        NaN             5/5         0.7400         0.8000          0.6667\n",
      "   Iris AdaptiveSwish         256       NaN       NaN        NaN             5/5         0.6800         0.8000          0.3333\n",
      "   Iris         LiSHT          16       NaN       NaN        NaN             5/5         0.7467         0.8000          0.6667\n",
      "   Iris         LiSHT          32       NaN       NaN        NaN             5/5         0.7267         0.8000          0.5333\n",
      "   Iris         LiSHT          64       NaN       NaN        NaN             5/5         0.5600         0.6667          0.4667\n",
      "   Iris         LiSHT         128       NaN       NaN        NaN             5/5         0.5333         0.6333          0.3333\n",
      "   Iris         LiSHT         256       NaN       NaN        NaN             5/5         0.5533         0.6667          0.4000\n",
      "   Iris        OptimA          16       NaN       NaN        NaN             5/5         0.8533         0.9667          0.8000\n",
      "   Iris        OptimA          32       NaN       NaN        NaN             5/5         0.7733         0.8000          0.6667\n",
      "   Iris        OptimA          64       NaN       NaN        NaN             5/5         0.7467         0.8333          0.6000\n",
      "   Iris        OptimA         128       NaN       NaN        NaN             5/5         0.7600         0.8000          0.7333\n",
      "   Iris        OptimA         256       NaN       NaN        NaN             5/5         0.6400         0.7667          0.3333\n",
      "   Iris  OptimALinear          16       NaN       NaN        NaN             5/5         0.8067         0.9000          0.7333\n",
      "   Iris  OptimALinear          32       NaN       NaN        NaN             5/5         0.7600         0.8333          0.7333\n",
      "   Iris  OptimALinear          64       NaN       NaN        NaN             5/5         0.7733         0.8000          0.7333\n",
      "   Iris  OptimALinear         128       NaN       NaN        NaN             5/5         0.7200         0.7667          0.6000\n",
      "   Iris  OptimALinear         256       NaN       NaN        NaN             5/5         0.6933         0.7667          0.6000\n",
      "   Iris         PReLU          16       NaN       NaN        NaN             5/5         0.7400         0.8000          0.5667\n",
      "   Iris         PReLU          32       NaN       NaN        NaN             5/5         0.7400         0.7667          0.7000\n",
      "   Iris         PReLU          64       NaN       NaN        NaN             5/5         0.7200         0.8000          0.6000\n",
      "   Iris         PReLU         128       NaN       NaN        NaN             5/5         0.7067         0.7667          0.6333\n",
      "   Iris         PReLU         256       NaN       NaN        NaN             5/5         0.6467         0.7333          0.5667\n",
      "\n",
      "--- Wine ---\n",
      "Dataset    Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "   Wine  AdaptiveMish          16       NaN       NaN        NaN             5/5         0.9611         1.0000          0.9167\n",
      "   Wine  AdaptiveMish          32       NaN       NaN        NaN             5/5         0.9278         1.0000          0.8611\n",
      "   Wine  AdaptiveMish          64       NaN       NaN        NaN             5/5         0.9389         1.0000          0.8611\n",
      "   Wine  AdaptiveMish         128       NaN       NaN        NaN             5/5         0.9222         0.9444          0.8889\n",
      "   Wine  AdaptiveMish         256       NaN       NaN        NaN             5/5         0.8500         0.8889          0.8056\n",
      "   Wine AdaptiveSwish          16       NaN       NaN        NaN             5/5         0.9278         0.9444          0.9167\n",
      "   Wine AdaptiveSwish          32       NaN       NaN        NaN             5/5         0.9278         0.9722          0.8611\n",
      "   Wine AdaptiveSwish          64       NaN       NaN        NaN             5/5         0.9111         1.0000          0.8333\n",
      "   Wine AdaptiveSwish         128       NaN       NaN        NaN             5/5         0.8556         0.9722          0.7500\n",
      "   Wine AdaptiveSwish         256       NaN       NaN        NaN             5/5         0.8111         0.9444          0.6389\n",
      "   Wine         LiSHT          16       NaN       NaN        NaN             5/5         0.9111         0.9444          0.8611\n",
      "   Wine         LiSHT          32       NaN       NaN        NaN             5/5         0.9111         0.9722          0.8611\n",
      "   Wine         LiSHT          64       NaN       NaN        NaN             5/5         0.9056         0.9444          0.8611\n",
      "   Wine         LiSHT         128       NaN       NaN        NaN             5/5         0.7722         0.9167          0.6111\n",
      "   Wine         LiSHT         256       NaN       NaN        NaN             5/5         0.8556         0.9167          0.7778\n",
      "   Wine        OptimA          16       NaN       NaN        NaN             5/5         0.9333         1.0000          0.8611\n",
      "   Wine        OptimA          32       NaN       NaN        NaN             5/5         0.9278         0.9722          0.8611\n",
      "   Wine        OptimA          64       NaN       NaN        NaN             5/5         0.9444         0.9722          0.8889\n",
      "   Wine        OptimA         128       NaN       NaN        NaN             5/5         0.8944         0.9444          0.8611\n",
      "   Wine        OptimA         256       NaN       NaN        NaN             5/5         0.9167         0.9722          0.8611\n",
      "   Wine  OptimALinear          16       NaN       NaN        NaN             5/5         0.9722         1.0000          0.9444\n",
      "   Wine  OptimALinear          32       NaN       NaN        NaN             5/5         0.9500         0.9722          0.9167\n",
      "   Wine  OptimALinear          64       NaN       NaN        NaN             5/5         0.9056         0.9167          0.8889\n",
      "   Wine  OptimALinear         128       NaN       NaN        NaN             5/5         0.8944         0.9722          0.8056\n",
      "   Wine  OptimALinear         256       NaN       NaN        NaN             5/5         0.8833         0.9722          0.8333\n",
      "   Wine         PReLU          16       NaN       NaN        NaN             5/5         0.9111         0.9444          0.8333\n",
      "   Wine         PReLU          32       NaN       NaN        NaN             5/5         0.8944         0.9444          0.8056\n",
      "   Wine         PReLU          64       NaN       NaN        NaN             5/5         0.9056         0.9167          0.8889\n",
      "   Wine         PReLU         128       NaN       NaN        NaN             5/5         0.8778         0.9167          0.8333\n",
      "   Wine         PReLU         256       NaN       NaN        NaN             5/5         0.8500         0.9444          0.6944\n",
      "\n",
      "--- Diabetes ---\n",
      " Dataset    Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "Diabetes  OptimALinear          16   42.5475   41.2916    43.5425             5/5            NaN            NaN             NaN\n",
      "Diabetes  OptimALinear          32   43.0273   41.1215    45.0673             5/5            NaN            NaN             NaN\n",
      "Diabetes AdaptiveSwish          16   43.5190   42.5806    44.6849             5/5            NaN            NaN             NaN\n",
      "Diabetes        OptimA          16   43.6474   42.9981    44.6422             5/5            NaN            NaN             NaN\n",
      "Diabetes        OptimA          32   43.7504   43.0661    45.3043             5/5            NaN            NaN             NaN\n",
      "Diabetes  OptimALinear          64   44.3679   43.5260    45.4369             5/5            NaN            NaN             NaN\n",
      "Diabetes         PReLU          16   44.6081   43.2879    47.9482             5/5            NaN            NaN             NaN\n",
      "Diabetes        OptimA          64   45.2514   44.6964    45.6017             5/5            NaN            NaN             NaN\n",
      "Diabetes         PReLU          32   45.4019   44.5516    47.4292             5/5            NaN            NaN             NaN\n",
      "Diabetes AdaptiveSwish          32   45.4515   45.0363    45.8041             5/5            NaN            NaN             NaN\n",
      "Diabetes  AdaptiveMish          16   47.0647   46.6843    47.2215             5/5            NaN            NaN             NaN\n",
      "Diabetes  AdaptiveMish          32   47.0982   46.2702    47.3828             5/5            NaN            NaN             NaN\n",
      "Diabetes         LiSHT          16   48.7932   47.1102    49.8609             5/5            NaN            NaN             NaN\n",
      "Diabetes         LiSHT          32   49.1108   48.0567    49.8994             5/5            NaN            NaN             NaN\n",
      "Diabetes AdaptiveSwish          64   51.7183   50.2747    55.4586             5/5            NaN            NaN             NaN\n",
      "Diabetes         LiSHT          64   53.2773   50.8428    56.1672             5/5            NaN            NaN             NaN\n",
      "Diabetes         PReLU          64   54.4617   53.3329    56.1804             5/5            NaN            NaN             NaN\n",
      "Diabetes        OptimA         128   56.8893   54.2612    60.1089             5/5            NaN            NaN             NaN\n",
      "Diabetes         PReLU         128   61.9782   60.5919    62.6821             5/5            NaN            NaN             NaN\n",
      "Diabetes         LiSHT         128   64.8945   61.8268    67.9969             5/5            NaN            NaN             NaN\n",
      "Diabetes  AdaptiveMish          64   66.3889   60.2986    70.2409             5/5            NaN            NaN             NaN\n",
      "Diabetes  OptimALinear         128   68.6067   59.9889    78.1842             5/5            NaN            NaN             NaN\n",
      "Diabetes AdaptiveSwish         128   69.4707   64.4591    72.7083             5/5            NaN            NaN             NaN\n",
      "Diabetes         LiSHT         256   75.0651   73.4543    76.7156             5/5            NaN            NaN             NaN\n",
      "Diabetes  AdaptiveMish         128   82.9994   76.8398    87.2754             5/5            NaN            NaN             NaN\n",
      "Diabetes AdaptiveSwish         256   88.0154   84.5821    94.4172             5/5            NaN            NaN             NaN\n",
      "Diabetes        OptimA         256   92.7566   90.5589    95.0172             5/5            NaN            NaN             NaN\n",
      "Diabetes         PReLU         256   94.3248   89.7280    98.7002             5/5            NaN            NaN             NaN\n",
      "Diabetes  OptimALinear         256  101.6769   87.8745   145.7749             5/5            NaN            NaN             NaN\n",
      "Diabetes  AdaptiveMish         256  116.3599  114.4916   120.0037             5/5            NaN            NaN             NaN\n",
      "\n",
      "--- California Housing ---\n",
      "           Dataset    Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "California Housing AdaptiveSwish          16    0.3595    0.3561     0.3633             5/5            NaN            NaN             NaN\n",
      "California Housing        OptimA          16    0.3606    0.3580     0.3624             5/5            NaN            NaN             NaN\n",
      "California Housing AdaptiveSwish          32    0.3618    0.3587     0.3659             5/5            NaN            NaN             NaN\n",
      "California Housing  OptimALinear          16    0.3634    0.3604     0.3697             5/5            NaN            NaN             NaN\n",
      "California Housing        OptimA          32    0.3651    0.3623     0.3688             5/5            NaN            NaN             NaN\n",
      "California Housing AdaptiveSwish          64    0.3665    0.3637     0.3715             5/5            NaN            NaN             NaN\n",
      "California Housing        OptimA          64    0.3675    0.3625     0.3740             5/5            NaN            NaN             NaN\n",
      "California Housing         PReLU          16    0.3701    0.3647     0.3744             5/5            NaN            NaN             NaN\n",
      "California Housing  OptimALinear          32    0.3731    0.3670     0.3845             5/5            NaN            NaN             NaN\n",
      "California Housing        OptimA         128    0.3733    0.3702     0.3770             5/5            NaN            NaN             NaN\n",
      "California Housing AdaptiveSwish         128    0.3755    0.3744     0.3784             5/5            NaN            NaN             NaN\n",
      "California Housing         PReLU          32    0.3756    0.3667     0.3832             5/5            NaN            NaN             NaN\n",
      "California Housing         PReLU          64    0.3768    0.3699     0.3837             5/5            NaN            NaN             NaN\n",
      "California Housing         PReLU         128    0.3785    0.3715     0.3825             5/5            NaN            NaN             NaN\n",
      "California Housing  OptimALinear          64    0.3790    0.3706     0.3873             5/5            NaN            NaN             NaN\n",
      "California Housing         PReLU         256    0.3790    0.3776     0.3807             5/5            NaN            NaN             NaN\n",
      "California Housing  OptimALinear         128    0.3829    0.3783     0.3902             5/5            NaN            NaN             NaN\n",
      "California Housing        OptimA         256    0.3853    0.3811     0.3924             5/5            NaN            NaN             NaN\n",
      "California Housing  OptimALinear         256    0.3876    0.3848     0.3908             5/5            NaN            NaN             NaN\n",
      "California Housing  AdaptiveMish          16    0.3882    0.3830     0.3918             5/5            NaN            NaN             NaN\n",
      "California Housing AdaptiveSwish         256    0.3891    0.3860     0.3932             5/5            NaN            NaN             NaN\n",
      "California Housing  AdaptiveMish          32    0.3912    0.3875     0.3971             5/5            NaN            NaN             NaN\n",
      "California Housing         LiSHT          32    0.3929    0.3878     0.4060             5/5            NaN            NaN             NaN\n",
      "California Housing         LiSHT          16    0.3934    0.3878     0.4069             5/5            NaN            NaN             NaN\n",
      "California Housing  AdaptiveMish          64    0.3958    0.3927     0.3986             5/5            NaN            NaN             NaN\n",
      "California Housing  AdaptiveMish         128    0.4008    0.3968     0.4039             5/5            NaN            NaN             NaN\n",
      "California Housing         LiSHT         128    0.4033    0.3960     0.4126             5/5            NaN            NaN             NaN\n",
      "California Housing         LiSHT          64    0.4060    0.3965     0.4266             5/5            NaN            NaN             NaN\n",
      "California Housing  AdaptiveMish         256    0.4090    0.4073     0.4107             5/5            NaN            NaN             NaN\n",
      "California Housing         LiSHT         256    0.4168    0.4087     0.4288             5/5            NaN            NaN             NaN\n"
     ]
    }
   ],
   "source": [
    "# Optionally, display results grouped by dataset for clarity\n",
    "print(\"\\n--- Results Grouped by Dataset ---\")\n",
    "for ds_name in datasets_config.keys():\n",
    "    print(f\"\\n--- {ds_name} ---\")\n",
    "    ds_df = results_df[results_df['Dataset'] == ds_name].sort_values(by=['Activation', 'Batch Size'])\n",
    "    # Sort within the dataset group to find best performance\n",
    "    metric_col = [col for col in ds_df.columns if col.startswith('Mean ')][0]\n",
    "    higher_is_better = (datasets_config[ds_name]['task_type'] == 'classification')\n",
    "    ds_df_sorted = ds_df.sort_values(by=metric_col, ascending=not higher_is_better)\n",
    "    print(ds_df_sorted.to_string(index=False, float_format=\"%.4f\"))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30937.448317,
   "end_time": "2025-05-14T18:26:03.183911",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-14T09:50:25.735594",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
