{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a879a07b",
   "metadata": {
    "papermill": {
     "duration": 0.003562,
     "end_time": "2025-05-13T06:07:37.145150",
     "exception": false,
     "start_time": "2025-05-13T06:07:37.141588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optimal Activation Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ea71b5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:37.151918Z",
     "iopub.status.busy": "2025-05-13T06:07:37.151668Z",
     "iopub.status.idle": "2025-05-13T06:07:52.656671Z",
     "shell.execute_reply": "2025-05-13T06:07:52.656071Z"
    },
    "papermill": {
     "duration": 15.50984,
     "end_time": "2025-05-13T06:07:52.658049",
     "exception": false,
     "start_time": "2025-05-13T06:07:37.148209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 06:07:38.780852: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747116459.008514      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747116459.071473      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau # Added ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris, load_wine, load_diabetes, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import time # To measure execution time\n",
    "import warnings # To suppress warnings if needed\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output (optional)\n",
    "# tf.get_logger().setLevel('ERROR')\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Configuration ---\n",
    "N_SEEDS = 5         # Number of random seeds to run for averaging results\n",
    "BASE_SEED = 42    # Base seed for reproducibility\n",
    "SEEDS = [BASE_SEED + i for i in range(N_SEEDS)] # List of seeds for multiple runs\n",
    "\n",
    "# Batch sizes to test\n",
    "BATCH_SIZES = [16, 32, 64, 128, 256]\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 200\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EARLY_STOPPING_PATIENCE = 20 # Patience for EarlyStopping\n",
    "REDUCE_LR_PATIENCE = 10     # Patience for ReduceLROnPlateau\n",
    "REDUCE_LR_FACTOR = 0.2      # Factor to reduce learning rate by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc68de5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:52.665057Z",
     "iopub.status.busy": "2025-05-13T06:07:52.664639Z",
     "iopub.status.idle": "2025-05-13T06:07:52.668921Z",
     "shell.execute_reply": "2025-05-13T06:07:52.668384Z"
    },
    "papermill": {
     "duration": 0.008698,
     "end_time": "2025-05-13T06:07:52.669931",
     "exception": false,
     "start_time": "2025-05-13T06:07:52.661233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Seed Setting Function ---\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Sets random seeds for reproducibility.\"\"\"\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # Ensure TF uses deterministic operations where possible\n",
    "    # Note: This might impact performance. Remove if not strictly needed.\n",
    "    # tf.config.experimental.enable_op_determinism() # Might require specific TF versions/configs\n",
    "\n",
    "# Set initial seed for data splitting consistency\n",
    "set_seed(BASE_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8fc442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:52.676327Z",
     "iopub.status.busy": "2025-05-13T06:07:52.676119Z",
     "iopub.status.idle": "2025-05-13T06:07:52.685973Z",
     "shell.execute_reply": "2025-05-13T06:07:52.685456Z"
    },
    "papermill": {
     "duration": 0.014382,
     "end_time": "2025-05-13T06:07:52.687081",
     "exception": false,
     "start_time": "2025-05-13T06:07:52.672699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Custom Activation Functions ---\n",
    "class OptimA(Layer):  # Optimal Activation\n",
    "    \"\"\"\n",
    "    Custom activation layer 'OptimA' with trainable parameters.\n",
    "    Combines tanh and softplus * sigmoid components.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(OptimA, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Defines the trainable weights (parameters) of the activation function.\"\"\"\n",
    "        self.alpha = self.add_weight(name='alpha', shape=(), initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=(), initializer=tf.keras.initializers.Constant(0.5), trainable=True)\n",
    "        self.gamma = self.add_weight(name='gamma', shape=(), initializer='ones', trainable=True)\n",
    "        self.delta = self.add_weight(name='delta', shape=(), initializer=tf.keras.initializers.Constant(0.5), trainable=True)\n",
    "        self.lambda_ = self.add_weight(name='lambda', shape=(), initializer='ones', trainable=True)\n",
    "        super(OptimA, self).build(input_shape) # Ensure build is called for the parent\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Defines the forward pass of the activation function.\"\"\"\n",
    "        term1 = self.alpha * tf.math.tanh(self.beta * x)\n",
    "        term2 = self.gamma * tf.math.softplus(self.delta * x) * tf.math.sigmoid(self.lambda_ * x)\n",
    "        return term1 + term2\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Ensures the layer can be saved and loaded.\"\"\"\n",
    "        config = super(OptimA, self).get_config()\n",
    "        # No specific state needs to be added here unless non-weight parameters are used\n",
    "        return config\n",
    "\n",
    "class OptimALinear(Layer):  # Optimal Activation (Linear Approximation)\n",
    "    \"\"\"\n",
    "    Custom activation layer 'OptimALinear' using linear approximations\n",
    "    for tanh, softplus, and sigmoid. Includes trainable parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, epsilon=1e-5, **kwargs):\n",
    "        super(OptimALinear, self).__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Defines the trainable weights (parameters) of the activation function.\"\"\"\n",
    "        self.alpha = self.add_weight(name='alpha', shape=(), initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=(), initializer=tf.keras.initializers.Constant(0.5), trainable=True)\n",
    "        self.gamma = self.add_weight(name='gamma', shape=(), initializer='ones', trainable=True)\n",
    "        self.delta = self.add_weight(name='delta', shape=(), initializer=tf.keras.initializers.Constant(0.5), trainable=True)\n",
    "        self.lambda_ = self.add_weight(name='lambda', shape=(), initializer='ones', trainable=True)\n",
    "        super(OptimALinear, self).build(input_shape) # Ensure build is called for the parent\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Defines the forward pass using linear approximations.\"\"\"\n",
    "        # Linear approximation for tanh (clipping)\n",
    "        term1 = self.alpha * tf.clip_by_value(self.beta * x, -1.0, 1.0)\n",
    "\n",
    "        # Linear approximations for softplus (ReLU-like) and sigmoid (linear segment)\n",
    "        # Softplus approx: max(0, val) + epsilon (to avoid potential zero multiplication)\n",
    "        softplus_approx = tf.maximum(0.0, self.delta * x) + self.epsilon\n",
    "        # Sigmoid approx near 0: 0.5 + 0.25 * val (first term of Taylor expansion around 0)\n",
    "        sigmoid_approx = tf.clip_by_value(0.5 + 0.25 * self.lambda_ * x, 0.0, 1.0) # Clip to [0,1]\n",
    "\n",
    "        term2 = self.gamma * softplus_approx * sigmoid_approx\n",
    "        return term1 + term2\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Ensures the layer can be saved and loaded.\"\"\"\n",
    "        config = super(OptimALinear, self).get_config()\n",
    "        config.update({\"epsilon\": self.epsilon})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17db3fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:52.694332Z",
     "iopub.status.busy": "2025-05-13T06:07:52.694126Z",
     "iopub.status.idle": "2025-05-13T06:07:52.697582Z",
     "shell.execute_reply": "2025-05-13T06:07:52.696808Z"
    },
    "papermill": {
     "duration": 0.007691,
     "end_time": "2025-05-13T06:07:52.698712",
     "exception": false,
     "start_time": "2025-05-13T06:07:52.691021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading and Preparation ---\n",
    "print(\"Loading and preparing data...\")\n",
    "\n",
    "# Dictionary to hold dataset configurations\n",
    "datasets_config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a916bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:52.705053Z",
     "iopub.status.busy": "2025-05-13T06:07:52.704706Z",
     "iopub.status.idle": "2025-05-13T06:07:52.780716Z",
     "shell.execute_reply": "2025-05-13T06:07:52.780131Z"
    },
    "papermill": {
     "duration": 0.080506,
     "end_time": "2025-05-13T06:07:52.781961",
     "exception": false,
     "start_time": "2025-05-13T06:07:52.701455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 1. Regression: Boston Housing (Note: Boston Housing is often discouraged due to ethical concerns, but kept here as per the original request)\n",
    "try:\n",
    "    (x_train_boston, y_train_boston), (x_test_boston, y_test_boston) = boston_housing.load_data(seed=BASE_SEED)\n",
    "    scaler_boston = StandardScaler()\n",
    "    x_train_boston = scaler_boston.fit_transform(x_train_boston)\n",
    "    x_test_boston = scaler_boston.transform(x_test_boston)\n",
    "    datasets_config['Boston Housing'] = {\n",
    "        'data': (x_train_boston, y_train_boston, x_test_boston, y_test_boston),\n",
    "        'task_type': 'regression',\n",
    "        'metric_name': 'MAE' # Mean Absolute Error\n",
    "    }\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not load Boston Housing dataset. Skipping. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487008d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:52.789606Z",
     "iopub.status.busy": "2025-05-13T06:07:52.789359Z",
     "iopub.status.idle": "2025-05-13T06:07:52.800868Z",
     "shell.execute_reply": "2025-05-13T06:07:52.800168Z"
    },
    "papermill": {
     "duration": 0.016456,
     "end_time": "2025-05-13T06:07:52.802033",
     "exception": false,
     "start_time": "2025-05-13T06:07:52.785577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Classification: Iris\n",
    "data_iris = load_iris()\n",
    "x_train_iris, x_test_iris, y_train_iris, y_test_iris = train_test_split(data_iris.data, data_iris.target, test_size=0.2, random_state=BASE_SEED, stratify=data_iris.target)\n",
    "scaler_iris = StandardScaler()\n",
    "x_train_iris = scaler_iris.fit_transform(x_train_iris)\n",
    "x_test_iris = scaler_iris.transform(x_test_iris)\n",
    "y_train_iris_cat = to_categorical(y_train_iris) # Keep original for potential different loss functions if needed\n",
    "y_test_iris_cat = to_categorical(y_test_iris)\n",
    "datasets_config['Iris'] = {\n",
    "    'data': (x_train_iris, y_train_iris_cat, x_test_iris, y_test_iris_cat),\n",
    "    'task_type': 'classification',\n",
    "    'metric_name': 'Accuracy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4bed3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:52.808973Z",
     "iopub.status.busy": "2025-05-13T06:07:52.808750Z",
     "iopub.status.idle": "2025-05-13T06:07:52.817824Z",
     "shell.execute_reply": "2025-05-13T06:07:52.817157Z"
    },
    "papermill": {
     "duration": 0.013888,
     "end_time": "2025-05-13T06:07:52.818974",
     "exception": false,
     "start_time": "2025-05-13T06:07:52.805086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Multiclass Classification: Wine\n",
    "data_wine = load_wine()\n",
    "x_train_wine, x_test_wine, y_train_wine, y_test_wine = train_test_split(data_wine.data, data_wine.target, test_size=0.2, random_state=BASE_SEED, stratify=data_wine.target)\n",
    "scaler_wine = StandardScaler()\n",
    "x_train_wine = scaler_wine.fit_transform(x_train_wine)\n",
    "x_test_wine = scaler_wine.transform(x_test_wine)\n",
    "y_train_wine_cat = to_categorical(y_train_wine)\n",
    "y_test_wine_cat = to_categorical(y_test_wine)\n",
    "datasets_config['Wine'] = {\n",
    "    'data': (x_train_wine, y_train_wine_cat, x_test_wine, y_test_wine_cat),\n",
    "    'task_type': 'classification',\n",
    "    'metric_name': 'Accuracy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18d2a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:52.825537Z",
     "iopub.status.busy": "2025-05-13T06:07:52.825293Z",
     "iopub.status.idle": "2025-05-13T06:07:52.834740Z",
     "shell.execute_reply": "2025-05-13T06:07:52.834237Z"
    },
    "papermill": {
     "duration": 0.013772,
     "end_time": "2025-05-13T06:07:52.835786",
     "exception": false,
     "start_time": "2025-05-13T06:07:52.822014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Regression: Diabetes Dataset\n",
    "data_diabetes = load_diabetes()\n",
    "x_train_diabetes, x_test_diabetes, y_train_diabetes, y_test_diabetes = train_test_split(\n",
    "    data_diabetes.data, data_diabetes.target, test_size=0.2, random_state=BASE_SEED\n",
    ")\n",
    "scaler_diabetes = StandardScaler()\n",
    "x_train_diabetes = scaler_diabetes.fit_transform(x_train_diabetes)\n",
    "x_test_diabetes = scaler_diabetes.transform(x_test_diabetes)\n",
    "datasets_config['Diabetes'] = {\n",
    "    'data': (x_train_diabetes, y_train_diabetes, x_test_diabetes, y_test_diabetes),\n",
    "    'task_type': 'regression',\n",
    "    'metric_name': 'MAE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a2f83d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:52.842790Z",
     "iopub.status.busy": "2025-05-13T06:07:52.842594Z",
     "iopub.status.idle": "2025-05-13T06:07:54.085031Z",
     "shell.execute_reply": "2025-05-13T06:07:54.084466Z"
    },
    "papermill": {
     "duration": 1.247369,
     "end_time": "2025-05-13T06:07:54.086332",
     "exception": false,
     "start_time": "2025-05-13T06:07:52.838963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Regression: California Housing Dataset\n",
    "data_california = fetch_california_housing()\n",
    "x_train_california, x_test_california, y_train_california, y_test_california = train_test_split(\n",
    "    data_california.data, data_california.target, test_size=0.2, random_state=BASE_SEED\n",
    ")\n",
    "scaler_california = StandardScaler()\n",
    "x_train_california = scaler_california.fit_transform(x_train_california)\n",
    "x_test_california = scaler_california.transform(x_test_california)\n",
    "datasets_config['California Housing'] = {\n",
    "    'data': (x_train_california, y_train_california, x_test_california, y_test_california),\n",
    "    'task_type': 'regression',\n",
    "    'metric_name': 'MAE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ebf6167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:54.093309Z",
     "iopub.status.busy": "2025-05-13T06:07:54.093100Z",
     "iopub.status.idle": "2025-05-13T06:07:54.096703Z",
     "shell.execute_reply": "2025-05-13T06:07:54.095940Z"
    },
    "papermill": {
     "duration": 0.008249,
     "end_time": "2025-05-13T06:07:54.097868",
     "exception": false,
     "start_time": "2025-05-13T06:07:54.089619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading and preparation complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Data loading and preparation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a268405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:54.104734Z",
     "iopub.status.busy": "2025-05-13T06:07:54.104519Z",
     "iopub.status.idle": "2025-05-13T06:07:54.112311Z",
     "shell.execute_reply": "2025-05-13T06:07:54.111648Z"
    },
    "papermill": {
     "duration": 0.012431,
     "end_time": "2025-05-13T06:07:54.113276",
     "exception": false,
     "start_time": "2025-05-13T06:07:54.100845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Model Building and Evaluation Function ---\n",
    "def build_and_evaluate_model(x_train, y_train, x_test, y_test, activation_instance,\n",
    "                             task_type=\"classification\", batch_size=32):\n",
    "    \"\"\"\n",
    "    Builds, compiles, trains, and evaluates a simple Sequential model.\n",
    "\n",
    "    Args:\n",
    "        x_train: Training features.\n",
    "        y_train: Training targets.\n",
    "        x_test: Testing features.\n",
    "        y_test: Testing targets.\n",
    "        activation_instance: An instantiated activation layer or a string identifier.\n",
    "        task_type (str): 'classification' or 'regression'.\n",
    "        batch_size (int): Batch size for training.\n",
    "\n",
    "    Returns:\n",
    "        float: The evaluation metric score (Accuracy for classification, MAE for regression).\n",
    "               Returns np.nan if training fails.\n",
    "    \"\"\"\n",
    "    # Ensure a new model is created for each call\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(x_train.shape[1],))) # Use Input layer for explicit shape definition\n",
    "    model.add(Dense(64, activation=activation_instance)) # Hidden layer\n",
    "\n",
    "    # Output layer and loss function based on task type\n",
    "    if task_type == \"classification\":\n",
    "        num_classes = y_train.shape[1]\n",
    "        if num_classes == 1: # Binary classification (should ideally be checked based on unique values in original y)\n",
    "             # This case isn't used with the current to_categorical preprocessing, but included for completeness\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            loss = 'binary_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "        else:  # Multiclass classification\n",
    "            model.add(Dense(num_classes, activation='softmax'))\n",
    "            loss = 'categorical_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "        monitor_metric = 'val_accuracy' # Monitor validation accuracy for callbacks\n",
    "        eval_metric_index = 1 # metrics list index for accuracy\n",
    "\n",
    "    elif task_type == \"regression\":\n",
    "        model.add(Dense(1)) # Linear output layer\n",
    "        loss = 'mse' # Mean Squared Error is common for training regression\n",
    "        metrics = ['mae'] # Mean Absolute Error is often preferred for evaluation\n",
    "        monitor_metric = 'val_mae' # Monitor validation MAE for callbacks\n",
    "        eval_metric_index = 1 # metrics list index for MAE\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = AdamW(learning_rate=1e-3, beta_1=0.95, beta_2=0.999, amsgrad=True)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    # Define callbacks\n",
    "    early_stop = EarlyStopping(monitor=monitor_metric, patience=EARLY_STOPPING_PATIENCE,\n",
    "                               restore_best_weights=True, mode='min' if task_type == 'regression' else 'max')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=monitor_metric, factor=REDUCE_LR_FACTOR,\n",
    "                                  patience=REDUCE_LR_PATIENCE, min_lr=1e-6,\n",
    "                                  mode='min' if task_type == 'regression' else 'max')\n",
    "\n",
    "    # Train the model\n",
    "    try:\n",
    "        history = model.fit(x_train, y_train,\n",
    "                          validation_split=VALIDATION_SPLIT,\n",
    "                          epochs=EPOCHS,\n",
    "                          batch_size=batch_size,\n",
    "                          callbacks=[early_stop, reduce_lr],\n",
    "                          verbose=0) # verbose=0 for cleaner output during loops\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        results = model.evaluate(x_test, y_test, verbose=0)\n",
    "        return results[eval_metric_index] # Return the desired metric (Accuracy or MAE)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"      ! Training/Evaluation failed: {e}\")\n",
    "        return np.nan # Return NaN if an error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29da29ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T06:07:54.120118Z",
     "iopub.status.busy": "2025-05-13T06:07:54.119919Z",
     "iopub.status.idle": "2025-05-13T11:52:18.364581Z",
     "shell.execute_reply": "2025-05-13T11:52:18.363629Z"
    },
    "papermill": {
     "duration": 20664.249811,
     "end_time": "2025-05-13T11:52:18.366111",
     "exception": false,
     "start_time": "2025-05-13T06:07:54.116300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Experiment ---\n",
      "\n",
      "--- Running Seed 1/5 (Seed: 42) ---\n",
      "  Dataset: Boston Housing (regression)\n",
      "    Activation: OptimA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747116475.338972      20 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747116478.928500      58 service.cc:148] XLA service 0x7ac76800e7f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747116478.928948      58 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1747116479.158840      58 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1747116479.815703      58 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Batch: 16  | MAE: 3.4083 | Time: 9.54s\n",
      "      Batch: 32  | MAE: 3.2316 | Time: 6.66s\n",
      "      Batch: 64  | MAE: 3.3461 | Time: 8.23s\n",
      "      Batch: 128 | MAE: 3.5783 | Time: 8.68s\n",
      "      Batch: 256 | MAE: 3.8940 | Time: 10.79s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 2.3126 | Time: 18.41s\n",
      "      Batch: 32  | MAE: 2.4301 | Time: 15.40s\n",
      "      Batch: 64  | MAE: 2.7020 | Time: 13.37s\n",
      "      Batch: 128 | MAE: 4.2114 | Time: 8.96s\n",
      "      Batch: 256 | MAE: 4.0601 | Time: 11.96s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 2.5436 | Time: 16.75s\n",
      "      Batch: 32  | MAE: 2.6886 | Time: 12.66s\n",
      "      Batch: 64  | MAE: 3.3790 | Time: 11.40s\n",
      "      Batch: 128 | MAE: 4.0395 | Time: 10.61s\n",
      "      Batch: 256 | MAE: 4.7299 | Time: 10.02s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 2.4567 | Time: 16.42s\n",
      "      Batch: 32  | MAE: 3.9160 | Time: 5.68s\n",
      "      Batch: 64  | MAE: 3.3097 | Time: 11.21s\n",
      "      Batch: 128 | MAE: 3.9171 | Time: 10.30s\n",
      "      Batch: 256 | MAE: 4.4725 | Time: 10.20s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 2.6686 | Time: 16.47s\n",
      "      Batch: 32  | MAE: 2.8366 | Time: 12.78s\n",
      "      Batch: 64  | MAE: 3.4895 | Time: 11.35s\n",
      "      Batch: 128 | MAE: 4.2089 | Time: 10.38s\n",
      "      Batch: 256 | MAE: 5.3761 | Time: 10.39s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 2.5787 | Time: 15.09s\n",
      "      Batch: 32  | MAE: 2.8319 | Time: 12.66s\n",
      "      Batch: 64  | MAE: 3.1860 | Time: 11.53s\n",
      "      Batch: 128 | MAE: 3.9115 | Time: 11.05s\n",
      "      Batch: 256 | MAE: 5.0636 | Time: 10.52s\n",
      "  Dataset: Iris (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 5.92s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 5.74s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 5.13s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 5.81s\n",
      "      Batch: 256 | Accuracy: 0.3333 | Time: 4.09s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.7333 | Time: 4.76s\n",
      "      Batch: 32  | Accuracy: 0.7333 | Time: 5.04s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 5.49s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 5.05s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 5.48s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 4.02s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 3.62s\n",
      "      Batch: 64  | Accuracy: 0.7000 | Time: 4.40s\n",
      "      Batch: 128 | Accuracy: 0.8000 | Time: 4.85s\n",
      "      Batch: 256 | Accuracy: 0.6667 | Time: 3.92s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | Accuracy: 0.7333 | Time: 3.81s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 3.61s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 3.66s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 3.25s\n",
      "      Batch: 256 | Accuracy: 0.7333 | Time: 3.01s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 3.65s\n",
      "      Batch: 32  | Accuracy: 0.7333 | Time: 4.11s\n",
      "      Batch: 64  | Accuracy: 0.7000 | Time: 5.67s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 3.06s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 3.31s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 3.56s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 3.62s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 3.50s\n",
      "      Batch: 128 | Accuracy: 0.6000 | Time: 4.29s\n",
      "      Batch: 256 | Accuracy: 0.8000 | Time: 2.98s\n",
      "  Dataset: Wine (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 5.68s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 5.33s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 5.40s\n",
      "      Batch: 128 | Accuracy: 0.9444 | Time: 6.86s\n",
      "      Batch: 256 | Accuracy: 0.9722 | Time: 4.95s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 5.92s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 5.45s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 6.83s\n",
      "      Batch: 128 | Accuracy: 0.8056 | Time: 4.91s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 5.63s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 4.48s\n",
      "      Batch: 32  | Accuracy: 1.0000 | Time: 4.09s\n",
      "      Batch: 64  | Accuracy: 0.9722 | Time: 4.81s\n",
      "      Batch: 128 | Accuracy: 0.9167 | Time: 4.13s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 3.79s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | Accuracy: 0.9722 | Time: 3.92s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 4.09s\n",
      "      Batch: 64  | Accuracy: 1.0000 | Time: 4.41s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 4.08s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 3.43s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | Accuracy: 0.8056 | Time: 3.90s\n",
      "      Batch: 32  | Accuracy: 0.8611 | Time: 3.92s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 5.32s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 4.00s\n",
      "      Batch: 256 | Accuracy: 0.8889 | Time: 3.87s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | Accuracy: 0.9722 | Time: 4.25s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 4.69s\n",
      "      Batch: 64  | Accuracy: 0.8611 | Time: 3.81s\n",
      "      Batch: 128 | Accuracy: 0.8889 | Time: 4.36s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 4.14s\n",
      "  Dataset: Diabetes (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 43.4902 | Time: 10.75s\n",
      "      Batch: 32  | MAE: 43.6714 | Time: 11.63s\n",
      "      Batch: 64  | MAE: 45.7388 | Time: 13.05s\n",
      "      Batch: 128 | MAE: 58.9595 | Time: 12.39s\n",
      "      Batch: 256 | MAE: 92.9456 | Time: 11.97s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 41.2958 | Time: 12.36s\n",
      "      Batch: 32  | MAE: 41.1393 | Time: 15.28s\n",
      "      Batch: 64  | MAE: 45.0447 | Time: 12.91s\n",
      "      Batch: 128 | MAE: 78.1867 | Time: 12.22s\n",
      "      Batch: 256 | MAE: 90.6436 | Time: 11.76s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 43.8410 | Time: 14.72s\n",
      "      Batch: 32  | MAE: 50.6882 | Time: 12.71s\n",
      "      Batch: 64  | MAE: 53.7651 | Time: 11.01s\n",
      "      Batch: 128 | MAE: 75.7971 | Time: 11.71s\n",
      "      Batch: 256 | MAE: 109.3369 | Time: 9.94s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 41.9016 | Time: 14.49s\n",
      "      Batch: 32  | MAE: 51.1104 | Time: 12.23s\n",
      "      Batch: 64  | MAE: 79.0049 | Time: 10.84s\n",
      "      Batch: 128 | MAE: 97.0703 | Time: 10.11s\n",
      "      Batch: 256 | MAE: 118.2005 | Time: 10.05s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 44.7554 | Time: 14.83s\n",
      "      Batch: 32  | MAE: 50.7488 | Time: 12.44s\n",
      "      Batch: 64  | MAE: 70.8184 | Time: 11.09s\n",
      "      Batch: 128 | MAE: 80.9857 | Time: 10.31s\n",
      "      Batch: 256 | MAE: 110.5775 | Time: 10.17s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 45.8446 | Time: 16.35s\n",
      "      Batch: 32  | MAE: 50.8366 | Time: 12.23s\n",
      "      Batch: 64  | MAE: 57.0169 | Time: 11.08s\n",
      "      Batch: 128 | MAE: 80.3748 | Time: 10.25s\n",
      "      Batch: 256 | MAE: 113.3652 | Time: 10.02s\n",
      "  Dataset: California Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 0.3665 | Time: 266.02s\n",
      "      Batch: 32  | MAE: 0.3810 | Time: 139.48s\n",
      "      Batch: 64  | MAE: 0.3801 | Time: 76.16s\n",
      "      Batch: 128 | MAE: 0.3828 | Time: 46.00s\n",
      "      Batch: 256 | MAE: 0.4046 | Time: 27.97s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 0.3800 | Time: 269.22s\n",
      "      Batch: 32  | MAE: 0.3850 | Time: 71.02s\n",
      "      Batch: 64  | MAE: 0.3889 | Time: 75.53s\n",
      "      Batch: 128 | MAE: 0.3913 | Time: 43.78s\n",
      "      Batch: 256 | MAE: 0.3994 | Time: 27.97s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 0.3730 | Time: 242.67s\n",
      "      Batch: 32  | MAE: 0.3733 | Time: 126.20s\n",
      "      Batch: 64  | MAE: 0.3788 | Time: 67.79s\n",
      "      Batch: 128 | MAE: 0.3834 | Time: 38.95s\n",
      "      Batch: 256 | MAE: 0.3869 | Time: 24.13s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 0.3950 | Time: 238.60s\n",
      "      Batch: 32  | MAE: 0.4024 | Time: 123.90s\n",
      "      Batch: 64  | MAE: 0.4062 | Time: 67.21s\n",
      "      Batch: 128 | MAE: 0.4143 | Time: 39.06s\n",
      "      Batch: 256 | MAE: 0.4280 | Time: 23.89s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 0.4054 | Time: 237.36s\n",
      "      Batch: 32  | MAE: 0.4013 | Time: 123.56s\n",
      "      Batch: 64  | MAE: 0.4110 | Time: 66.90s\n",
      "      Batch: 128 | MAE: 0.4220 | Time: 38.59s\n",
      "      Batch: 256 | MAE: 0.4250 | Time: 24.03s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 0.3918 | Time: 241.10s\n",
      "      Batch: 32  | MAE: 0.3882 | Time: 125.17s\n",
      "      Batch: 64  | MAE: 0.3918 | Time: 68.21s\n",
      "      Batch: 128 | MAE: 0.4049 | Time: 39.57s\n",
      "      Batch: 256 | MAE: 0.4099 | Time: 24.12s\n",
      "\n",
      "--- Running Seed 2/5 (Seed: 43) ---\n",
      "  Dataset: Boston Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 2.5275 | Time: 19.38s\n",
      "      Batch: 32  | MAE: 3.3728 | Time: 6.61s\n",
      "      Batch: 64  | MAE: 3.5091 | Time: 7.64s\n",
      "      Batch: 128 | MAE: 3.4899 | Time: 8.98s\n",
      "      Batch: 256 | MAE: 3.7247 | Time: 13.23s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 2.2954 | Time: 18.83s\n",
      "      Batch: 32  | MAE: 2.4767 | Time: 14.71s\n",
      "      Batch: 64  | MAE: 2.9285 | Time: 13.15s\n",
      "      Batch: 128 | MAE: 4.1789 | Time: 8.46s\n",
      "      Batch: 256 | MAE: 3.9697 | Time: 11.96s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 2.6352 | Time: 16.00s\n",
      "      Batch: 32  | MAE: 2.8313 | Time: 12.47s\n",
      "      Batch: 64  | MAE: 3.4439 | Time: 11.55s\n",
      "      Batch: 128 | MAE: 3.8084 | Time: 10.11s\n",
      "      Batch: 256 | MAE: 4.6303 | Time: 10.18s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 2.4764 | Time: 18.92s\n",
      "      Batch: 32  | MAE: 2.6957 | Time: 12.75s\n",
      "      Batch: 64  | MAE: 3.3757 | Time: 11.51s\n",
      "      Batch: 128 | MAE: 3.9206 | Time: 10.41s\n",
      "      Batch: 256 | MAE: 4.4188 | Time: 10.03s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 2.5921 | Time: 15.78s\n",
      "      Batch: 32  | MAE: 2.7602 | Time: 12.48s\n",
      "      Batch: 64  | MAE: 3.4954 | Time: 11.04s\n",
      "      Batch: 128 | MAE: 4.1469 | Time: 10.31s\n",
      "      Batch: 256 | MAE: 5.3363 | Time: 9.87s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 2.5611 | Time: 15.54s\n",
      "      Batch: 32  | MAE: 2.7326 | Time: 12.30s\n",
      "      Batch: 64  | MAE: 3.2019 | Time: 11.02s\n",
      "      Batch: 128 | MAE: 3.9855 | Time: 10.43s\n",
      "      Batch: 256 | MAE: 4.7348 | Time: 10.00s\n",
      "  Dataset: Iris (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 7.35s\n",
      "      Batch: 32  | Accuracy: 0.6667 | Time: 4.27s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 4.83s\n",
      "      Batch: 128 | Accuracy: 0.8000 | Time: 4.63s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 4.11s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 5.04s\n",
      "      Batch: 32  | Accuracy: 0.8333 | Time: 5.83s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 5.70s\n",
      "      Batch: 128 | Accuracy: 0.7000 | Time: 4.69s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 6.85s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 3.65s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 3.76s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 4.66s\n",
      "      Batch: 128 | Accuracy: 0.6333 | Time: 3.31s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 3.91s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | Accuracy: 0.8333 | Time: 4.23s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 4.01s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 4.05s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 3.64s\n",
      "      Batch: 256 | Accuracy: 0.8000 | Time: 3.08s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 3.62s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 3.45s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 3.90s\n",
      "      Batch: 128 | Accuracy: 0.4000 | Time: 2.82s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 3.23s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 4.25s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 3.55s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 6.40s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 3.55s\n",
      "      Batch: 256 | Accuracy: 0.6667 | Time: 3.73s\n",
      "  Dataset: Wine (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 5.57s\n",
      "      Batch: 32  | Accuracy: 0.8611 | Time: 5.49s\n",
      "      Batch: 64  | Accuracy: 0.9722 | Time: 5.43s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 4.99s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 5.33s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 5.55s\n",
      "      Batch: 32  | Accuracy: 0.9167 | Time: 5.35s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 5.33s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 7.26s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 5.10s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | Accuracy: 0.9722 | Time: 3.67s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 3.34s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 3.70s\n",
      "      Batch: 128 | Accuracy: 0.9167 | Time: 3.97s\n",
      "      Batch: 256 | Accuracy: 0.8889 | Time: 3.66s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 3.92s\n",
      "      Batch: 32  | Accuracy: 0.8889 | Time: 3.37s\n",
      "      Batch: 64  | Accuracy: 1.0000 | Time: 4.00s\n",
      "      Batch: 128 | Accuracy: 0.9722 | Time: 4.26s\n",
      "      Batch: 256 | Accuracy: 0.8333 | Time: 3.51s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 3.78s\n",
      "      Batch: 32  | Accuracy: 0.9167 | Time: 3.56s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 3.85s\n",
      "      Batch: 128 | Accuracy: 0.8056 | Time: 3.37s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 3.49s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 3.89s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 6.29s\n",
      "      Batch: 64  | Accuracy: 0.9722 | Time: 4.24s\n",
      "      Batch: 128 | Accuracy: 1.0000 | Time: 4.25s\n",
      "      Batch: 256 | Accuracy: 0.9444 | Time: 4.37s\n",
      "  Dataset: Diabetes (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 43.4478 | Time: 10.38s\n",
      "      Batch: 32  | MAE: 43.2581 | Time: 11.75s\n",
      "      Batch: 64  | MAE: 45.5774 | Time: 13.06s\n",
      "      Batch: 128 | MAE: 60.1412 | Time: 12.20s\n",
      "      Batch: 256 | MAE: 95.0234 | Time: 11.96s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 43.4942 | Time: 9.65s\n",
      "      Batch: 32  | MAE: 44.6864 | Time: 10.71s\n",
      "      Batch: 64  | MAE: 44.4136 | Time: 12.94s\n",
      "      Batch: 128 | MAE: 68.5946 | Time: 16.12s\n",
      "      Batch: 256 | MAE: 145.7749 | Time: 4.97s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 43.6892 | Time: 14.52s\n",
      "      Batch: 32  | MAE: 49.0148 | Time: 12.08s\n",
      "      Batch: 64  | MAE: 55.0058 | Time: 10.95s\n",
      "      Batch: 128 | MAE: 75.6791 | Time: 10.12s\n",
      "      Batch: 256 | MAE: 110.8138 | Time: 10.07s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 43.4561 | Time: 14.14s\n",
      "      Batch: 32  | MAE: 50.5881 | Time: 11.97s\n",
      "      Batch: 64  | MAE: 80.4699 | Time: 10.82s\n",
      "      Batch: 128 | MAE: 143.8722 | Time: 10.06s\n",
      "      Batch: 256 | MAE: 145.7923 | Time: 2.89s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 44.8269 | Time: 14.56s\n",
      "      Batch: 32  | MAE: 52.0265 | Time: 11.94s\n",
      "      Batch: 64  | MAE: 62.8214 | Time: 10.89s\n",
      "      Batch: 128 | MAE: 86.1812 | Time: 10.15s\n",
      "      Batch: 256 | MAE: 114.8628 | Time: 9.87s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 45.4825 | Time: 14.75s\n",
      "      Batch: 32  | MAE: 51.8152 | Time: 12.00s\n",
      "      Batch: 64  | MAE: 60.9300 | Time: 10.76s\n",
      "      Batch: 128 | MAE: 84.4243 | Time: 10.33s\n",
      "      Batch: 256 | MAE: 115.4971 | Time: 9.92s\n",
      "  Dataset: California Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 0.3886 | Time: 274.12s\n",
      "      Batch: 32  | MAE: 0.3733 | Time: 142.40s\n",
      "      Batch: 64  | MAE: 0.3802 | Time: 77.62s\n",
      "      Batch: 128 | MAE: 0.3863 | Time: 44.01s\n",
      "      Batch: 256 | MAE: 0.3880 | Time: 27.41s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 0.3743 | Time: 268.66s\n",
      "      Batch: 32  | MAE: 0.3749 | Time: 139.29s\n",
      "      Batch: 64  | MAE: 0.3872 | Time: 62.71s\n",
      "      Batch: 128 | MAE: 0.3871 | Time: 43.79s\n",
      "      Batch: 256 | MAE: 0.3994 | Time: 27.60s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 0.3654 | Time: 237.94s\n",
      "      Batch: 32  | MAE: 0.3777 | Time: 125.36s\n",
      "      Batch: 64  | MAE: 0.3785 | Time: 66.85s\n",
      "      Batch: 128 | MAE: 0.3849 | Time: 38.60s\n",
      "      Batch: 256 | MAE: 0.3868 | Time: 24.00s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 0.4122 | Time: 238.34s\n",
      "      Batch: 32  | MAE: 0.3974 | Time: 130.08s\n",
      "      Batch: 64  | MAE: 0.4045 | Time: 69.02s\n",
      "      Batch: 128 | MAE: 0.4148 | Time: 39.25s\n",
      "      Batch: 256 | MAE: 0.4235 | Time: 24.47s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 0.4028 | Time: 240.68s\n",
      "      Batch: 32  | MAE: 0.4003 | Time: 125.69s\n",
      "      Batch: 64  | MAE: 0.4161 | Time: 67.71s\n",
      "      Batch: 128 | MAE: 0.4197 | Time: 38.46s\n",
      "      Batch: 256 | MAE: 0.4252 | Time: 24.05s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 0.3889 | Time: 240.31s\n",
      "      Batch: 32  | MAE: 0.3888 | Time: 128.80s\n",
      "      Batch: 64  | MAE: 0.3920 | Time: 72.44s\n",
      "      Batch: 128 | MAE: 0.3999 | Time: 42.14s\n",
      "      Batch: 256 | MAE: 0.4160 | Time: 26.91s\n",
      "\n",
      "--- Running Seed 3/5 (Seed: 44) ---\n",
      "  Dataset: Boston Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 3.0144 | Time: 22.96s\n",
      "      Batch: 32  | MAE: 2.6843 | Time: 18.18s\n",
      "      Batch: 64  | MAE: 3.1094 | Time: 16.01s\n",
      "      Batch: 128 | MAE: 3.7900 | Time: 10.20s\n",
      "      Batch: 256 | MAE: 3.4792 | Time: 13.70s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 2.4264 | Time: 21.09s\n",
      "      Batch: 32  | MAE: 4.1581 | Time: 11.33s\n",
      "      Batch: 64  | MAE: 2.9337 | Time: 16.12s\n",
      "      Batch: 128 | MAE: 4.4093 | Time: 9.30s\n",
      "      Batch: 256 | MAE: 3.7134 | Time: 13.91s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 2.5983 | Time: 17.96s\n",
      "      Batch: 32  | MAE: 2.8037 | Time: 14.33s\n",
      "      Batch: 64  | MAE: 3.4069 | Time: 13.03s\n",
      "      Batch: 128 | MAE: 3.9006 | Time: 11.82s\n",
      "      Batch: 256 | MAE: 4.6809 | Time: 11.72s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 3.9988 | Time: 5.78s\n",
      "      Batch: 32  | MAE: 4.3292 | Time: 5.66s\n",
      "      Batch: 64  | MAE: 3.4504 | Time: 12.90s\n",
      "      Batch: 128 | MAE: 4.1507 | Time: 11.88s\n",
      "      Batch: 256 | MAE: 4.3918 | Time: 11.36s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 2.5141 | Time: 17.71s\n",
      "      Batch: 32  | MAE: 2.9197 | Time: 14.33s\n",
      "      Batch: 64  | MAE: 3.6575 | Time: 13.05s\n",
      "      Batch: 128 | MAE: 4.2202 | Time: 11.80s\n",
      "      Batch: 256 | MAE: 4.9540 | Time: 11.49s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 2.6328 | Time: 17.56s\n",
      "      Batch: 32  | MAE: 2.7131 | Time: 14.42s\n",
      "      Batch: 64  | MAE: 3.3961 | Time: 13.14s\n",
      "      Batch: 128 | MAE: 4.0925 | Time: 11.84s\n",
      "      Batch: 256 | MAE: 5.1516 | Time: 20.01s\n",
      "  Dataset: Iris (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 6.06s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 5.60s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 5.37s\n",
      "      Batch: 128 | Accuracy: 0.7333 | Time: 5.64s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 6.25s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.9000 | Time: 7.77s\n",
      "      Batch: 32  | Accuracy: 0.7333 | Time: 4.70s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 7.31s\n",
      "      Batch: 128 | Accuracy: 0.6000 | Time: 4.80s\n",
      "      Batch: 256 | Accuracy: 0.6000 | Time: 4.62s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | Accuracy: 0.8667 | Time: 5.48s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 4.08s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 3.52s\n",
      "      Batch: 128 | Accuracy: 0.3667 | Time: 3.46s\n",
      "      Batch: 256 | Accuracy: 0.4000 | Time: 3.20s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 4.66s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 4.62s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 3.77s\n",
      "      Batch: 128 | Accuracy: 0.7333 | Time: 8.75s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 3.63s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | Accuracy: 0.5667 | Time: 3.52s\n",
      "      Batch: 32  | Accuracy: 0.7000 | Time: 3.14s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 3.90s\n",
      "      Batch: 128 | Accuracy: 0.6000 | Time: 3.64s\n",
      "      Batch: 256 | Accuracy: 0.6667 | Time: 4.12s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 4.57s\n",
      "      Batch: 32  | Accuracy: 0.6333 | Time: 3.15s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 4.87s\n",
      "      Batch: 128 | Accuracy: 0.6333 | Time: 3.95s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 3.62s\n",
      "  Dataset: Wine (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.8889 | Time: 5.88s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 6.04s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 6.24s\n",
      "      Batch: 128 | Accuracy: 0.9167 | Time: 5.54s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 6.00s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 6.18s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 5.55s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 5.76s\n",
      "      Batch: 128 | Accuracy: 0.9722 | Time: 5.41s\n",
      "      Batch: 256 | Accuracy: 0.9722 | Time: 10.55s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 4.36s\n",
      "      Batch: 32  | Accuracy: 1.0000 | Time: 4.29s\n",
      "      Batch: 64  | Accuracy: 1.0000 | Time: 5.31s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 4.68s\n",
      "      Batch: 256 | Accuracy: 0.8056 | Time: 4.33s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | Accuracy: 0.9722 | Time: 4.23s\n",
      "      Batch: 32  | Accuracy: 0.9167 | Time: 4.10s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 4.35s\n",
      "      Batch: 128 | Accuracy: 0.9167 | Time: 5.33s\n",
      "      Batch: 256 | Accuracy: 0.8889 | Time: 3.86s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | Accuracy: 0.9722 | Time: 4.06s\n",
      "      Batch: 32  | Accuracy: 0.8333 | Time: 3.78s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 4.54s\n",
      "      Batch: 128 | Accuracy: 0.9167 | Time: 4.41s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 5.31s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 4.06s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 4.70s\n",
      "      Batch: 64  | Accuracy: 0.9444 | Time: 5.31s\n",
      "      Batch: 128 | Accuracy: 0.9167 | Time: 4.02s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 4.44s\n",
      "  Dataset: Diabetes (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 43.0209 | Time: 10.64s\n",
      "      Batch: 32  | MAE: 43.0594 | Time: 13.79s\n",
      "      Batch: 64  | MAE: 44.7841 | Time: 14.82s\n",
      "      Batch: 128 | MAE: 54.6715 | Time: 13.73s\n",
      "      Batch: 256 | MAE: 90.5704 | Time: 13.55s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 42.7842 | Time: 17.24s\n",
      "      Batch: 32  | MAE: 42.1802 | Time: 14.87s\n",
      "      Batch: 64  | MAE: 43.5454 | Time: 15.24s\n",
      "      Batch: 128 | MAE: 59.9953 | Time: 13.88s\n",
      "      Batch: 256 | MAE: 87.8760 | Time: 13.52s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 42.6984 | Time: 16.48s\n",
      "      Batch: 32  | MAE: 49.4142 | Time: 13.70s\n",
      "      Batch: 64  | MAE: 55.0455 | Time: 12.66s\n",
      "      Batch: 128 | MAE: 71.3999 | Time: 12.22s\n",
      "      Batch: 256 | MAE: 111.8510 | Time: 11.55s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 42.0741 | Time: 16.58s\n",
      "      Batch: 32  | MAE: 49.7605 | Time: 14.12s\n",
      "      Batch: 64  | MAE: 80.6632 | Time: 12.65s\n",
      "      Batch: 128 | MAE: 96.3525 | Time: 11.69s\n",
      "      Batch: 256 | MAE: 145.5902 | Time: 3.14s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 43.4773 | Time: 16.63s\n",
      "      Batch: 32  | MAE: 50.8435 | Time: 13.94s\n",
      "      Batch: 64  | MAE: 62.3781 | Time: 13.01s\n",
      "      Batch: 128 | MAE: 85.2244 | Time: 11.86s\n",
      "      Batch: 256 | MAE: 110.2315 | Time: 11.64s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 44.8023 | Time: 16.61s\n",
      "      Batch: 32  | MAE: 51.2546 | Time: 14.18s\n",
      "      Batch: 64  | MAE: 58.7786 | Time: 12.91s\n",
      "      Batch: 128 | MAE: 76.6272 | Time: 11.67s\n",
      "      Batch: 256 | MAE: 111.7471 | Time: 11.49s\n",
      "  Dataset: California Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 0.3643 | Time: 289.09s\n",
      "      Batch: 32  | MAE: 0.3749 | Time: 150.77s\n",
      "      Batch: 64  | MAE: 0.3723 | Time: 93.33s\n",
      "      Batch: 128 | MAE: 0.3807 | Time: 50.48s\n",
      "      Batch: 256 | MAE: 0.4134 | Time: 32.02s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 0.3694 | Time: 293.94s\n",
      "      Batch: 32  | MAE: 0.3803 | Time: 154.75s\n",
      "      Batch: 64  | MAE: 0.3779 | Time: 84.43s\n",
      "      Batch: 128 | MAE: 0.3853 | Time: 48.89s\n",
      "      Batch: 256 | MAE: 0.3941 | Time: 31.88s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 0.3714 | Time: 257.49s\n",
      "      Batch: 32  | MAE: 0.3735 | Time: 134.72s\n",
      "      Batch: 64  | MAE: 0.3815 | Time: 73.22s\n",
      "      Batch: 128 | MAE: 0.3809 | Time: 42.87s\n",
      "      Batch: 256 | MAE: 0.3885 | Time: 26.81s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 0.3989 | Time: 240.39s\n",
      "      Batch: 32  | MAE: 0.3962 | Time: 125.71s\n",
      "      Batch: 64  | MAE: 0.4022 | Time: 68.11s\n",
      "      Batch: 128 | MAE: 0.4166 | Time: 41.26s\n",
      "      Batch: 256 | MAE: 0.4335 | Time: 25.59s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 0.3979 | Time: 259.24s\n",
      "      Batch: 32  | MAE: 0.4017 | Time: 124.50s\n",
      "      Batch: 64  | MAE: 0.4096 | Time: 67.42s\n",
      "      Batch: 128 | MAE: 0.4160 | Time: 38.58s\n",
      "      Batch: 256 | MAE: 0.4241 | Time: 24.46s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 0.3874 | Time: 206.65s\n",
      "      Batch: 32  | MAE: 0.3870 | Time: 125.61s\n",
      "      Batch: 64  | MAE: 0.3906 | Time: 67.92s\n",
      "      Batch: 128 | MAE: 0.3970 | Time: 39.38s\n",
      "      Batch: 256 | MAE: 0.4136 | Time: 24.49s\n",
      "\n",
      "--- Running Seed 4/5 (Seed: 45) ---\n",
      "  Dataset: Boston Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 3.4024 | Time: 12.38s\n",
      "      Batch: 32  | MAE: 2.6524 | Time: 16.84s\n",
      "      Batch: 64  | MAE: 2.9597 | Time: 14.79s\n",
      "      Batch: 128 | MAE: 3.5751 | Time: 9.13s\n",
      "      Batch: 256 | MAE: 3.7262 | Time: 11.89s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 2.3524 | Time: 19.46s\n",
      "      Batch: 32  | MAE: 2.4947 | Time: 15.88s\n",
      "      Batch: 64  | MAE: 3.1649 | Time: 13.98s\n",
      "      Batch: 128 | MAE: 4.4692 | Time: 8.57s\n",
      "      Batch: 256 | MAE: 3.9440 | Time: 12.43s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 2.6477 | Time: 16.21s\n",
      "      Batch: 32  | MAE: 2.7644 | Time: 12.85s\n",
      "      Batch: 64  | MAE: 3.2627 | Time: 11.29s\n",
      "      Batch: 128 | MAE: 4.1029 | Time: 10.34s\n",
      "      Batch: 256 | MAE: 4.4695 | Time: 10.22s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 2.4679 | Time: 15.57s\n",
      "      Batch: 32  | MAE: 3.8857 | Time: 5.74s\n",
      "      Batch: 64  | MAE: 3.6387 | Time: 11.44s\n",
      "      Batch: 128 | MAE: 4.0346 | Time: 10.19s\n",
      "      Batch: 256 | MAE: 4.3622 | Time: 10.11s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 2.6417 | Time: 15.85s\n",
      "      Batch: 32  | MAE: 2.8631 | Time: 12.61s\n",
      "      Batch: 64  | MAE: 3.5699 | Time: 11.38s\n",
      "      Batch: 128 | MAE: 4.1931 | Time: 10.10s\n",
      "      Batch: 256 | MAE: 4.8829 | Time: 9.86s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 2.6160 | Time: 15.48s\n",
      "      Batch: 32  | MAE: 2.7929 | Time: 12.31s\n",
      "      Batch: 64  | MAE: 3.3020 | Time: 11.13s\n",
      "      Batch: 128 | MAE: 3.7085 | Time: 10.16s\n",
      "      Batch: 256 | MAE: 4.4726 | Time: 9.88s\n",
      "  Dataset: Iris (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.9667 | Time: 12.22s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 5.45s\n",
      "      Batch: 64  | Accuracy: 0.6000 | Time: 4.80s\n",
      "      Batch: 128 | Accuracy: 0.7333 | Time: 5.35s\n",
      "      Batch: 256 | Accuracy: 0.6667 | Time: 4.09s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.8667 | Time: 6.05s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 4.17s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 4.89s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 4.59s\n",
      "      Batch: 256 | Accuracy: 0.7000 | Time: 4.93s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 2.97s\n",
      "      Batch: 32  | Accuracy: 0.7333 | Time: 2.99s\n",
      "      Batch: 64  | Accuracy: 0.7000 | Time: 3.69s\n",
      "      Batch: 128 | Accuracy: 0.5667 | Time: 3.52s\n",
      "      Batch: 256 | Accuracy: 0.8333 | Time: 2.76s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | Accuracy: 0.9000 | Time: 4.61s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 3.46s\n",
      "      Batch: 64  | Accuracy: 0.7000 | Time: 3.07s\n",
      "      Batch: 128 | Accuracy: 0.7000 | Time: 3.34s\n",
      "      Batch: 256 | Accuracy: 0.5333 | Time: 4.87s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 3.94s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 3.03s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 3.17s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 3.05s\n",
      "      Batch: 256 | Accuracy: 0.7333 | Time: 3.02s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 3.20s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 3.24s\n",
      "      Batch: 64  | Accuracy: 0.6667 | Time: 3.32s\n",
      "      Batch: 128 | Accuracy: 0.6333 | Time: 2.86s\n",
      "      Batch: 256 | Accuracy: 0.7333 | Time: 3.89s\n",
      "  Dataset: Wine (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 12.03s\n",
      "      Batch: 32  | Accuracy: 0.8889 | Time: 5.49s\n",
      "      Batch: 64  | Accuracy: 0.9722 | Time: 5.58s\n",
      "      Batch: 128 | Accuracy: 0.8889 | Time: 5.46s\n",
      "      Batch: 256 | Accuracy: 0.9167 | Time: 4.77s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.9722 | Time: 5.74s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 5.42s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 5.57s\n",
      "      Batch: 128 | Accuracy: 0.9444 | Time: 4.98s\n",
      "      Batch: 256 | Accuracy: 0.8333 | Time: 5.46s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 3.63s\n",
      "      Batch: 32  | Accuracy: 0.8889 | Time: 3.55s\n",
      "      Batch: 64  | Accuracy: 0.9444 | Time: 4.43s\n",
      "      Batch: 128 | Accuracy: 0.9722 | Time: 5.40s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 3.82s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | Accuracy: 0.8889 | Time: 3.69s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 4.09s\n",
      "      Batch: 64  | Accuracy: 0.8611 | Time: 3.37s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 3.93s\n",
      "      Batch: 256 | Accuracy: 0.8333 | Time: 4.53s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | Accuracy: 0.8611 | Time: 3.97s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 3.80s\n",
      "      Batch: 64  | Accuracy: 0.9167 | Time: 4.45s\n",
      "      Batch: 128 | Accuracy: 0.8333 | Time: 3.53s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 3.43s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | Accuracy: 0.9444 | Time: 3.64s\n",
      "      Batch: 32  | Accuracy: 0.8889 | Time: 3.67s\n",
      "      Batch: 64  | Accuracy: 1.0000 | Time: 4.02s\n",
      "      Batch: 128 | Accuracy: 0.7778 | Time: 3.68s\n",
      "      Batch: 256 | Accuracy: 0.9444 | Time: 3.66s\n",
      "  Dataset: Diabetes (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 44.5691 | Time: 9.64s\n",
      "      Batch: 32  | MAE: 44.0088 | Time: 18.83s\n",
      "      Batch: 64  | MAE: 45.3728 | Time: 13.91s\n",
      "      Batch: 128 | MAE: 56.4763 | Time: 12.63s\n",
      "      Batch: 256 | MAE: 93.2026 | Time: 12.31s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 42.9101 | Time: 11.23s\n",
      "      Batch: 32  | MAE: 42.4911 | Time: 13.19s\n",
      "      Batch: 64  | MAE: 43.6657 | Time: 13.31s\n",
      "      Batch: 128 | MAE: 66.3430 | Time: 12.30s\n",
      "      Batch: 256 | MAE: 92.2431 | Time: 12.28s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 44.0663 | Time: 14.58s\n",
      "      Batch: 32  | MAE: 49.3226 | Time: 12.07s\n",
      "      Batch: 64  | MAE: 55.9173 | Time: 11.26s\n",
      "      Batch: 128 | MAE: 72.7846 | Time: 10.47s\n",
      "      Batch: 256 | MAE: 109.9699 | Time: 9.94s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 42.7519 | Time: 14.57s\n",
      "      Batch: 32  | MAE: 48.9179 | Time: 11.91s\n",
      "      Batch: 64  | MAE: 74.5949 | Time: 11.00s\n",
      "      Batch: 128 | MAE: 98.2959 | Time: 10.30s\n",
      "      Batch: 256 | MAE: 118.4012 | Time: 10.05s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 46.5323 | Time: 14.87s\n",
      "      Batch: 32  | MAE: 48.6125 | Time: 12.51s\n",
      "      Batch: 64  | MAE: 60.8682 | Time: 11.14s\n",
      "      Batch: 128 | MAE: 85.3713 | Time: 10.36s\n",
      "      Batch: 256 | MAE: 113.8616 | Time: 10.06s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 45.8521 | Time: 15.07s\n",
      "      Batch: 32  | MAE: 53.8419 | Time: 12.29s\n",
      "      Batch: 64  | MAE: 56.6328 | Time: 11.17s\n",
      "      Batch: 128 | MAE: 79.9029 | Time: 10.53s\n",
      "      Batch: 256 | MAE: 107.7615 | Time: 10.22s\n",
      "  Dataset: California Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 0.3713 | Time: 268.54s\n",
      "      Batch: 32  | MAE: 0.3764 | Time: 142.13s\n",
      "      Batch: 64  | MAE: 0.3729 | Time: 77.06s\n",
      "      Batch: 128 | MAE: 0.3858 | Time: 44.45s\n",
      "      Batch: 256 | MAE: 0.3993 | Time: 36.05s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 0.3755 | Time: 278.49s\n",
      "      Batch: 32  | MAE: 0.3789 | Time: 144.70s\n",
      "      Batch: 64  | MAE: 0.3895 | Time: 62.84s\n",
      "      Batch: 128 | MAE: 0.3899 | Time: 45.23s\n",
      "      Batch: 256 | MAE: 0.4116 | Time: 28.21s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 0.3712 | Time: 245.13s\n",
      "      Batch: 32  | MAE: 0.3749 | Time: 127.89s\n",
      "      Batch: 64  | MAE: 0.3798 | Time: 69.17s\n",
      "      Batch: 128 | MAE: 0.3850 | Time: 39.88s\n",
      "      Batch: 256 | MAE: 0.3883 | Time: 24.78s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 0.4025 | Time: 241.49s\n",
      "      Batch: 32  | MAE: 0.4008 | Time: 126.31s\n",
      "      Batch: 64  | MAE: 0.4012 | Time: 67.79s\n",
      "      Batch: 128 | MAE: 0.4122 | Time: 39.12s\n",
      "      Batch: 256 | MAE: 0.4294 | Time: 24.52s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 0.3979 | Time: 242.24s\n",
      "      Batch: 32  | MAE: 0.4013 | Time: 127.34s\n",
      "      Batch: 64  | MAE: 0.4151 | Time: 69.68s\n",
      "      Batch: 128 | MAE: 0.4175 | Time: 39.61s\n",
      "      Batch: 256 | MAE: 0.4231 | Time: 24.31s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 0.3875 | Time: 239.58s\n",
      "      Batch: 32  | MAE: 0.3910 | Time: 125.25s\n",
      "      Batch: 64  | MAE: 0.3931 | Time: 67.62s\n",
      "      Batch: 128 | MAE: 0.3955 | Time: 38.81s\n",
      "      Batch: 256 | MAE: 0.4037 | Time: 24.42s\n",
      "\n",
      "--- Running Seed 5/5 (Seed: 46) ---\n",
      "  Dataset: Boston Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 2.5000 | Time: 19.98s\n",
      "      Batch: 32  | MAE: 3.3461 | Time: 6.40s\n",
      "      Batch: 64  | MAE: 3.4809 | Time: 8.26s\n",
      "      Batch: 128 | MAE: 3.7715 | Time: 9.26s\n",
      "      Batch: 256 | MAE: 3.6614 | Time: 10.57s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 2.2925 | Time: 18.45s\n",
      "      Batch: 32  | MAE: 2.4542 | Time: 14.67s\n",
      "      Batch: 64  | MAE: 2.9363 | Time: 13.23s\n",
      "      Batch: 128 | MAE: 4.1866 | Time: 16.86s\n",
      "      Batch: 256 | MAE: 4.2506 | Time: 12.68s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 2.6034 | Time: 16.00s\n",
      "      Batch: 32  | MAE: 2.8813 | Time: 12.97s\n",
      "      Batch: 64  | MAE: 3.5080 | Time: 11.73s\n",
      "      Batch: 128 | MAE: 3.9784 | Time: 10.47s\n",
      "      Batch: 256 | MAE: 4.5640 | Time: 10.05s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 2.4998 | Time: 15.80s\n",
      "      Batch: 32  | MAE: 2.9344 | Time: 12.36s\n",
      "      Batch: 64  | MAE: 3.5183 | Time: 11.23s\n",
      "      Batch: 128 | MAE: 4.2065 | Time: 9.31s\n",
      "      Batch: 256 | MAE: 4.6524 | Time: 9.85s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 2.6358 | Time: 15.64s\n",
      "      Batch: 32  | MAE: 2.9817 | Time: 12.28s\n",
      "      Batch: 64  | MAE: 3.5404 | Time: 11.15s\n",
      "      Batch: 128 | MAE: 4.0828 | Time: 10.27s\n",
      "      Batch: 256 | MAE: 5.4926 | Time: 9.92s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 2.6328 | Time: 15.59s\n",
      "      Batch: 32  | MAE: 2.7445 | Time: 12.35s\n",
      "      Batch: 64  | MAE: 3.2209 | Time: 11.06s\n",
      "      Batch: 128 | MAE: 3.9592 | Time: 10.26s\n",
      "      Batch: 256 | MAE: 4.7907 | Time: 10.02s\n",
      "  Dataset: Iris (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.9000 | Time: 5.52s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 4.66s\n",
      "      Batch: 64  | Accuracy: 0.8333 | Time: 5.11s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 5.93s\n",
      "      Batch: 256 | Accuracy: 0.7333 | Time: 5.63s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 4.95s\n",
      "      Batch: 32  | Accuracy: 0.7333 | Time: 4.75s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 5.39s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 4.51s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 4.47s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | Accuracy: 0.7333 | Time: 3.74s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 3.53s\n",
      "      Batch: 64  | Accuracy: 0.6667 | Time: 3.08s\n",
      "      Batch: 128 | Accuracy: 0.8000 | Time: 3.07s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 3.79s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 4.04s\n",
      "      Batch: 32  | Accuracy: 0.7667 | Time: 3.09s\n",
      "      Batch: 64  | Accuracy: 0.8000 | Time: 3.53s\n",
      "      Batch: 128 | Accuracy: 0.7667 | Time: 4.58s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 10.17s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | Accuracy: 0.7667 | Time: 3.28s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 4.03s\n",
      "      Batch: 64  | Accuracy: 0.7333 | Time: 4.17s\n",
      "      Batch: 128 | Accuracy: 0.8000 | Time: 3.34s\n",
      "      Batch: 256 | Accuracy: 0.6000 | Time: 3.60s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | Accuracy: 0.8000 | Time: 3.24s\n",
      "      Batch: 32  | Accuracy: 0.8000 | Time: 4.07s\n",
      "      Batch: 64  | Accuracy: 0.7667 | Time: 3.54s\n",
      "      Batch: 128 | Accuracy: 0.8000 | Time: 3.61s\n",
      "      Batch: 256 | Accuracy: 0.7667 | Time: 3.82s\n",
      "  Dataset: Wine (classification)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | Accuracy: 0.8611 | Time: 5.37s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 5.27s\n",
      "      Batch: 64  | Accuracy: 0.9722 | Time: 5.36s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 4.87s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 4.92s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | Accuracy: 1.0000 | Time: 5.39s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 5.12s\n",
      "      Batch: 64  | Accuracy: 0.8889 | Time: 5.25s\n",
      "      Batch: 128 | Accuracy: 0.8889 | Time: 6.06s\n",
      "      Batch: 256 | Accuracy: 0.8333 | Time: 4.55s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 3.75s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 3.92s\n",
      "      Batch: 64  | Accuracy: 0.8611 | Time: 3.54s\n",
      "      Batch: 128 | Accuracy: 0.9444 | Time: 4.11s\n",
      "      Batch: 256 | Accuracy: 0.9444 | Time: 4.68s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | Accuracy: 0.8889 | Time: 3.85s\n",
      "      Batch: 32  | Accuracy: 0.9722 | Time: 3.55s\n",
      "      Batch: 64  | Accuracy: 0.9722 | Time: 4.57s\n",
      "      Batch: 128 | Accuracy: 0.8889 | Time: 3.28s\n",
      "      Batch: 256 | Accuracy: 0.8611 | Time: 4.04s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | Accuracy: 0.9167 | Time: 3.55s\n",
      "      Batch: 32  | Accuracy: 0.9444 | Time: 3.45s\n",
      "      Batch: 64  | Accuracy: 0.8333 | Time: 4.03s\n",
      "      Batch: 128 | Accuracy: 0.8611 | Time: 3.69s\n",
      "      Batch: 256 | Accuracy: 0.8889 | Time: 3.92s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | Accuracy: 0.9722 | Time: 3.75s\n",
      "      Batch: 32  | Accuracy: 0.9167 | Time: 3.54s\n",
      "      Batch: 64  | Accuracy: 0.9444 | Time: 3.77s\n",
      "      Batch: 128 | Accuracy: 0.7222 | Time: 3.05s\n",
      "      Batch: 256 | Accuracy: 0.8056 | Time: 3.27s\n",
      "  Dataset: Diabetes (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 43.5065 | Time: 18.61s\n",
      "      Batch: 32  | MAE: 43.2290 | Time: 12.85s\n",
      "      Batch: 64  | MAE: 45.3391 | Time: 13.65s\n",
      "      Batch: 128 | MAE: 54.2836 | Time: 12.51s\n",
      "      Batch: 256 | MAE: 92.0771 | Time: 12.15s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 40.7299 | Time: 17.45s\n",
      "      Batch: 32  | MAE: 44.0479 | Time: 11.87s\n",
      "      Batch: 64  | MAE: 45.5135 | Time: 13.10s\n",
      "      Batch: 128 | MAE: 69.9555 | Time: 12.14s\n",
      "      Batch: 256 | MAE: 91.8503 | Time: 11.81s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 43.9149 | Time: 14.42s\n",
      "      Batch: 32  | MAE: 48.8042 | Time: 12.15s\n",
      "      Batch: 64  | MAE: 56.8994 | Time: 10.99s\n",
      "      Batch: 128 | MAE: 73.0152 | Time: 10.03s\n",
      "      Batch: 256 | MAE: 108.3371 | Time: 9.83s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 43.0116 | Time: 14.63s\n",
      "      Batch: 32  | MAE: 59.0607 | Time: 11.69s\n",
      "      Batch: 64  | MAE: 77.8465 | Time: 10.71s\n",
      "      Batch: 128 | MAE: 98.8548 | Time: 10.13s\n",
      "      Batch: 256 | MAE: 145.7114 | Time: 2.84s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 46.6845 | Time: 14.36s\n",
      "      Batch: 32  | MAE: 51.1767 | Time: 12.05s\n",
      "      Batch: 64  | MAE: 64.6359 | Time: 10.79s\n",
      "      Batch: 128 | MAE: 84.7470 | Time: 10.06s\n",
      "      Batch: 256 | MAE: 111.9642 | Time: 9.98s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 45.8787 | Time: 14.46s\n",
      "      Batch: 32  | MAE: 53.0194 | Time: 12.02s\n",
      "      Batch: 64  | MAE: 57.5830 | Time: 10.87s\n",
      "      Batch: 128 | MAE: 81.0628 | Time: 10.05s\n",
      "      Batch: 256 | MAE: 110.0672 | Time: 10.05s\n",
      "  Dataset: California Housing (regression)\n",
      "    Activation: OptimA\n",
      "      Batch: 16  | MAE: 0.3640 | Time: 264.41s\n",
      "      Batch: 32  | MAE: 0.3670 | Time: 139.00s\n",
      "      Batch: 64  | MAE: 0.3728 | Time: 75.33s\n",
      "      Batch: 128 | MAE: 0.3806 | Time: 43.27s\n",
      "      Batch: 256 | MAE: 0.4012 | Time: 27.48s\n",
      "    Activation: OptimALinear\n",
      "      Batch: 16  | MAE: 0.3774 | Time: 266.38s\n",
      "      Batch: 32  | MAE: 0.3791 | Time: 139.50s\n",
      "      Batch: 64  | MAE: 0.3849 | Time: 75.76s\n",
      "      Batch: 128 | MAE: 0.3907 | Time: 43.70s\n",
      "      Batch: 256 | MAE: 0.3977 | Time: 27.57s\n",
      "    Activation: ReLU\n",
      "      Batch: 16  | MAE: 0.3703 | Time: 254.33s\n",
      "      Batch: 32  | MAE: 0.3702 | Time: 128.07s\n",
      "      Batch: 64  | MAE: 0.3731 | Time: 67.88s\n",
      "      Batch: 128 | MAE: 0.3750 | Time: 40.34s\n",
      "      Batch: 256 | MAE: 0.3849 | Time: 24.98s\n",
      "    Activation: ELU\n",
      "      Batch: 16  | MAE: 0.3935 | Time: 245.13s\n",
      "      Batch: 32  | MAE: 0.3964 | Time: 127.95s\n",
      "      Batch: 64  | MAE: 0.4078 | Time: 68.12s\n",
      "      Batch: 128 | MAE: 0.4071 | Time: 38.99s\n",
      "      Batch: 256 | MAE: 0.4368 | Time: 24.47s\n",
      "    Activation: Swish\n",
      "      Batch: 16  | MAE: 0.3978 | Time: 241.34s\n",
      "      Batch: 32  | MAE: 0.4014 | Time: 126.79s\n",
      "      Batch: 64  | MAE: 0.4123 | Time: 68.21s\n",
      "      Batch: 128 | MAE: 0.4175 | Time: 39.02s\n",
      "      Batch: 256 | MAE: 0.4213 | Time: 24.11s\n",
      "    Activation: GeLU\n",
      "      Batch: 16  | MAE: 0.3882 | Time: 240.99s\n",
      "      Batch: 32  | MAE: 0.3888 | Time: 125.55s\n",
      "      Batch: 64  | MAE: 0.3910 | Time: 67.87s\n",
      "      Batch: 128 | MAE: 0.4104 | Time: 38.75s\n",
      "      Batch: 256 | MAE: 0.4055 | Time: 24.32s\n",
      "\n",
      "--- Experiment Finished ---\n",
      "Total time: 20664.24 seconds (344.40 minutes)\n"
     ]
    }
   ],
   "source": [
    "# --- Activation Functions Dictionary ---\n",
    "# We need to instantiate custom layers inside the loop later,\n",
    "# so we store either the class or string name here.\n",
    "activations_to_test = {\n",
    "    'OptimA': OptimA, # Store class\n",
    "    'OptimALinear': OptimALinear, # Store class\n",
    "    'ReLU': 'relu',\n",
    "    'ELU': 'elu',\n",
    "    'Swish': 'swish',\n",
    "    'GeLU': 'gelu'\n",
    "}\n",
    "\n",
    "# --- Results Storage ---\n",
    "# Structure: results[dataset_name][activation_name][batch_size] = [list_of_scores_from_seeds]\n",
    "results = {\n",
    "    ds_name: {\n",
    "        act_name: {\n",
    "            bs: [] for bs in BATCH_SIZES\n",
    "        } for act_name in activations_to_test.keys()\n",
    "    } for ds_name in datasets_config.keys()\n",
    "}\n",
    "\n",
    "# --- Main Experiment Loop ---\n",
    "print(\"\\n--- Starting Experiment ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"\\n--- Running Seed {i+1}/{N_SEEDS} (Seed: {seed}) ---\")\n",
    "    set_seed(seed) # Set seed for this specific run's TF/Numpy operations\n",
    "\n",
    "    for ds_name, ds_config in datasets_config.items():\n",
    "        print(f\"  Dataset: {ds_name} ({ds_config['task_type']})\")\n",
    "        x_train, y_train, x_test, y_test = ds_config['data']\n",
    "        task_type = ds_config['task_type']\n",
    "        metric_name = ds_config['metric_name']\n",
    "\n",
    "        for act_name, activation_ref in activations_to_test.items():\n",
    "            print(f\"    Activation: {act_name}\")\n",
    "\n",
    "            for bs in BATCH_SIZES:\n",
    "                # print(f\"      Batch Size: {bs} ... \", end=\"\")\n",
    "                run_start_time = time.time()\n",
    "\n",
    "                # Instantiate custom layers here for each trial to reset their state\n",
    "                if activation_ref == OptimA:\n",
    "                    activation_instance = OptimA()\n",
    "                elif activation_ref == OptimALinear:\n",
    "                    activation_instance = OptimALinear()\n",
    "                else:\n",
    "                    activation_instance = activation_ref # Use string name directly\n",
    "\n",
    "                # Build, train, and evaluate\n",
    "                score = build_and_evaluate_model(\n",
    "                    x_train, y_train, x_test, y_test,\n",
    "                    activation_instance=activation_instance,\n",
    "                    task_type=task_type,\n",
    "                    batch_size=bs\n",
    "                )\n",
    "\n",
    "                run_end_time = time.time()\n",
    "                run_duration = run_end_time - run_start_time\n",
    "\n",
    "                # Store the result\n",
    "                results[ds_name][act_name][bs].append(score)\n",
    "\n",
    "                # Print result for this run\n",
    "                if not np.isnan(score):\n",
    "                    # print(f\"Score ({metric_name}): {score:.4f} (Time: {run_duration:.2f}s)\")\n",
    "                     print(f\"      Batch: {bs:<3} | {metric_name}: {score:.4f} | Time: {run_duration:.2f}s\")\n",
    "                else:\n",
    "                    # print(\"Failed.\")\n",
    "                     print(f\"      Batch: {bs:<3} | Failed.\")\n",
    "\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "print(f\"\\n--- Experiment Finished ---\")\n",
    "print(f\"Total time: {total_duration:.2f} seconds ({total_duration/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23b4b535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T11:52:18.432788Z",
     "iopub.status.busy": "2025-05-13T11:52:18.432543Z",
     "iopub.status.idle": "2025-05-13T11:52:18.461038Z",
     "shell.execute_reply": "2025-05-13T11:52:18.460460Z"
    },
    "papermill": {
     "duration": 0.061233,
     "end_time": "2025-05-13T11:52:18.462024",
     "exception": false,
     "start_time": "2025-05-13T11:52:18.400791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Results ---\n",
      "\n",
      "--- Aggregated Results Table ---\n",
      "Metrics averaged over 5 seeds.\n",
      "Note: 'Best' means highest Accuracy for Classification, lowest MAE for Regression.\n"
     ]
    }
   ],
   "source": [
    "# --- Process and Display Results ---\n",
    "print(\"\\n--- Processing Results ---\")\n",
    "\n",
    "processed_results = []\n",
    "\n",
    "for ds_name, ds_results in results.items():\n",
    "    task_type = datasets_config[ds_name]['task_type']\n",
    "    metric_name = datasets_config[ds_name]['metric_name']\n",
    "    # Determine if higher score is better (classification) or lower is better (regression)\n",
    "    higher_is_better = (task_type == 'classification')\n",
    "\n",
    "    for act_name, act_results in ds_results.items():\n",
    "        for bs, scores in act_results.items():\n",
    "            valid_scores = [s for s in scores if not np.isnan(s)] # Filter out NaNs\n",
    "            if not valid_scores:\n",
    "                mean_score, best_score, worst_score = np.nan, np.nan, np.nan\n",
    "                num_successful_runs = 0\n",
    "            else:\n",
    "                mean_score = np.mean(valid_scores)\n",
    "                num_successful_runs = len(valid_scores)\n",
    "                if higher_is_better:\n",
    "                    best_score = np.max(valid_scores)\n",
    "                    worst_score = np.min(valid_scores)\n",
    "                else: # Lower is better (MAE)\n",
    "                    best_score = np.min(valid_scores)\n",
    "                    worst_score = np.max(valid_scores)\n",
    "\n",
    "            processed_results.append({\n",
    "                'Dataset': ds_name,\n",
    "                'Activation': act_name,\n",
    "                'Batch Size': bs,\n",
    "                f'Mean {metric_name}': mean_score,\n",
    "                f'Best {metric_name}': best_score,\n",
    "                f'Worst {metric_name}': worst_score,\n",
    "                'Successful Runs': f\"{num_successful_runs}/{N_SEEDS}\"\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(processed_results)\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"\\n--- Aggregated Results Table ---\")\n",
    "print(f\"Metrics averaged over {N_SEEDS} seeds.\")\n",
    "print(f\"Note: 'Best' means highest Accuracy for Classification, lowest MAE for Regression.\")\n",
    "\n",
    "# Display sorted results (e.g., by Dataset, then Mean Score)\n",
    "# Adjust sorting based on what comparison is most important\n",
    "# Example: Sort by Dataset, then Activation, then Batch Size\n",
    "results_df_sorted = results_df.sort_values(by=['Dataset', 'Activation', 'Batch Size'])\n",
    "\n",
    "# Or sort to find the best performing overall (example for classification)\n",
    "# results_df_sorted = results_df.sort_values(by=['Mean Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7062dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T11:52:18.530499Z",
     "iopub.status.busy": "2025-05-13T11:52:18.530135Z",
     "iopub.status.idle": "2025-05-13T11:52:18.549159Z",
     "shell.execute_reply": "2025-05-13T11:52:18.548189Z"
    },
    "papermill": {
     "duration": 0.0585,
     "end_time": "2025-05-13T11:52:18.550978",
     "exception": false,
     "start_time": "2025-05-13T11:52:18.492478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Dataset   Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "    Boston Housing          ELU          16    2.7799    2.4567     3.9988             5/5            NaN            NaN             NaN\n",
      "    Boston Housing          ELU          32    3.5522    2.6957     4.3292             5/5            NaN            NaN             NaN\n",
      "    Boston Housing          ELU          64    3.4586    3.3097     3.6387             5/5            NaN            NaN             NaN\n",
      "    Boston Housing          ELU         128    4.0459    3.9171     4.2065             5/5            NaN            NaN             NaN\n",
      "    Boston Housing          ELU         256    4.4595    4.3622     4.6524             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         GeLU          16    2.6043    2.5611     2.6328             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         GeLU          32    2.7630    2.7131     2.8319             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         GeLU          64    3.2614    3.1860     3.3961             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         GeLU         128    3.9314    3.7085     4.0925             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         GeLU         256    4.8427    4.4726     5.1516             5/5            NaN            NaN             NaN\n",
      "    Boston Housing       OptimA          16    2.9705    2.5000     3.4083             5/5            NaN            NaN             NaN\n",
      "    Boston Housing       OptimA          32    3.0574    2.6524     3.3728             5/5            NaN            NaN             NaN\n",
      "    Boston Housing       OptimA          64    3.2811    2.9597     3.5091             5/5            NaN            NaN             NaN\n",
      "    Boston Housing       OptimA         128    3.6409    3.4899     3.7900             5/5            NaN            NaN             NaN\n",
      "    Boston Housing       OptimA         256    3.6971    3.4792     3.8940             5/5            NaN            NaN             NaN\n",
      "    Boston Housing OptimALinear          16    2.3359    2.2925     2.4264             5/5            NaN            NaN             NaN\n",
      "    Boston Housing OptimALinear          32    2.8028    2.4301     4.1581             5/5            NaN            NaN             NaN\n",
      "    Boston Housing OptimALinear          64    2.9331    2.7020     3.1649             5/5            NaN            NaN             NaN\n",
      "    Boston Housing OptimALinear         128    4.2911    4.1789     4.4692             5/5            NaN            NaN             NaN\n",
      "    Boston Housing OptimALinear         256    3.9876    3.7134     4.2506             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         ReLU          16    2.6056    2.5436     2.6477             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         ReLU          32    2.7938    2.6886     2.8813             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         ReLU          64    3.4001    3.2627     3.5080             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         ReLU         128    3.9660    3.8084     4.1029             5/5            NaN            NaN             NaN\n",
      "    Boston Housing         ReLU         256    4.6149    4.4695     4.7299             5/5            NaN            NaN             NaN\n",
      "    Boston Housing        Swish          16    2.6105    2.5141     2.6686             5/5            NaN            NaN             NaN\n",
      "    Boston Housing        Swish          32    2.8722    2.7602     2.9817             5/5            NaN            NaN             NaN\n",
      "    Boston Housing        Swish          64    3.5505    3.4895     3.6575             5/5            NaN            NaN             NaN\n",
      "    Boston Housing        Swish         128    4.1704    4.0828     4.2202             5/5            NaN            NaN             NaN\n",
      "    Boston Housing        Swish         256    5.2084    4.8829     5.4926             5/5            NaN            NaN             NaN\n",
      "California Housing          ELU          16    0.4004    0.3935     0.4122             5/5            NaN            NaN             NaN\n",
      "California Housing          ELU          32    0.3986    0.3962     0.4024             5/5            NaN            NaN             NaN\n",
      "California Housing          ELU          64    0.4044    0.4012     0.4078             5/5            NaN            NaN             NaN\n",
      "California Housing          ELU         128    0.4130    0.4071     0.4166             5/5            NaN            NaN             NaN\n",
      "California Housing          ELU         256    0.4302    0.4235     0.4368             5/5            NaN            NaN             NaN\n",
      "California Housing         GeLU          16    0.3888    0.3874     0.3918             5/5            NaN            NaN             NaN\n",
      "California Housing         GeLU          32    0.3888    0.3870     0.3910             5/5            NaN            NaN             NaN\n",
      "California Housing         GeLU          64    0.3917    0.3906     0.3931             5/5            NaN            NaN             NaN\n",
      "California Housing         GeLU         128    0.4015    0.3955     0.4104             5/5            NaN            NaN             NaN\n",
      "California Housing         GeLU         256    0.4097    0.4037     0.4160             5/5            NaN            NaN             NaN\n",
      "California Housing       OptimA          16    0.3710    0.3640     0.3886             5/5            NaN            NaN             NaN\n",
      "California Housing       OptimA          32    0.3745    0.3670     0.3810             5/5            NaN            NaN             NaN\n",
      "California Housing       OptimA          64    0.3757    0.3723     0.3802             5/5            NaN            NaN             NaN\n",
      "California Housing       OptimA         128    0.3832    0.3806     0.3863             5/5            NaN            NaN             NaN\n",
      "California Housing       OptimA         256    0.4013    0.3880     0.4134             5/5            NaN            NaN             NaN\n",
      "California Housing OptimALinear          16    0.3753    0.3694     0.3800             5/5            NaN            NaN             NaN\n",
      "California Housing OptimALinear          32    0.3796    0.3749     0.3850             5/5            NaN            NaN             NaN\n",
      "California Housing OptimALinear          64    0.3857    0.3779     0.3895             5/5            NaN            NaN             NaN\n",
      "California Housing OptimALinear         128    0.3889    0.3853     0.3913             5/5            NaN            NaN             NaN\n",
      "California Housing OptimALinear         256    0.4004    0.3941     0.4116             5/5            NaN            NaN             NaN\n",
      "California Housing         ReLU          16    0.3703    0.3654     0.3730             5/5            NaN            NaN             NaN\n",
      "California Housing         ReLU          32    0.3739    0.3702     0.3777             5/5            NaN            NaN             NaN\n",
      "California Housing         ReLU          64    0.3783    0.3731     0.3815             5/5            NaN            NaN             NaN\n",
      "California Housing         ReLU         128    0.3818    0.3750     0.3850             5/5            NaN            NaN             NaN\n",
      "California Housing         ReLU         256    0.3871    0.3849     0.3885             5/5            NaN            NaN             NaN\n",
      "California Housing        Swish          16    0.4004    0.3978     0.4054             5/5            NaN            NaN             NaN\n",
      "California Housing        Swish          32    0.4012    0.4003     0.4017             5/5            NaN            NaN             NaN\n",
      "California Housing        Swish          64    0.4128    0.4096     0.4161             5/5            NaN            NaN             NaN\n",
      "California Housing        Swish         128    0.4185    0.4160     0.4220             5/5            NaN            NaN             NaN\n",
      "California Housing        Swish         256    0.4237    0.4213     0.4252             5/5            NaN            NaN             NaN\n",
      "          Diabetes          ELU          16   42.6391   41.9016    43.4561             5/5            NaN            NaN             NaN\n",
      "          Diabetes          ELU          32   51.8875   48.9179    59.0607             5/5            NaN            NaN             NaN\n",
      "          Diabetes          ELU          64   78.5159   74.5949    80.6632             5/5            NaN            NaN             NaN\n",
      "          Diabetes          ELU         128  106.8891   96.3525   143.8722             5/5            NaN            NaN             NaN\n",
      "          Diabetes          ELU         256  134.7391  118.2005   145.7923             5/5            NaN            NaN             NaN\n",
      "          Diabetes         GeLU          16   45.5720   44.8023    45.8787             5/5            NaN            NaN             NaN\n",
      "          Diabetes         GeLU          32   52.1535   50.8366    53.8419             5/5            NaN            NaN             NaN\n",
      "          Diabetes         GeLU          64   58.1883   56.6328    60.9300             5/5            NaN            NaN             NaN\n",
      "          Diabetes         GeLU         128   80.4784   76.6272    84.4243             5/5            NaN            NaN             NaN\n",
      "          Diabetes         GeLU         256  111.6876  107.7615   115.4971             5/5            NaN            NaN             NaN\n",
      "          Diabetes       OptimA          16   43.6069   43.0209    44.5691             5/5            NaN            NaN             NaN\n",
      "          Diabetes       OptimA          32   43.4453   43.0594    44.0088             5/5            NaN            NaN             NaN\n",
      "          Diabetes       OptimA          64   45.3624   44.7841    45.7388             5/5            NaN            NaN             NaN\n",
      "          Diabetes       OptimA         128   56.9064   54.2836    60.1412             5/5            NaN            NaN             NaN\n",
      "          Diabetes       OptimA         256   92.7638   90.5704    95.0234             5/5            NaN            NaN             NaN\n",
      "          Diabetes OptimALinear          16   42.2429   40.7299    43.4942             5/5            NaN            NaN             NaN\n",
      "          Diabetes OptimALinear          32   42.9090   41.1393    44.6864             5/5            NaN            NaN             NaN\n",
      "          Diabetes OptimALinear          64   44.4366   43.5454    45.5135             5/5            NaN            NaN             NaN\n",
      "          Diabetes OptimALinear         128   68.6150   59.9953    78.1867             5/5            NaN            NaN             NaN\n",
      "          Diabetes OptimALinear         256  101.6776   87.8760   145.7749             5/5            NaN            NaN             NaN\n",
      "          Diabetes         ReLU          16   43.6420   42.6984    44.0663             5/5            NaN            NaN             NaN\n",
      "          Diabetes         ReLU          32   49.4488   48.8042    50.6882             5/5            NaN            NaN             NaN\n",
      "          Diabetes         ReLU          64   55.3266   53.7651    56.8994             5/5            NaN            NaN             NaN\n",
      "          Diabetes         ReLU         128   73.7352   71.3999    75.7971             5/5            NaN            NaN             NaN\n",
      "          Diabetes         ReLU         256  110.0617  108.3371   111.8510             5/5            NaN            NaN             NaN\n",
      "          Diabetes        Swish          16   45.2553   43.4773    46.6845             5/5            NaN            NaN             NaN\n",
      "          Diabetes        Swish          32   50.6816   48.6125    52.0265             5/5            NaN            NaN             NaN\n",
      "          Diabetes        Swish          64   64.3044   60.8682    70.8184             5/5            NaN            NaN             NaN\n",
      "          Diabetes        Swish         128   84.5019   80.9857    86.1812             5/5            NaN            NaN             NaN\n",
      "          Diabetes        Swish         256  112.2996  110.2315   114.8628             5/5            NaN            NaN             NaN\n",
      "              Iris          ELU          16       NaN       NaN        NaN             5/5         0.8067         0.9000          0.7333\n",
      "              Iris          ELU          32       NaN       NaN        NaN             5/5         0.7800         0.8000          0.7667\n",
      "              Iris          ELU          64       NaN       NaN        NaN             5/5         0.7600         0.8000          0.7000\n",
      "              Iris          ELU         128       NaN       NaN        NaN             5/5         0.7467         0.7667          0.7000\n",
      "              Iris          ELU         256       NaN       NaN        NaN             5/5         0.7200         0.8000          0.5333\n",
      "              Iris         GeLU          16       NaN       NaN        NaN             5/5         0.7800         0.8000          0.7667\n",
      "              Iris         GeLU          32       NaN       NaN        NaN             5/5         0.7533         0.8000          0.6333\n",
      "              Iris         GeLU          64       NaN       NaN        NaN             5/5         0.7400         0.8000          0.6667\n",
      "              Iris         GeLU         128       NaN       NaN        NaN             5/5         0.6867         0.8000          0.6000\n",
      "              Iris         GeLU         256       NaN       NaN        NaN             5/5         0.7467         0.8000          0.6667\n",
      "              Iris       OptimA          16       NaN       NaN        NaN             5/5         0.8533         0.9667          0.8000\n",
      "              Iris       OptimA          32       NaN       NaN        NaN             5/5         0.7733         0.8000          0.6667\n",
      "              Iris       OptimA          64       NaN       NaN        NaN             5/5         0.7467         0.8333          0.6000\n",
      "              Iris       OptimA         128       NaN       NaN        NaN             5/5         0.7600         0.8000          0.7333\n",
      "              Iris       OptimA         256       NaN       NaN        NaN             5/5         0.6400         0.7667          0.3333\n",
      "              Iris OptimALinear          16       NaN       NaN        NaN             5/5         0.8067         0.9000          0.7333\n",
      "              Iris OptimALinear          32       NaN       NaN        NaN             5/5         0.7600         0.8333          0.7333\n",
      "              Iris OptimALinear          64       NaN       NaN        NaN             5/5         0.7733         0.8000          0.7333\n",
      "              Iris OptimALinear         128       NaN       NaN        NaN             5/5         0.7200         0.7667          0.6000\n",
      "              Iris OptimALinear         256       NaN       NaN        NaN             5/5         0.6933         0.7667          0.6000\n",
      "              Iris         ReLU          16       NaN       NaN        NaN             5/5         0.7867         0.8667          0.7333\n",
      "              Iris         ReLU          32       NaN       NaN        NaN             5/5         0.7667         0.8000          0.7333\n",
      "              Iris         ReLU          64       NaN       NaN        NaN             5/5         0.7133         0.7667          0.6667\n",
      "              Iris         ReLU         128       NaN       NaN        NaN             5/5         0.6333         0.8000          0.3667\n",
      "              Iris         ReLU         256       NaN       NaN        NaN             5/5         0.6733         0.8333          0.4000\n",
      "              Iris        Swish          16       NaN       NaN        NaN             5/5         0.7400         0.8000          0.5667\n",
      "              Iris        Swish          32       NaN       NaN        NaN             5/5         0.7533         0.8000          0.7000\n",
      "              Iris        Swish          64       NaN       NaN        NaN             5/5         0.7400         0.7667          0.7000\n",
      "              Iris        Swish         128       NaN       NaN        NaN             5/5         0.6667         0.8000          0.4000\n",
      "              Iris        Swish         256       NaN       NaN        NaN             5/5         0.6933         0.7667          0.6000\n",
      "              Wine          ELU          16       NaN       NaN        NaN             5/5         0.9333         0.9722          0.8889\n",
      "              Wine          ELU          32       NaN       NaN        NaN             5/5         0.9389         0.9722          0.8889\n",
      "              Wine          ELU          64       NaN       NaN        NaN             5/5         0.9500         1.0000          0.8611\n",
      "              Wine          ELU         128       NaN       NaN        NaN             5/5         0.9000         0.9722          0.8611\n",
      "              Wine          ELU         256       NaN       NaN        NaN             5/5         0.8667         0.9167          0.8333\n",
      "              Wine         GeLU          16       NaN       NaN        NaN             5/5         0.9667         1.0000          0.9444\n",
      "              Wine         GeLU          32       NaN       NaN        NaN             5/5         0.9333         0.9722          0.8889\n",
      "              Wine         GeLU          64       NaN       NaN        NaN             5/5         0.9444         1.0000          0.8611\n",
      "              Wine         GeLU         128       NaN       NaN        NaN             5/5         0.8611         1.0000          0.7222\n",
      "              Wine         GeLU         256       NaN       NaN        NaN             5/5         0.8944         0.9444          0.8056\n",
      "              Wine       OptimA          16       NaN       NaN        NaN             5/5         0.9333         1.0000          0.8611\n",
      "              Wine       OptimA          32       NaN       NaN        NaN             5/5         0.9278         0.9722          0.8611\n",
      "              Wine       OptimA          64       NaN       NaN        NaN             5/5         0.9444         0.9722          0.8889\n",
      "              Wine       OptimA         128       NaN       NaN        NaN             5/5         0.8944         0.9444          0.8611\n",
      "              Wine       OptimA         256       NaN       NaN        NaN             5/5         0.9167         0.9722          0.8611\n",
      "              Wine OptimALinear          16       NaN       NaN        NaN             5/5         0.9722         1.0000          0.9444\n",
      "              Wine OptimALinear          32       NaN       NaN        NaN             5/5         0.9500         0.9722          0.9167\n",
      "              Wine OptimALinear          64       NaN       NaN        NaN             5/5         0.9056         0.9167          0.8889\n",
      "              Wine OptimALinear         128       NaN       NaN        NaN             5/5         0.8944         0.9722          0.8056\n",
      "              Wine OptimALinear         256       NaN       NaN        NaN             5/5         0.8833         0.9722          0.8333\n",
      "              Wine         ReLU          16       NaN       NaN        NaN             5/5         0.9500         1.0000          0.9167\n",
      "              Wine         ReLU          32       NaN       NaN        NaN             5/5         0.9556         1.0000          0.8889\n",
      "              Wine         ReLU          64       NaN       NaN        NaN             5/5         0.9333         1.0000          0.8611\n",
      "              Wine         ReLU         128       NaN       NaN        NaN             5/5         0.9222         0.9722          0.8611\n",
      "              Wine         ReLU         256       NaN       NaN        NaN             5/5         0.8833         0.9444          0.8056\n",
      "              Wine        Swish          16       NaN       NaN        NaN             5/5         0.8944         0.9722          0.8056\n",
      "              Wine        Swish          32       NaN       NaN        NaN             5/5         0.9000         0.9444          0.8333\n",
      "              Wine        Swish          64       NaN       NaN        NaN             5/5         0.8889         0.9167          0.8333\n",
      "              Wine        Swish         128       NaN       NaN        NaN             5/5         0.8556         0.9167          0.8056\n",
      "              Wine        Swish         256       NaN       NaN        NaN             5/5         0.8722         0.8889          0.8611\n"
     ]
    }
   ],
   "source": [
    "print(results_df_sorted.to_string(index=False, float_format=\"%.4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a899dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T11:52:18.622662Z",
     "iopub.status.busy": "2025-05-13T11:52:18.622439Z",
     "iopub.status.idle": "2025-05-13T11:52:18.646829Z",
     "shell.execute_reply": "2025-05-13T11:52:18.646190Z"
    },
    "papermill": {
     "duration": 0.057144,
     "end_time": "2025-05-13T11:52:18.648049",
     "exception": false,
     "start_time": "2025-05-13T11:52:18.590905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results Grouped by Dataset ---\n",
      "\n",
      "--- Boston Housing ---\n",
      "       Dataset   Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "Boston Housing OptimALinear          16    2.3359    2.2925     2.4264             5/5            NaN            NaN             NaN\n",
      "Boston Housing         GeLU          16    2.6043    2.5611     2.6328             5/5            NaN            NaN             NaN\n",
      "Boston Housing         ReLU          16    2.6056    2.5436     2.6477             5/5            NaN            NaN             NaN\n",
      "Boston Housing        Swish          16    2.6105    2.5141     2.6686             5/5            NaN            NaN             NaN\n",
      "Boston Housing         GeLU          32    2.7630    2.7131     2.8319             5/5            NaN            NaN             NaN\n",
      "Boston Housing          ELU          16    2.7799    2.4567     3.9988             5/5            NaN            NaN             NaN\n",
      "Boston Housing         ReLU          32    2.7938    2.6886     2.8813             5/5            NaN            NaN             NaN\n",
      "Boston Housing OptimALinear          32    2.8028    2.4301     4.1581             5/5            NaN            NaN             NaN\n",
      "Boston Housing        Swish          32    2.8722    2.7602     2.9817             5/5            NaN            NaN             NaN\n",
      "Boston Housing OptimALinear          64    2.9331    2.7020     3.1649             5/5            NaN            NaN             NaN\n",
      "Boston Housing       OptimA          16    2.9705    2.5000     3.4083             5/5            NaN            NaN             NaN\n",
      "Boston Housing       OptimA          32    3.0574    2.6524     3.3728             5/5            NaN            NaN             NaN\n",
      "Boston Housing         GeLU          64    3.2614    3.1860     3.3961             5/5            NaN            NaN             NaN\n",
      "Boston Housing       OptimA          64    3.2811    2.9597     3.5091             5/5            NaN            NaN             NaN\n",
      "Boston Housing         ReLU          64    3.4001    3.2627     3.5080             5/5            NaN            NaN             NaN\n",
      "Boston Housing          ELU          64    3.4586    3.3097     3.6387             5/5            NaN            NaN             NaN\n",
      "Boston Housing        Swish          64    3.5505    3.4895     3.6575             5/5            NaN            NaN             NaN\n",
      "Boston Housing          ELU          32    3.5522    2.6957     4.3292             5/5            NaN            NaN             NaN\n",
      "Boston Housing       OptimA         128    3.6409    3.4899     3.7900             5/5            NaN            NaN             NaN\n",
      "Boston Housing       OptimA         256    3.6971    3.4792     3.8940             5/5            NaN            NaN             NaN\n",
      "Boston Housing         GeLU         128    3.9314    3.7085     4.0925             5/5            NaN            NaN             NaN\n",
      "Boston Housing         ReLU         128    3.9660    3.8084     4.1029             5/5            NaN            NaN             NaN\n",
      "Boston Housing OptimALinear         256    3.9876    3.7134     4.2506             5/5            NaN            NaN             NaN\n",
      "Boston Housing          ELU         128    4.0459    3.9171     4.2065             5/5            NaN            NaN             NaN\n",
      "Boston Housing        Swish         128    4.1704    4.0828     4.2202             5/5            NaN            NaN             NaN\n",
      "Boston Housing OptimALinear         128    4.2911    4.1789     4.4692             5/5            NaN            NaN             NaN\n",
      "Boston Housing          ELU         256    4.4595    4.3622     4.6524             5/5            NaN            NaN             NaN\n",
      "Boston Housing         ReLU         256    4.6149    4.4695     4.7299             5/5            NaN            NaN             NaN\n",
      "Boston Housing         GeLU         256    4.8427    4.4726     5.1516             5/5            NaN            NaN             NaN\n",
      "Boston Housing        Swish         256    5.2084    4.8829     5.4926             5/5            NaN            NaN             NaN\n",
      "\n",
      "--- Iris ---\n",
      "Dataset   Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "   Iris          ELU          16       NaN       NaN        NaN             5/5         0.8067         0.9000          0.7333\n",
      "   Iris          ELU          32       NaN       NaN        NaN             5/5         0.7800         0.8000          0.7667\n",
      "   Iris          ELU          64       NaN       NaN        NaN             5/5         0.7600         0.8000          0.7000\n",
      "   Iris          ELU         128       NaN       NaN        NaN             5/5         0.7467         0.7667          0.7000\n",
      "   Iris          ELU         256       NaN       NaN        NaN             5/5         0.7200         0.8000          0.5333\n",
      "   Iris         GeLU          16       NaN       NaN        NaN             5/5         0.7800         0.8000          0.7667\n",
      "   Iris         GeLU          32       NaN       NaN        NaN             5/5         0.7533         0.8000          0.6333\n",
      "   Iris         GeLU          64       NaN       NaN        NaN             5/5         0.7400         0.8000          0.6667\n",
      "   Iris         GeLU         128       NaN       NaN        NaN             5/5         0.6867         0.8000          0.6000\n",
      "   Iris         GeLU         256       NaN       NaN        NaN             5/5         0.7467         0.8000          0.6667\n",
      "   Iris       OptimA          16       NaN       NaN        NaN             5/5         0.8533         0.9667          0.8000\n",
      "   Iris       OptimA          32       NaN       NaN        NaN             5/5         0.7733         0.8000          0.6667\n",
      "   Iris       OptimA          64       NaN       NaN        NaN             5/5         0.7467         0.8333          0.6000\n",
      "   Iris       OptimA         128       NaN       NaN        NaN             5/5         0.7600         0.8000          0.7333\n",
      "   Iris       OptimA         256       NaN       NaN        NaN             5/5         0.6400         0.7667          0.3333\n",
      "   Iris OptimALinear          16       NaN       NaN        NaN             5/5         0.8067         0.9000          0.7333\n",
      "   Iris OptimALinear          32       NaN       NaN        NaN             5/5         0.7600         0.8333          0.7333\n",
      "   Iris OptimALinear          64       NaN       NaN        NaN             5/5         0.7733         0.8000          0.7333\n",
      "   Iris OptimALinear         128       NaN       NaN        NaN             5/5         0.7200         0.7667          0.6000\n",
      "   Iris OptimALinear         256       NaN       NaN        NaN             5/5         0.6933         0.7667          0.6000\n",
      "   Iris         ReLU          16       NaN       NaN        NaN             5/5         0.7867         0.8667          0.7333\n",
      "   Iris         ReLU          32       NaN       NaN        NaN             5/5         0.7667         0.8000          0.7333\n",
      "   Iris         ReLU          64       NaN       NaN        NaN             5/5         0.7133         0.7667          0.6667\n",
      "   Iris         ReLU         128       NaN       NaN        NaN             5/5         0.6333         0.8000          0.3667\n",
      "   Iris         ReLU         256       NaN       NaN        NaN             5/5         0.6733         0.8333          0.4000\n",
      "   Iris        Swish          16       NaN       NaN        NaN             5/5         0.7400         0.8000          0.5667\n",
      "   Iris        Swish          32       NaN       NaN        NaN             5/5         0.7533         0.8000          0.7000\n",
      "   Iris        Swish          64       NaN       NaN        NaN             5/5         0.7400         0.7667          0.7000\n",
      "   Iris        Swish         128       NaN       NaN        NaN             5/5         0.6667         0.8000          0.4000\n",
      "   Iris        Swish         256       NaN       NaN        NaN             5/5         0.6933         0.7667          0.6000\n",
      "\n",
      "--- Wine ---\n",
      "Dataset   Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "   Wine          ELU          16       NaN       NaN        NaN             5/5         0.9333         0.9722          0.8889\n",
      "   Wine          ELU          32       NaN       NaN        NaN             5/5         0.9389         0.9722          0.8889\n",
      "   Wine          ELU          64       NaN       NaN        NaN             5/5         0.9500         1.0000          0.8611\n",
      "   Wine          ELU         128       NaN       NaN        NaN             5/5         0.9000         0.9722          0.8611\n",
      "   Wine          ELU         256       NaN       NaN        NaN             5/5         0.8667         0.9167          0.8333\n",
      "   Wine         GeLU          16       NaN       NaN        NaN             5/5         0.9667         1.0000          0.9444\n",
      "   Wine         GeLU          32       NaN       NaN        NaN             5/5         0.9333         0.9722          0.8889\n",
      "   Wine         GeLU          64       NaN       NaN        NaN             5/5         0.9444         1.0000          0.8611\n",
      "   Wine         GeLU         128       NaN       NaN        NaN             5/5         0.8611         1.0000          0.7222\n",
      "   Wine         GeLU         256       NaN       NaN        NaN             5/5         0.8944         0.9444          0.8056\n",
      "   Wine       OptimA          16       NaN       NaN        NaN             5/5         0.9333         1.0000          0.8611\n",
      "   Wine       OptimA          32       NaN       NaN        NaN             5/5         0.9278         0.9722          0.8611\n",
      "   Wine       OptimA          64       NaN       NaN        NaN             5/5         0.9444         0.9722          0.8889\n",
      "   Wine       OptimA         128       NaN       NaN        NaN             5/5         0.8944         0.9444          0.8611\n",
      "   Wine       OptimA         256       NaN       NaN        NaN             5/5         0.9167         0.9722          0.8611\n",
      "   Wine OptimALinear          16       NaN       NaN        NaN             5/5         0.9722         1.0000          0.9444\n",
      "   Wine OptimALinear          32       NaN       NaN        NaN             5/5         0.9500         0.9722          0.9167\n",
      "   Wine OptimALinear          64       NaN       NaN        NaN             5/5         0.9056         0.9167          0.8889\n",
      "   Wine OptimALinear         128       NaN       NaN        NaN             5/5         0.8944         0.9722          0.8056\n",
      "   Wine OptimALinear         256       NaN       NaN        NaN             5/5         0.8833         0.9722          0.8333\n",
      "   Wine         ReLU          16       NaN       NaN        NaN             5/5         0.9500         1.0000          0.9167\n",
      "   Wine         ReLU          32       NaN       NaN        NaN             5/5         0.9556         1.0000          0.8889\n",
      "   Wine         ReLU          64       NaN       NaN        NaN             5/5         0.9333         1.0000          0.8611\n",
      "   Wine         ReLU         128       NaN       NaN        NaN             5/5         0.9222         0.9722          0.8611\n",
      "   Wine         ReLU         256       NaN       NaN        NaN             5/5         0.8833         0.9444          0.8056\n",
      "   Wine        Swish          16       NaN       NaN        NaN             5/5         0.8944         0.9722          0.8056\n",
      "   Wine        Swish          32       NaN       NaN        NaN             5/5         0.9000         0.9444          0.8333\n",
      "   Wine        Swish          64       NaN       NaN        NaN             5/5         0.8889         0.9167          0.8333\n",
      "   Wine        Swish         128       NaN       NaN        NaN             5/5         0.8556         0.9167          0.8056\n",
      "   Wine        Swish         256       NaN       NaN        NaN             5/5         0.8722         0.8889          0.8611\n",
      "\n",
      "--- Diabetes ---\n",
      " Dataset   Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "Diabetes OptimALinear          16   42.2429   40.7299    43.4942             5/5            NaN            NaN             NaN\n",
      "Diabetes          ELU          16   42.6391   41.9016    43.4561             5/5            NaN            NaN             NaN\n",
      "Diabetes OptimALinear          32   42.9090   41.1393    44.6864             5/5            NaN            NaN             NaN\n",
      "Diabetes       OptimA          32   43.4453   43.0594    44.0088             5/5            NaN            NaN             NaN\n",
      "Diabetes       OptimA          16   43.6069   43.0209    44.5691             5/5            NaN            NaN             NaN\n",
      "Diabetes         ReLU          16   43.6420   42.6984    44.0663             5/5            NaN            NaN             NaN\n",
      "Diabetes OptimALinear          64   44.4366   43.5454    45.5135             5/5            NaN            NaN             NaN\n",
      "Diabetes        Swish          16   45.2553   43.4773    46.6845             5/5            NaN            NaN             NaN\n",
      "Diabetes       OptimA          64   45.3624   44.7841    45.7388             5/5            NaN            NaN             NaN\n",
      "Diabetes         GeLU          16   45.5720   44.8023    45.8787             5/5            NaN            NaN             NaN\n",
      "Diabetes         ReLU          32   49.4488   48.8042    50.6882             5/5            NaN            NaN             NaN\n",
      "Diabetes        Swish          32   50.6816   48.6125    52.0265             5/5            NaN            NaN             NaN\n",
      "Diabetes          ELU          32   51.8875   48.9179    59.0607             5/5            NaN            NaN             NaN\n",
      "Diabetes         GeLU          32   52.1535   50.8366    53.8419             5/5            NaN            NaN             NaN\n",
      "Diabetes         ReLU          64   55.3266   53.7651    56.8994             5/5            NaN            NaN             NaN\n",
      "Diabetes       OptimA         128   56.9064   54.2836    60.1412             5/5            NaN            NaN             NaN\n",
      "Diabetes         GeLU          64   58.1883   56.6328    60.9300             5/5            NaN            NaN             NaN\n",
      "Diabetes        Swish          64   64.3044   60.8682    70.8184             5/5            NaN            NaN             NaN\n",
      "Diabetes OptimALinear         128   68.6150   59.9953    78.1867             5/5            NaN            NaN             NaN\n",
      "Diabetes         ReLU         128   73.7352   71.3999    75.7971             5/5            NaN            NaN             NaN\n",
      "Diabetes          ELU          64   78.5159   74.5949    80.6632             5/5            NaN            NaN             NaN\n",
      "Diabetes         GeLU         128   80.4784   76.6272    84.4243             5/5            NaN            NaN             NaN\n",
      "Diabetes        Swish         128   84.5019   80.9857    86.1812             5/5            NaN            NaN             NaN\n",
      "Diabetes       OptimA         256   92.7638   90.5704    95.0234             5/5            NaN            NaN             NaN\n",
      "Diabetes OptimALinear         256  101.6776   87.8760   145.7749             5/5            NaN            NaN             NaN\n",
      "Diabetes          ELU         128  106.8891   96.3525   143.8722             5/5            NaN            NaN             NaN\n",
      "Diabetes         ReLU         256  110.0617  108.3371   111.8510             5/5            NaN            NaN             NaN\n",
      "Diabetes         GeLU         256  111.6876  107.7615   115.4971             5/5            NaN            NaN             NaN\n",
      "Diabetes        Swish         256  112.2996  110.2315   114.8628             5/5            NaN            NaN             NaN\n",
      "Diabetes          ELU         256  134.7391  118.2005   145.7923             5/5            NaN            NaN             NaN\n",
      "\n",
      "--- California Housing ---\n",
      "           Dataset   Activation  Batch Size  Mean MAE  Best MAE  Worst MAE Successful Runs  Mean Accuracy  Best Accuracy  Worst Accuracy\n",
      "California Housing         ReLU          16    0.3703    0.3654     0.3730             5/5            NaN            NaN             NaN\n",
      "California Housing       OptimA          16    0.3710    0.3640     0.3886             5/5            NaN            NaN             NaN\n",
      "California Housing         ReLU          32    0.3739    0.3702     0.3777             5/5            NaN            NaN             NaN\n",
      "California Housing       OptimA          32    0.3745    0.3670     0.3810             5/5            NaN            NaN             NaN\n",
      "California Housing OptimALinear          16    0.3753    0.3694     0.3800             5/5            NaN            NaN             NaN\n",
      "California Housing       OptimA          64    0.3757    0.3723     0.3802             5/5            NaN            NaN             NaN\n",
      "California Housing         ReLU          64    0.3783    0.3731     0.3815             5/5            NaN            NaN             NaN\n",
      "California Housing OptimALinear          32    0.3796    0.3749     0.3850             5/5            NaN            NaN             NaN\n",
      "California Housing         ReLU         128    0.3818    0.3750     0.3850             5/5            NaN            NaN             NaN\n",
      "California Housing       OptimA         128    0.3832    0.3806     0.3863             5/5            NaN            NaN             NaN\n",
      "California Housing OptimALinear          64    0.3857    0.3779     0.3895             5/5            NaN            NaN             NaN\n",
      "California Housing         ReLU         256    0.3871    0.3849     0.3885             5/5            NaN            NaN             NaN\n",
      "California Housing         GeLU          16    0.3888    0.3874     0.3918             5/5            NaN            NaN             NaN\n",
      "California Housing         GeLU          32    0.3888    0.3870     0.3910             5/5            NaN            NaN             NaN\n",
      "California Housing OptimALinear         128    0.3889    0.3853     0.3913             5/5            NaN            NaN             NaN\n",
      "California Housing         GeLU          64    0.3917    0.3906     0.3931             5/5            NaN            NaN             NaN\n",
      "California Housing          ELU          32    0.3986    0.3962     0.4024             5/5            NaN            NaN             NaN\n",
      "California Housing        Swish          16    0.4004    0.3978     0.4054             5/5            NaN            NaN             NaN\n",
      "California Housing          ELU          16    0.4004    0.3935     0.4122             5/5            NaN            NaN             NaN\n",
      "California Housing OptimALinear         256    0.4004    0.3941     0.4116             5/5            NaN            NaN             NaN\n",
      "California Housing        Swish          32    0.4012    0.4003     0.4017             5/5            NaN            NaN             NaN\n",
      "California Housing       OptimA         256    0.4013    0.3880     0.4134             5/5            NaN            NaN             NaN\n",
      "California Housing         GeLU         128    0.4015    0.3955     0.4104             5/5            NaN            NaN             NaN\n",
      "California Housing          ELU          64    0.4044    0.4012     0.4078             5/5            NaN            NaN             NaN\n",
      "California Housing         GeLU         256    0.4097    0.4037     0.4160             5/5            NaN            NaN             NaN\n",
      "California Housing        Swish          64    0.4128    0.4096     0.4161             5/5            NaN            NaN             NaN\n",
      "California Housing          ELU         128    0.4130    0.4071     0.4166             5/5            NaN            NaN             NaN\n",
      "California Housing        Swish         128    0.4185    0.4160     0.4220             5/5            NaN            NaN             NaN\n",
      "California Housing        Swish         256    0.4237    0.4213     0.4252             5/5            NaN            NaN             NaN\n",
      "California Housing          ELU         256    0.4302    0.4235     0.4368             5/5            NaN            NaN             NaN\n"
     ]
    }
   ],
   "source": [
    "# Optionally, display results grouped by dataset for clarity\n",
    "print(\"\\n--- Results Grouped by Dataset ---\")\n",
    "for ds_name in datasets_config.keys():\n",
    "    print(f\"\\n--- {ds_name} ---\")\n",
    "    ds_df = results_df[results_df['Dataset'] == ds_name].sort_values(by=['Activation', 'Batch Size'])\n",
    "    # Sort within the dataset group to find best performance\n",
    "    metric_col = [col for col in ds_df.columns if col.startswith('Mean ')][0]\n",
    "    higher_is_better = (datasets_config[ds_name]['task_type'] == 'classification')\n",
    "    ds_df_sorted = ds_df.sort_values(by=metric_col, ascending=not higher_is_better)\n",
    "    print(ds_df_sorted.to_string(index=False, float_format=\"%.4f\"))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20690.431985,
   "end_time": "2025-05-13T11:52:23.420263",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-13T06:07:32.988278",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
